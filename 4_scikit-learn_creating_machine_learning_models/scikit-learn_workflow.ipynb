{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# A Simple Scikit-Learn (sklearn) Classification Workflow\r\n",
    "\r\n",
    "This notebook demonstrates some of the most useful functions of the beautiful Scikit-Learn package.\r\n",
    "\r\n",
    "What we're going to cover:\r\n",
    "\r\n",
    "0. An end-to-end Scikit-Learn workflow\r\n",
    "1. Getting the data ready\r\n",
    "2. Choosing the right estimator/algorithm for our problems\r\n",
    "3. Fitting the model/algorithm and using it to make predictions on our data\r\n",
    "4. Evaluating the model\r\n",
    "5. Improving the model\r\n",
    "6. Saving and loading a trained model\r\n",
    "7. Putting it all together\r\n",
    "\r\n",
    "<img src=\"img/sklearn_workflow.png\"/>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. An end-to-end Scikit-Learn workflow\r\n",
    "\r\n",
    "### Import the essential packages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Standard imports\r\n",
    "%matplotlib inline\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import pandas as pd\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Getting the data ready"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "heart_disease = pd.read_csv(\"../data/heart-disease.csv\")\r\n",
    "heart_disease"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We then divide the data into a *features matrix* called `X`, and a target column `y`. As the name implies, the features matrix contains the *features* of the dataset, or the columns that we're going to use to try and predict the target column."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "X = heart_disease.drop(\"target\", axis=1)\r\n",
    "y = heart_disease[\"target\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Choosing the right estimator/algorithm for our problems\r\n",
    "\r\n",
    "Now that we have the features matrix and the target we need to predict, it's time to choose what's the best algorithm that predicts the target. Choosing the best algorithm in this case means choosing the right model for the problem, and the right hyperparameters to tune the model just right to give the best predictions.\r\n",
    "\r\n",
    "For now, let's just use the `RandomForestClassifier` model. The `RandomForestClassifier` model is one of many classification models provided by Scikit-Learn. We'll explore the finer details about different kinds of models in the upcoming sections. Let's also use the default hyperparameters for now.\r\n",
    "\r\n",
    "For future reference, you can also use the [Scikit-Learn machine learning map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) to help you choose the right model to use for your own dataset.\r\n",
    "\r\n",
    "<img src=\"img/sklearn_ml_map.png\" width=500/>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Import the model\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "# Instantiate the model\r\n",
    "clf = RandomForestClassifier()\r\n",
    "# Show the default hyperparameters\r\n",
    "clf.get_params()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Fitting the model/algorithm and using it to make predictions on our data\r\n",
    "\r\n",
    "Now that we have a model we can use, it's time to fit the model to the training data.\r\n",
    "\r\n",
    "For that, we wil need to split our dataset into training and test sets.\r\n",
    "\r\n",
    "Fortunately, Scikit-Learn provides a handy tool to help us split our dataset. Let's take a look:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Great! we now have a proper split of training and test data.\r\n",
    "\r\n",
    "Now, it's time to fit the model into the training set:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "clf.fit(X_train, y_train);"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "OK, we've fit the model into the training data. Let's try and make some predictions and see just how well the model does its predictions.\r\n",
    "\r\n",
    "Let's now use the test data and make some predictions:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "y_preds = clf.predict(X_test)\r\n",
    "y_preds"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "y_test"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "106    1\n",
       "273    0\n",
       "214    0\n",
       "178    0\n",
       "60     1\n",
       "      ..\n",
       "82     1\n",
       "249    0\n",
       "264    0\n",
       "219    0\n",
       "242    0\n",
       "Name: target, Length: 61, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We've now got a bunch of `0`s and `1`s, and our predictions *look like* the test set target.\r\n",
    "\r\n",
    "But how do we check if the predictions line up with the test set targets or not?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Evaluating the model\r\n",
    "\r\n",
    "Scikit-learn also gives us a great tool to evaluate how well the model fits into our dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "clf.score(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Oh, wow. a perfect score of `1.0`. How nice!\r\n",
    "\r\n",
    "But what we just did is just checked the score using the training set that the model already uses to begin with. Of course it would have a perfect score when we evaluate it using the training set!\r\n",
    "\r\n",
    "Let's now try again using the test set this time:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "clf.score(X_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7868852459016393"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Not bad! We can see that the model gives a pretty good mean accuracy.\r\n",
    "\r\n",
    "Since we're dealing with a classification model, let's also explore some other ways to evaluate our classification model.\r\n",
    "\r\n",
    "Again, Scikit-Learn gives us a variety of tools for these kinds of things!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, let's try using the `classification_report` tool:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "print(classification_report(y_test, y_preds))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.79        32\n",
      "           1       0.77      0.79      0.78        29\n",
      "\n",
      "    accuracy                           0.79        61\n",
      "   macro avg       0.79      0.79      0.79        61\n",
      "weighted avg       0.79      0.79      0.79        61\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hoo boy, that's quite a bit to take in!\r\n",
    "\r\n",
    "Let's try and interpret what this classification report says:\r\n",
    "\r\n",
    "In a nutshell, the classification report compares the actual target data from the test set with the model predictions for the test set, and generates some scores on how well the model predicts the values on the test set, i.e. how accurately it got the `0` or `1` result, and so on.\r\n",
    "\r\n",
    "Next, let's try using the confusion matrix:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "confusion_matrix(y_test, y_preds)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[25,  7],\n",
       "       [ 6, 23]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's also try the accuracy score:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "accuracy_score(y_test, y_preds)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7868852459016393"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice that we got the same result as the `clf.score()` earlier. Pretty good stuff!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Improving the model\r\n",
    "\r\n",
    "Now, what can we do to try and get better results/scores on our models? \r\n",
    "\r\n",
    "This is where we tune the hyperparameters get different predictions.\r\n",
    "\r\n",
    "For starters, let's try tweaking the amount of `n_estimators` for the model:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "np.random.seed(42)\r\n",
    "\r\n",
    "for i in range(10, 100, 10):\r\n",
    "    print(f\"Trying model with {i} estimators...\")\r\n",
    "    clf = RandomForestClassifier(n_estimators=i).fit(X_train, y_train)\r\n",
    "    print(f\"Model accuracy on test set: {clf.score(X_test, y_test) * 100:.2f}%\\n\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Trying model with 10 estimators...\n",
      "Model accuracy on test set: 78.69%\n",
      "\n",
      "Trying model with 20 estimators...\n",
      "Model accuracy on test set: 81.97%\n",
      "\n",
      "Trying model with 30 estimators...\n",
      "Model accuracy on test set: 81.97%\n",
      "\n",
      "Trying model with 40 estimators...\n",
      "Model accuracy on test set: 78.69%\n",
      "\n",
      "Trying model with 50 estimators...\n",
      "Model accuracy on test set: 80.33%\n",
      "\n",
      "Trying model with 60 estimators...\n",
      "Model accuracy on test set: 85.25%\n",
      "\n",
      "Trying model with 70 estimators...\n",
      "Model accuracy on test set: 85.25%\n",
      "\n",
      "Trying model with 80 estimators...\n",
      "Model accuracy on test set: 88.52%\n",
      "\n",
      "Trying model with 90 estimators...\n",
      "Model accuracy on test set: 83.61%\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Trying out different `n_estimators` from 10 to 100, we can find that we can get the best model accuracy when we use 80 estimators!\r\n",
    "\r\n",
    "That's just one of the many hyperparameters we can tune to try and improve out machine learning models. Let's explore these further as we gain more knowledge about Scikit-Learn!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Saving and loading a trained model\r\n",
    "\r\n",
    "Once we find a model has a good looking fit for our dataset, it's a good idea to save that model so we can just load it back later.\r\n",
    "\r\n",
    "Here, we shall use the `pickle` library to save and load our models:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import pickle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To save a model, we simply `pickle.dump()` it to a filename we can specify:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "pickle.dump(clf, open(\"random_forest_model_1.pkl\", \"wb\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Great! We now have a file containing the model we just used (in this case, the one with 100 estimators).\r\n",
    "\r\n",
    "To load the saved model, simply call `pickle.load()`:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "loaded_model = pickle.load(open(\"random_forest_model_1.pkl\", \"rb\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's verify that we have loaded the correct file:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "loaded_model.score(X_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8360655737704918"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Putting it all together\r\n",
    "\r\n",
    "We've just gone through the typical workflow when dealing with Scikit-Learn projects. We went through the step-by-step process of loading a dataset, choosing a machine learning model to predict target values for the dataset, fitting the model and making actual predictions, evaluating how well the model predicted the data (compared to the actual target results), improving the model by tuning different hyperparameters, and finally saving and loading models for future use.\r\n",
    "\r\n",
    "This has been a lot to cover, but it's still just a small taste of the full capabilities Scikit-Learn offers. In the next lectures, we shall dive deeper into the workflow we went through and try to understand the deeper concepts of machine learning using Scikit-Learn. Stay Tuned!"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit (conda)"
  },
  "interpreter": {
   "hash": "a17b241f4543d8602b7482e0e0acc758b16495de27bccf17cd651e6db5d1cb08"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}