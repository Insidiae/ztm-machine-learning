{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Scikit-Learn (sklearn)\n",
    "\n",
    "This notebook demonstrates some of the most useful functions of the beautiful Scikit-Learn library.\n",
    "\n",
    "## What is Scikit-Learn?\n",
    "\n",
    "[Scikit-Learn](https://scikit-learn.org/stable/index.html), also referred to as `sklearn`, is an open-source, commercially usable Python machine learning library. Built on NumPy, SciPy, and Matplotlib, It provides simple, efficient tools that are accessible to everybody, and reusable in various contexts.\n",
    "\n",
    "![Scikit-Learn is used for modeling in machine learning projects.](./img/sklearn_6-step_ml_framework_tools_scikit-learn_highlight.png)\n",
    "\n",
    "## What we're going to cover\n",
    "\n",
    "This notebook shall be focusing on the main use cases of the Scikit-Learn library. More specifically, we shall go through the typical workflow of a Scikit-Learn project in a step-by-step process and improving upon our knowledge of Scikit-Learn as we go through the steps.\n",
    "\n",
    "0. An end-to-end Scikit-Learn workflow\n",
    "1. Getting the data ready\n",
    "2. Choosing the right estimator/algorithm for our problems\n",
    "3. Fitting the model/algorithm and using it to make predictions on our data\n",
    "4. Evaluating the model\n",
    "5. Improving the model\n",
    "6. Saving and loading a trained model\n",
    "7. Putting it all together\n",
    "\n",
    "**Note:** All of the steps in this notebook shall focus on **supervised learning** (having data and labels).\n",
    "\n",
    "## 0. An end-to-end Scikit-Learn workflow\n",
    "\n",
    "Scikit-Learn is a vast library containing a large variety of tools that can be used in various different contexts. As such, it might be better to start off with a typical end-to-end Scikit-Learn workflow and take a look at the most common use-cases of the library. \n",
    "\n",
    "[This notebook](./scikit-learn_workflow.ipynb) demonstrates one such typical Scikit-Learn workflow.\n",
    "\n",
    "From there, we shall take a much closer look at each step in the process and improve upon the knoledge we gained using Scikit-Learn.\n",
    "\n",
    "![Diagram of the Scikit-Learn workflow](img/sklearn_workflow.png)\n",
    "\n",
    "## 1. Getting the data ready\n",
    "\n",
    "### Standard imports\n",
    "\n",
    "The very first step when working with a machine learning project is to import the necessary libraries and packages you'll be working with.\n",
    "\n",
    "For this project, we shall keep using the usual Numpy, Pandas, and Matplotlib packages, so let's go ahead and import those right away:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've imported the usual packages, let's get some data to work with.\n",
    "\n",
    "Let's take a look at some heart disease data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease = pd.read_csv(\"../data/heart-disease.csv\")\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three main things we have to do are:\n",
    "\n",
    "- Split the data into features (usually called `X`) and labels (usually called `y`)\n",
    "- Converting non-numeric values into numeric values (also called *feature encoding*)\n",
    "- Filling (aka *imputing*) or disregarding missing values in the data\n",
    "\n",
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  \n",
       "0   0     1  \n",
       "1   0     2  \n",
       "2   0     2  \n",
       "3   0     2  \n",
       "4   0     2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = heart_disease[\"target\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've split the data into features and labels, we also have to split them further into *training* and *test sets* that we can use to train and validate the machine learning models we're going to be making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((242, 13), (61, 13), (242,), (61,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! we now have training and test sets for our heart disease data.\n",
    "\n",
    "When we take a look at the shapes of the training and test shapes, notice we seem to get tuples corresponding to the dimensions of the data. The second number in the tuples simply means that `X` has `13` columns of data, while `y` has only one column. But what about the `242` and `61`?\n",
    "\n",
    "Let's take a look at the shape of our original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((303, 13), (303,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(heart_disease)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the original heart disease data has `303` rows.\n",
    "\n",
    "When we did the `train_test_split()` call, notice we had a `test_size` parameter set to `0.2`.\n",
    "\n",
    "This means 20% of the data rows shoud be allocated for the test set. Let's verify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(303 * 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "303 - 61"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it checks out. 242 rows were allocated for the training set while 61 rows were allocated for the test set.\n",
    "\n",
    "### Converting data into numeric values\n",
    "\n",
    "Luckily, the heart disease data provided to us is already in numeric form on all columns.\n",
    "\n",
    "However, most other datasets might not have all their data in numerical form.\n",
    "\n",
    "It is important to convert the non-numeric data into numerical form first, because most machine learning models only work on numeric inputs.\n",
    "\n",
    "Let's take a look at another example dataset and see how we can convert these kinds of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431</td>\n",
       "      <td>4</td>\n",
       "      <td>15323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714</td>\n",
       "      <td>5</td>\n",
       "      <td>19943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714</td>\n",
       "      <td>4</td>\n",
       "      <td>28343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365</td>\n",
       "      <td>4</td>\n",
       "      <td>13434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577</td>\n",
       "      <td>3</td>\n",
       "      <td>14043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Make Colour  Odometer (KM)  Doors  Price\n",
       "0   Honda  White          35431      4  15323\n",
       "1     BMW   Blue         192714      5  19943\n",
       "2   Honda  White          84714      4  28343\n",
       "3  Toyota  White         154365      4  13434\n",
       "4  Nissan   Blue         181577      3  14043"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales = pd.read_csv(\"../data/car-sales-extended.csv\")\n",
    "car_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(car_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             object\n",
       "Colour           object\n",
       "Odometer (KM)     int64\n",
       "Doors             int64\n",
       "Price             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the `Make` and `Colour` columns have non-numeric data.\n",
    "\n",
    "Let's see what happens if we try and build a model on the dataset without first converting those columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = car_sales.drop(\"Price\", axis=1)\n",
    "y = car_sales[\"Price\"]\n",
    "\n",
    "np.random.seed(69)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Toyota'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ecb56ad8f06d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    327\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         )\n",
      "\u001b[1;32md:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    570\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 956\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m    957\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    736\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 738\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    739\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m                 raise ValueError(\n",
      "\u001b[1;32md:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1898\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1899\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1900\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1901\u001b[0m     def __array_wrap__(\n",
      "\u001b[1;32md:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Toyota'"
     ]
    }
   ],
   "source": [
    "# Try to predict with random forest on price column (doesn't work)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh dear, looks like Scikit-Learn throws an error when we try and build a model this time.\n",
    "\n",
    "The error message gives us a hint as to what went wrong:\n",
    "> ValueError: could not convert string to float: 'Toyota'\n",
    "\n",
    "This means the `RandomForestRegressor()` model only accepts numeric inputs. Otherwise, it throws an error when it tries to deal with non-numeric data.\n",
    "\n",
    "Now, let's see how to get around that error by converting the non-numeric data into a numeric format that the model can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `categorical_features` list contains the columns that have non-numeric or *categorical* data\n",
    "\n",
    "Now, we're trying to convert the `Make` and `Colour` columns into a numeric format, but why is `Doors` also included in the list?\n",
    "\n",
    "Let's take a look at the `Doors` column first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    856\n",
       "5     79\n",
       "3     65\n",
       "Name: Doors, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales[\"Doors\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Doors` column indeed contains numerical data, but at the same time it also has very few distinct values with little variance.\n",
    "\n",
    "Thus, it can also make sense to treat those discrete values as different *categories* that the data can fall into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 3.54310e+04],\n",
       "       [1.00000e+00, 0.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        1.00000e+00, 1.92714e+05],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 8.47140e+04],\n",
       "       ...,\n",
       "       [0.00000e+00, 0.00000e+00, 1.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 6.66040e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 2.15883e+05],\n",
       "       [0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 2.48360e+05]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                  one_hot,\n",
    "                                  categorical_features)],\n",
    "                                  remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that's quite a lot to take in. Let's try and convert it into a Pandas `DataFrame` so we can have an easier time reading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>192714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181577.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66604.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215883.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248360.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9    10   11        12\n",
       "0    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   35431.0\n",
       "1    1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  192714.0\n",
       "2    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   84714.0\n",
       "3    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  154365.0\n",
       "4    0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  181577.0\n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...\n",
       "995  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   35820.0\n",
       "996  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  155144.0\n",
       "997  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0   66604.0\n",
       "998  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  215883.0\n",
       "999  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  248360.0\n",
       "\n",
       "[1000 rows x 13 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(transformed_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you might say: \"Hold on, this doesn't look the same as the original data!\", but let's take a step back and look at what's actually happened here.\n",
    "\n",
    "For reference, here's the dataset we're working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>35820</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>White</td>\n",
       "      <td>155144</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>66604</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215883</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>248360</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Make Colour  Odometer (KM)  Doors\n",
       "0     Honda  White          35431      4\n",
       "1       BMW   Blue         192714      5\n",
       "2     Honda  White          84714      4\n",
       "3    Toyota  White         154365      4\n",
       "4    Nissan   Blue         181577      3\n",
       "..      ...    ...            ...    ...\n",
       "995  Toyota  Black          35820      4\n",
       "996  Nissan  White         155144      3\n",
       "997  Nissan   Blue          66604      4\n",
       "998   Honda  White         215883      4\n",
       "999  Toyota   Blue         248360      4\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm... It looks like we do have the same values on the `Odometer (KM)` column in the `teansformed_X` dataset.\n",
    "\n",
    "Still, what's the deal with all the other columns?\n",
    "\n",
    "The new columns are a result of the `OneHotEncoder` transforming the catergorical data into multiple categories.\n",
    "\n",
    "It does this by generating additional columns to represent each distinct category for the data.\n",
    "\n",
    "For example, `OneHotEncoder` generated four columns to represent each of the car makes (`BMW`, `Honda`, `Nissan`, and `Toyota`). Each of those columns will then have a value of `0.0` if the car doesn't have the corresponding car make, or `1.0` if the car does have the corresponding car make. Note that only one column out of those four will have a `1.0` value, and the rest should have a value of `0.0`.\n",
    "\n",
    "`OneHotEncoder` also does the same thing for the other `categorical_features` in the dataset.\n",
    "\n",
    "#### Another way to encode categorical data\n",
    "\n",
    "We can also use the `get_dummies()` function from the Pandas library to convert categorical data into numeric form.\n",
    "\n",
    "Let's take a look at the original `car_sales` dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431</td>\n",
       "      <td>4</td>\n",
       "      <td>15323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714</td>\n",
       "      <td>5</td>\n",
       "      <td>19943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714</td>\n",
       "      <td>4</td>\n",
       "      <td>28343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365</td>\n",
       "      <td>4</td>\n",
       "      <td>13434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577</td>\n",
       "      <td>3</td>\n",
       "      <td>14043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Make Colour  Odometer (KM)  Doors  Price\n",
       "0   Honda  White          35431      4  15323\n",
       "1     BMW   Blue         192714      5  19943\n",
       "2   Honda  White          84714      4  28343\n",
       "3  Toyota  White         154365      4  13434\n",
       "4  Nissan   Blue         181577      3  14043"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doors</th>\n",
       "      <th>Make_BMW</th>\n",
       "      <th>Make_Honda</th>\n",
       "      <th>Make_Nissan</th>\n",
       "      <th>Make_Toyota</th>\n",
       "      <th>Colour_Black</th>\n",
       "      <th>Colour_Blue</th>\n",
       "      <th>Colour_Green</th>\n",
       "      <th>Colour_Red</th>\n",
       "      <th>Colour_White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Doors  Make_BMW  Make_Honda  Make_Nissan  Make_Toyota  Colour_Black  \\\n",
       "0        4         0           1            0            0             0   \n",
       "1        5         1           0            0            0             0   \n",
       "2        4         0           1            0            0             0   \n",
       "3        4         0           0            0            1             0   \n",
       "4        3         0           0            1            0             0   \n",
       "..     ...       ...         ...          ...          ...           ...   \n",
       "995      4         0           0            0            1             1   \n",
       "996      3         0           0            1            0             0   \n",
       "997      4         0           0            1            0             0   \n",
       "998      4         0           1            0            0             0   \n",
       "999      4         0           0            0            1             0   \n",
       "\n",
       "     Colour_Blue  Colour_Green  Colour_Red  Colour_White  \n",
       "0              0             0           0             1  \n",
       "1              1             0           0             0  \n",
       "2              0             0           0             1  \n",
       "3              0             0           0             1  \n",
       "4              1             0           0             0  \n",
       "..           ...           ...         ...           ...  \n",
       "995            0             0           0             0  \n",
       "996            0             0           0             1  \n",
       "997            1             0           0             0  \n",
       "998            0             0           0             1  \n",
       "999            1             0           0             0  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = pd.get_dummies(car_sales[[\"Make\", \"Colour\", \"Doors\"]])\n",
    "dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the `Make` and `Colour` columns were split into different categories, but the `Doors` column was still left intact.\n",
    "\n",
    "Again, since the `Doors` column is already numeric, we can leave it as-is, but if we want to treat it as a categorical data, we can convert it into an `object` type for the `get_dummies()` function to split it into categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make_BMW</th>\n",
       "      <th>Make_Honda</th>\n",
       "      <th>Make_Nissan</th>\n",
       "      <th>Make_Toyota</th>\n",
       "      <th>Colour_Black</th>\n",
       "      <th>Colour_Blue</th>\n",
       "      <th>Colour_Green</th>\n",
       "      <th>Colour_Red</th>\n",
       "      <th>Colour_White</th>\n",
       "      <th>Doors_3</th>\n",
       "      <th>Doors_4</th>\n",
       "      <th>Doors_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Make_BMW  Make_Honda  Make_Nissan  Make_Toyota  Colour_Black  \\\n",
       "0           0           1            0            0             0   \n",
       "1           1           0            0            0             0   \n",
       "2           0           1            0            0             0   \n",
       "3           0           0            0            1             0   \n",
       "4           0           0            1            0             0   \n",
       "..        ...         ...          ...          ...           ...   \n",
       "995         0           0            0            1             1   \n",
       "996         0           0            1            0             0   \n",
       "997         0           0            1            0             0   \n",
       "998         0           1            0            0             0   \n",
       "999         0           0            0            1             0   \n",
       "\n",
       "     Colour_Blue  Colour_Green  Colour_Red  Colour_White  Doors_3  Doors_4  \\\n",
       "0              0             0           0             1        0        1   \n",
       "1              1             0           0             0        0        0   \n",
       "2              0             0           0             1        0        1   \n",
       "3              0             0           0             1        0        1   \n",
       "4              1             0           0             0        1        0   \n",
       "..           ...           ...         ...           ...      ...      ...   \n",
       "995            0             0           0             0        0        1   \n",
       "996            0             0           0             1        1        0   \n",
       "997            1             0           0             0        0        1   \n",
       "998            0             0           0             1        0        1   \n",
       "999            1             0           0             0        0        1   \n",
       "\n",
       "     Doors_5  \n",
       "0          0  \n",
       "1          1  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "..       ...  \n",
       "995        0  \n",
       "996        0  \n",
       "997        0  \n",
       "998        0  \n",
       "999        0  \n",
       "\n",
       "[1000 rows x 12 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales[\"Doors\"] = car_sales[\"Doors\"].astype(object)\n",
    "dummies = pd.get_dummies(car_sales[[\"Make\", \"Colour\", \"Doors\"]])\n",
    "dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now that we've successfully transformed the data into numeric form, we can try and fit a model on our transformed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31695249778476753"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(69)\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X, y, test_size=0.2)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic! Looks like we've successfully fitted a model to the data without getting an error this time, all thanks to transforming our data into numeric form.\n",
    "\n",
    "### Dealing with missing values\n",
    "\n",
    "There are two ways to deal with missing data.\n",
    "\n",
    "- Fill in the missing parts with a predetermined value. This approach is also known as **_imputation_**.\n",
    "- Remove the rows cotaining missing data altogether. Note that this results in having less data to work with.\n",
    "\n",
    "**Note:** Dealing with missing values is a problem to problem issue. And there's often no best way to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>35820.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>155144.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>66604.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215883.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>248360.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12732.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Make Colour  Odometer (KM)  Doors    Price\n",
       "0     Honda  White        35431.0    4.0  15323.0\n",
       "1       BMW   Blue       192714.0    5.0  19943.0\n",
       "2     Honda  White        84714.0    4.0  28343.0\n",
       "3    Toyota  White       154365.0    4.0  13434.0\n",
       "4    Nissan   Blue       181577.0    3.0  14043.0\n",
       "..      ...    ...            ...    ...      ...\n",
       "995  Toyota  Black        35820.0    4.0  32042.0\n",
       "996     NaN  White       155144.0    3.0   5716.0\n",
       "997  Nissan   Blue        66604.0    4.0  31570.0\n",
       "998   Honda  White       215883.0    4.0   4001.0\n",
       "999  Toyota   Blue       248360.0    4.0  12732.0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing = pd.read_csv(\"../data/car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see some odd bits on `NaN` values in this dataset.\n",
    "\n",
    "One way to quickly check exactly how much missing data is in your dataset is to use the `isna()` method from Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have quite a lot of missing fields in our dataset.\n",
    "\n",
    "What happens if we try and fit a model on a dataset with missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = car_sales_missing.drop(\"Price\", axis=1)\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-189d5475a87d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m69\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformed_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    327\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         )\n",
      "\u001b[1;32md:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    570\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 956\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m    957\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    710\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m         \u001b[0m_ensure_no_complex_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 712\u001b[1;33m         array = _ensure_sparse_format(\n\u001b[0m\u001b[0;32m    713\u001b[0m             \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[1;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse)\u001b[0m\n\u001b[0;32m    469\u001b[0m             )\n\u001b[0;32m    470\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"allow-nan\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    112\u001b[0m         ):\n\u001b[0;32m    113\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"infinity\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"NaN, infinity\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    115\u001b[0m                 msg_err.format(\n\u001b[0;32m    116\u001b[0m                     \u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "# Transform categorical data into numeric form\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                   one_hot,\n",
    "                                   categorical_features)],\n",
    "                                   remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X\n",
    "\n",
    "# Try and fit a model\n",
    "np.random.seed(69)\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X, y, test_size=0.2)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get another error this time:\n",
    "> ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
    "\n",
    "This means Scikit-Learn also needs the data to contain no missing values.\n",
    "\n",
    "Let's see how we can deal with these missing data before we try and fit a model on this dataset.\n",
    "\n",
    "#### Option 1: Use Pandas to deal with missing data\n",
    "\n",
    "We can use Pandas to fill in the missing values of the dataset.\n",
    "\n",
    "For numerical values we can simply use the mean of the existing data in the column, and for categorical data we can use some other predetermined value instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>35820.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Missing</td>\n",
       "      <td>White</td>\n",
       "      <td>155144.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>66604.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215883.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>248360.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12732.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Make Colour  Odometer (KM)  Doors    Price\n",
       "0      Honda  White        35431.0    4.0  15323.0\n",
       "1        BMW   Blue       192714.0    5.0  19943.0\n",
       "2      Honda  White        84714.0    4.0  28343.0\n",
       "3     Toyota  White       154365.0    4.0  13434.0\n",
       "4     Nissan   Blue       181577.0    3.0  14043.0\n",
       "..       ...    ...            ...    ...      ...\n",
       "995   Toyota  Black        35820.0    4.0  32042.0\n",
       "996  Missing  White       155144.0    3.0   5716.0\n",
       "997   Nissan   Blue        66604.0    4.0  31570.0\n",
       "998    Honda  White       215883.0    4.0   4001.0\n",
       "999   Toyota   Blue       248360.0    4.0  12732.0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing[\"Make\"].fillna(\"Missing\", inplace=True)\n",
    "car_sales_missing[\"Colour\"].fillna(\"Missing\", inplace=True)\n",
    "car_sales_missing[\"Odometer (KM)\"].fillna(car_sales_missing[\"Odometer (KM)\"].mean(), inplace=True)\n",
    "car_sales_missing[\"Doors\"].fillna(4, inplace=True)\n",
    "car_sales_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make              0\n",
       "Colour            0\n",
       "Odometer (KM)     0\n",
       "Doors             0\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `Price` column still has missing values.\n",
    "\n",
    "Since `Price` is the value we're trying to predict, it might be better to just remove the rows with no `Price` value for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             0\n",
       "Colour           0\n",
       "Odometer (KM)    0\n",
       "Doors            0\n",
       "Price            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have no missing values in our data, but it came at a cost of having to remove a number of rows that had no `Price` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "950"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(car_sales_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try fitting a model into this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = car_sales_missing.drop(\"Price\", axis=1)\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25296341556528734"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform categorical data into numeric form\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                   one_hot,\n",
    "                                   categorical_features)],\n",
    "                                   remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X\n",
    "\n",
    "# Try and fit a model\n",
    "np.random.seed(69)\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X, y, test_size=0.2)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: Use Scikit-Learn to deal with missing data\n",
    "\n",
    "We can also use Scikit-Learn to deal with missing data.\n",
    "\n",
    "Let's use the `car_sales_missing` dataset once again, this time using Scikit-Learn to fill in or remove rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing = pd.read_csv(\"../data/car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we can drop the rows with the missing `Price` values for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             47\n",
       "Colour           46\n",
       "Odometer (KM)    48\n",
       "Doors            47\n",
       "Price             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing.dropna(subset=[\"Price\"], inplace=True)\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also split the remaining data into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X and y\n",
    "X = car_sales_missing.drop(\"Price\", axis=1)\n",
    "y = car_sales_missing[\"Price\"]\n",
    "\n",
    "# Split data into train and test\n",
    "np.random.seed(69)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's fill in the missing data using Scikit-Learn.\n",
    "\n",
    "Note that it is best practice to use the following Scikit-Learn functions to fill and transform missing data separately on the training and test sets.\n",
    "\n",
    "Why is that? It is because performing imputation on the whole un-split dataset is causing \"information leakage\", which is when information contained in the test set is \"leaked\" into the training data set. The result is a biased estimator with an optimistic test error. The test set should be set aside at the beginning of any machine learning project and only be touched when validating the model.\n",
    "\n",
    "Here are some guidelines to keep in mind when handling missing data:\n",
    "- Split your data first (into train/test), always keep your training & test data separate\n",
    "- Fill/transform the training set and test sets separately (this goes for filling data with pandas as well)\n",
    "- Don't use data from the future (test set) to fill data from the past (training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Use SimpleImputer to fill in missing values\n",
    "cat_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"Missing\")\n",
    "door_imputer = SimpleImputer(strategy=\"constant\", fill_value=4)\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "# Define columns\n",
    "cat_features = [\"Make\", \"Colour\"]\n",
    "door_feature = [\"Doors\"]\n",
    "num_features = [\"Odometer (KM)\"]\n",
    "\n",
    "# Create an imputer\n",
    "imputer = ColumnTransformer([\n",
    "    (\"cat_imputer\", cat_imputer, cat_features),\n",
    "    (\"door_imputer\", door_imputer, door_feature),\n",
    "    (\"num_imputer\", num_imputer, num_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an imputer set up, it's time to use it to actually fill in the missing values in the dataset.\n",
    "\n",
    "> **Note:** We use `fit_transform()` on the training data and `transform()` on the testing data. In essence, we learn the patterns in the training set and transform it via imputation (fit, then transform). Then we take those same patterns and fill the test set (transform only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['BMW', 'White', 5.0, 152410.0],\n",
       "       ['Nissan', 'Green', 4.0, 87701.0],\n",
       "       ['Nissan', 'White', 4.0, 51004.0],\n",
       "       ...,\n",
       "       ['Honda', 'White', 4.0, 40134.0],\n",
       "       ['Nissan', 'Black', 4.0, 125251.0],\n",
       "       ['Missing', 'White', 4.0, 109384.0]], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_X_train = imputer.fit_transform(X_train)\n",
    "filled_X_test = imputer.transform(X_test)\n",
    "\n",
    "filled_X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the result as a Pandas `DataFrame` to get a better look at what just happened:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BMW</td>\n",
       "      <td>White</td>\n",
       "      <td>5.0</td>\n",
       "      <td>152410.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Green</td>\n",
       "      <td>4.0</td>\n",
       "      <td>87701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>White</td>\n",
       "      <td>4.0</td>\n",
       "      <td>51004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Blue</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>4.0</td>\n",
       "      <td>132327.821823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>4.0</td>\n",
       "      <td>193179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Blue</td>\n",
       "      <td>4.0</td>\n",
       "      <td>196507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Black</td>\n",
       "      <td>4.0</td>\n",
       "      <td>125251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>Missing</td>\n",
       "      <td>White</td>\n",
       "      <td>4.0</td>\n",
       "      <td>109384.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Make Colour Doors  Odometer (KM)\n",
       "0        BMW  White   5.0       152410.0\n",
       "1     Nissan  Green   4.0        87701.0\n",
       "2     Nissan  White   4.0        51004.0\n",
       "3      Honda   Blue   4.0        30120.0\n",
       "4     Toyota   Blue   4.0  132327.821823\n",
       "..       ...    ...   ...            ...\n",
       "755    Honda  White   4.0       193179.0\n",
       "756    Honda   Blue   4.0       196507.0\n",
       "757    Honda  White   4.0        40134.0\n",
       "758   Nissan  Black   4.0       125251.0\n",
       "759  Missing  White   4.0       109384.0\n",
       "\n",
       "[760 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_filled_train = pd.DataFrame(filled_X_train,\n",
    "                                      columns=[\"Make\", \"Colour\", \"Doors\", \"Odometer (KM)\"])\n",
    "\n",
    "car_sales_filled_test = pd.DataFrame(filled_X_test,\n",
    "                                      columns=[\"Make\", \"Colour\", \"Doors\", \"Odometer (KM)\"])\n",
    "\n",
    "car_sales_filled_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             0\n",
       "Colour           0\n",
       "Doors            0\n",
       "Odometer (KM)    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_filled_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonderful! We've just used Scikit-Learn to fill in the missing values.\n",
    "\n",
    "Now, there's just one more step before we can fit a model to this dataset.\n",
    "\n",
    "Let's revisit a previous topic and convert the categorical features into a numeric form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<760x15 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3040 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode the features with the same code as before \n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\", \n",
    "                                 one_hot, \n",
    "                                 categorical_features)],\n",
    "                                 remainder=\"passthrough\")\n",
    "\n",
    "# Fill train and test values separately\n",
    "transformed_X_train = transformer.fit_transform(car_sales_filled_train)\n",
    "transformed_X_test = transformer.transform(car_sales_filled_test)\n",
    "\n",
    "# Check transformed and filled X_train\n",
    "transformed_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>152410.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87701.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51004.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132327.821823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>193179.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>196507.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40134.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125251.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109384.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9    10   11   12   13  \\\n",
       "0    1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0   \n",
       "1    0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "2    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   \n",
       "3    0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "4    0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "755  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   \n",
       "756  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "757  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   \n",
       "758  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "759  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   \n",
       "\n",
       "                14  \n",
       "0    152410.000000  \n",
       "1     87701.000000  \n",
       "2     51004.000000  \n",
       "3     30120.000000  \n",
       "4    132327.821823  \n",
       "..             ...  \n",
       "755  193179.000000  \n",
       "756  196507.000000  \n",
       "757   40134.000000  \n",
       "758  125251.000000  \n",
       "759  109384.000000  \n",
       "\n",
       "[760 rows x 15 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(transformed_X_train.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've done all the necessary steps to get our data ready, let's see if we can fit a machine learning model this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2603174739059788"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(69)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(transformed_X_train, y_train)\n",
    "model.score(transformed_X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work! We've successfully prepared our dataset by splitting into training and test sets, handling missing data, and converting categorical features into a numerical form. That means we are now able to use these steps to transform any other dataset in order to better fit machine learning models.\n",
    "\n",
    "If this looks confusing, don't worry, we've covered a lot of ground very quickly. And we'll revisit these strategies in a future section in way which makes a lot more sense.\n",
    "\n",
    "For now, the key takeaways to remember are:\n",
    "\n",
    "- Most datasets you come across won't be in a form ready to immediately start using them with machine learning models. And some may take more preparation than others to get ready to use.\n",
    "- For most machine learning models, your data has to be numerical. This will involve converting whatever you're working with into numbers. This process is often referred to as **feature engineering** or **feature encoding**.\n",
    "- Some machine learning models aren't compatible with missing data. The process of filling missing data is referred to as **data imputation**.\n",
    "\n",
    "## 2. Choosing the right estimator/algorithm for our problems\n",
    "\n",
    "In order to get the right predictions for our data, it is important that we choose the right machine learning model that can best fit our data.\n",
    "\n",
    "So far we've been using the `RandomForestRegressor` model provided by Scikit-Learn. But how did we know that it's the right model to use for our dataset? When does it make sense to use that particular model, and when does it make more sense to choose another model to fit?\n",
    "\n",
    "First, we must ask ourselves what kind of machine learning problem are we trying to solve.\n",
    "\n",
    "Here are some common types of machine learning problems:\n",
    "- **Classification** - predicting whether a sample is one thing or another (i.e. whether a patient has heart disease)\n",
    "   > Sometimes you'll see `clf` (short for classifier) used as a classification estimator instance's variable name.\n",
    "- **Regression** - predicting a number (i.e. selling price of a car)\n",
    "- **Clustering** - discovering groups in data (i.e. identifying different cutomer segments)\n",
    "- **Dimensionality Reduction** - reducing the number of features in a given dataset (select only the important ones)\n",
    "\n",
    "Scikit-Learn also provides [a handy cheat-sheet](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) to help us identify the machine learning problem, as well as some options for machine learning models to use on our given datasets:\n",
    "\n",
    "![Scikit-Learn algorithm cheat-sheet](./img/sklearn_ml_map.png)\n",
    "\n",
    "> **Note:** Scikit-Learn uses *estimator* as another term for machine learning *model* or *algorithm*.\n",
    "\n",
    "### Picking a machine learning model for a regression problem\n",
    "\n",
    "Let's start with a regression problem. We'll use the [California housing dataset](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset) built into Scikit-Learn's `datasets` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "california = fetch_california_housing() # returns a HUGE dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `california` dataset is loaded as a Python dictionary, so let's turn it into a Pandas `DataFrame` to make it easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  target  \n",
       "0        -122.23   4.526  \n",
       "1        -122.22   3.585  \n",
       "2        -122.24   3.521  \n",
       "3        -122.25   3.413  \n",
       "4        -122.25   3.422  \n",
       "...          ...     ...  \n",
       "20635    -121.09   0.781  \n",
       "20636    -121.21   0.771  \n",
       "20637    -121.22   0.923  \n",
       "20638    -121.32   0.847  \n",
       "20639    -121.24   0.894  \n",
       "\n",
       "[20640 rows x 9 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "california_df = pd.DataFrame(california[\"data\"], columns=california[\"feature_names\"])\n",
    "california_df[\"target\"] = pd.Series(california[\"target\"])\n",
    "california_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's quite a lot of data. Let's see exactly how many samples are we working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20640"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(california_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now let's try using that cheat-sheet and pick a machine learning model for the dataset.\n",
    "\n",
    "![Using the Scikit-Learn cheatsheet to choose a model for the Boston housing dataset](./img/sklearn-ml-map-cheatsheet-california-housing-ridge.png)\n",
    "\n",
    "Following the flowchart we see that Scikit-Learn suggests using a [`Ridge`](https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression) regression model. Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6060537241737072"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "np.random.seed(69)\n",
    "\n",
    "X = california_df.drop(\"target\", axis=1)\n",
    "y = california_df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = Ridge()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad. But let's see if we can still get an even better result.\n",
    "\n",
    "What happens if the `Ridge` regressor did not work, or did not produce as good of a score as we wanted?\n",
    "\n",
    "Let's check back on the cheat-sheet to see if we can prceed with an alternative step:\n",
    "\n",
    "![Trying out the Ensemble regressors in case the Ridge regressor did not achieve the result we wanted](./img/sklearn-ml-map-cheatsheet-california-housing-ensemble.png)\n",
    "\n",
    "Following the diagram, we see that the next step would be to try out [`EnsembleRegressors`](https://scikit-learn.org/stable/modules/ensemble.html).\n",
    "\n",
    "One of the most common and useful ensemble methods is the [Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#forest), known for its fast training and prediction times and adaptability to different problems.\n",
    "\n",
    "We've actually used the `RandomForestRegressor` model earlier in this notebook, and here we see why we chose this particular model in those earlier datasets.\n",
    "\n",
    "The basic premise of the Random Forest is to combine a number of different decision trees, each one random from the other and make a prediction on a sample by averaging the result of each decision tree.\n",
    "\n",
    "An in-depth discussion of the Random Forest algorithm is beyond the scope of this notebook but if you're interested in learning more, [An Implementation and Explanation of the Random Forest](https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76) in Python by Will Koehrsen is a great read.\n",
    "\n",
    "Let's try using the [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) on the Boston dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8081169165695959"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(69)\n",
    "\n",
    "X = california_df.drop(\"target\", axis=1)\n",
    "y = california_df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonderful! We see that we get a much better score using the `RandomForestRegressor`.\n",
    "\n",
    "### Picking a machine learning model for a classification problem\n",
    "\n",
    "Now let's try another type of machine learning problem. This time let's work through the steps of picking a model for a classification problem.\n",
    "\n",
    "The heart disease dataset from earlier contains data for exactly that kind of problem, so let's take another look at that here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease = pd.read_csv(\"../data/heart-disease.csv\")\n",
    "heart_disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's check how many samples we're dealing with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(heart_disease)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's work through the cheat-sheet yet again to try and find the right model for our heart disease dataset.\n",
    "\n",
    "![Using the Scikit-Learn cheat-sheet to find the right model for the heart disease dataset](./img/sklearn-ml-map-cheatsheet-heart-disease-linear-svc.png)\n",
    "\n",
    "Following the diagram, we see that we are recommended to use the [`LinearSVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC) model. `LinearSVC` stands for Linear Support Vector Classifier.\n",
    "\n",
    "Let's try it on our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8360655737704918"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "np.random.seed(69)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = LinearSVC(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, but we see that we get some warning that tells us that the model fails to converge on a final result.\n",
    "\n",
    "We can try and tweak some settings to try and fix those issues, but let's get to that another time.\n",
    "\n",
    "For now, let's proceed along the cheat-sheet and choose another classifier model.\n",
    "\n",
    "![Picking another classifier model from the cheat-sheet](./img/sklearn-ml-map-cheatsheet-heart-disease-ensemble.png)\n",
    "\n",
    "We see that we get to the `EnsembleMethods` again. Except this time, we're going to be using ensemble *classifiers* instead of *regressors*.\n",
    "\n",
    "The Random Forest model has another variant that is used for classification problems. Let's try using it on the heart disease data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(69)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good job! We see that we got no warnings this time using the `RandomForestClassifier`, and we also got a better score to boot.\n",
    "\n",
    "Again, we can tweak some settings or *hyperparameters* in the models above to try and improve their results, and we'll take a look at that more closely in later sections.\n",
    "\n",
    "To wrap things up for this section, here's some quick guideleined for choosing machine learning models:\n",
    "- If you have structured data (tables or dataframes), use ensemble methods, such as, a Random Forest.\n",
    "- If you have unstructured data (text, images, audio, things not in tables), use deep learning or transfer learning.\n",
    "\n",
    "For this notebook, we're focused on structured data, which is why the Random Forest has been our model of choice.\n",
    "\n",
    "If you'd like to learn more about the Random Forest and why it's the war horse of machine learning, check out these resources:\n",
    "\n",
    "- [Random Forest Wikipedia](https://en.wikipedia.org/wiki/Random_forest)\n",
    "- [Random Forests in Python](http://blog.yhat.com/posts/random-forests-in-python.html) by yhat\n",
    "- [An Implementation and Explanation of the Random Forest in Python](https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76) by Will Koehrsen\n",
    "\n",
    "The beautiful part about using Scikit-Learn is that its API allows us to use different models with pretty much the exact same workflows. Indeed, we see that our code has stayed pretty much the same across the different machine learning models used in this section. A big part of being a machine learning engineer or data scientist is experimenting - you might want to try out some of the other models on the cheat-sheet and see how you go. The more you can reduce the time between experiments, the better.\n",
    "\n",
    "## 3. Fitting the model/algorithm and using it to make predictions on our data\n",
    "\n",
    "Now that we have chosen a model for our data, it's time to have the model learn about our data so it can be used to make predictions.\n",
    "\n",
    "We've actually encountered some examples of this in the earlier sections, when we were fitting the model to the sample datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(69)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what is the `fit()` method actually doing when we call it on our data?\n",
    "\n",
    "When we call the `fit()` method, the machine learning algorithm attempt to find patterns between `X` and/or `y`.\n",
    "\n",
    "Let's take a look at our `X` and `y` data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>193</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>293</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "77    59    1   1       140   221    0        1      164      1      0.0   \n",
       "117   56    1   3       120   193    0        0      162      0      1.9   \n",
       "124   39    0   2        94   199    0        1      179      0      0.0   \n",
       "237   60    1   0       140   293    0        0      170      0      1.2   \n",
       "122   41    0   2       112   268    0        0      172      1      0.0   \n",
       "\n",
       "     slope  ca  thal  \n",
       "77       2   0     2  \n",
       "117      1   0     3  \n",
       "124      2   0     2  \n",
       "237      1   2     3  \n",
       "122      2   0     2  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77     1\n",
       "117    1\n",
       "124    1\n",
       "237    0\n",
       "122    1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we call `fit(X, y)`, the model takes a look at all the examples in `X` (features) and sees what the corresponding `y` (label) is.\n",
    "\n",
    "Each different model looks at the data differently, but for now you can imagine it being similar to how people notice patterns in data over time.\n",
    "\n",
    "You'd look at the feature variables, X, the age, sex, chol (cholesterol) and see what different values led to the labels, y, 1 for heart disease, 0 for not heart disease.\n",
    "\n",
    "This concept, regardless of the problem, is similar throughout all of machine learning.\n",
    "\n",
    "**During training (finding patterns in data):**\n",
    "\n",
    "A machine learning algorithm looks at a dataset, finds patterns, tries to use those patterns to predict something and corrects itself as best it can with the available data and labels. It stores these patterns for later use.\n",
    "\n",
    "**During testing or in production (using learned patterns):**\n",
    "\n",
    "A machine learning algorithm uses the patterns its previously learned in a dataset to make a prediction on some unseen data.\n",
    "\n",
    "### Making predictions using a machine learning model\n",
    "\n",
    "After fitting the model to the data (aka training the machine learning model), we'll want to use it to make predictions.\n",
    "\n",
    "Scikit-Learn offers several ways to make predictions, the most common of which being `predict()` and `predict_proba()`.\n",
    "\n",
    "Let's see how they work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given data in the form of `X`, the `predict()` function returns labels in the form of `y`.\n",
    "\n",
    "It's standard practice to save these predictions to a variable named something like `y_preds` for later comparison to `y_test` or `y_true` (usually same as `y_test` just another name):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = clf.predict(X_test)\n",
    "np.mean(y_preds == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, where have we seen that kind of result before?\n",
    "\n",
    "That's right, the `accuracy_score()` and `clf.score()` functions make these comparisons in the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've been dealing with the `predict()` function. The `predict()` function returns values in the same format as the labels in `y`.\n",
    "\n",
    "If you would instead like to get the *probabilities* of getting a label based on the given data, you can instead use `predict_proba()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9 , 0.1 ],\n",
       "       [0.99, 0.01],\n",
       "       [0.73, 0.27],\n",
       "       [0.93, 0.07],\n",
       "       [0.01, 0.99]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast, here's what `predict()` would've returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `predict_proba()` returns an array of values for each row of the input rather than just one single number per row like `predict()` does.\n",
    "\n",
    "The array of values returned by `predict_proba()` are actualy the *probabilities* of getting a certain label (in our case either `0` or `1`) given an input sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9, 0.1]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This particular output means that for the sample `X_test[:1]`, the model predicts that the sample will have a label `0` with a probability score of `0.9`.\n",
    "\n",
    "Conversely, this also means the sample would have a label `1` with probability score of `0.1`.\n",
    "\n",
    "Given these two probabilities, which one do you think would we get if we used `predict()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a predicted label `0`.\n",
    "\n",
    "Because our problem is a classification task, we could simply just get the one with the highest probability if we want a singular output label.\n",
    "\n",
    "With our dataset only having two labels to choose from, predicting a label with 0.5 probability every time would be the same as a coin toss (guessing). Therefore, once the prediction probability of a sample passes 0.5 for a certain label, it's assigned that label.\n",
    "\n",
    "### Predicting values for regression problems\n",
    "\n",
    "`predict()` can also be used for regression problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(69)\n",
    "\n",
    "X = california_df.drop(\"target\", axis=1)\n",
    "y = california_df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For regression problems, we can validate our predictions using `mean_absolute_error()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3270582259932172"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluating the model\n",
    "\n",
    "We've seen how to train a model to find patterns in data with `fit()`. We've also seen how to make predictions with the trined model using `predict()` and `predict_proba()`.\n",
    "\n",
    "Now it's time to evaluate how trustworthy our model's predictions are.\n",
    "\n",
    "Once you've trained a model, you'll want a way to measure how trustworthy its predictions are.\n",
    "\n",
    "Scikit-Learn implements 3 different methods of evaluating models.\n",
    "\n",
    "1. The `score()` method. Calling `score()` on a model instance will return a metric assosciated with the type of model you're using. The metric depends on which model you're using.\n",
    "2. The `scoring` parameter. This parameter can be passed to methods such as `cross_val_score()` or `GridSearchCV()` to tell Scikit-Learn to use a specific type of scoring metric.\n",
    "3. Problem-specific metric functions. Similar to how the `scoring` parameter can be passed different scoring functions, Scikit-Learn implements these as stand alone functions.\n",
    "\n",
    "The scoring function you use will also depend on the problem you're working on.\n",
    "\n",
    "Classification problems have different evaluation metrics and scoring functions to regression problems.\n",
    "\n",
    "Let's look at some examples.\n",
    "\n",
    "### General model evaluation with `score()`\n",
    "\n",
    "We've already seen a quick and easy way to evaluate a machine learning model.\n",
    "\n",
    "Each model instance provided by Scikit-Learn comes with a `score()` method that we can use to generate a metric for how accurate the models predictions are compared to the actual test data labels.\n",
    "\n",
    "Let's review the heart disease dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(69)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a trained model, we can simply use the `score()` method and pass along the test data (meaning the data the model has never seen before) to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `score()` method may differ for different type of machine learning models.\n",
    "\n",
    "For instance, a `RandomForestClassifier`'s `score()` method uses mean accuracy between the prediction vs the test label as its score method.\n",
    "\n",
    "A model which predicts everything 100% correct would receive a score of 1.0 (or 100%).\n",
    "\n",
    "Using the `score()` method, we can see that our model currently has a score of 0.8524, or 85.24%.\n",
    "\n",
    "Let's try and `score()` a regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8081169165695959"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(69)\n",
    "\n",
    "X = california_df.drop(\"target\", axis=1)\n",
    "y = california_df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we can call the `score()` method in pretty much the same way, but there's actually a subtle difference to how the `score()` method works behind the scenes.\n",
    "\n",
    "A `RandomForestRegressor` model uses a different metric to score the model's accuracy. Specifically, the metric used for regression models is the coefficient of determination or [R^2 (pronounced R-squared)](https://en.wikipedia.org/wiki/Coefficient_of_determination).\n",
    "\n",
    "### Evaluating a model using the `scoring` parameter\n",
    "\n",
    "The `score()` method is one way to quickly asses the performance of a machine learning models, providing some default evaluation metric that can work across most types of machine learning models.\n",
    "\n",
    "If you want to take a step up from using `score()`, Scikit-Learn also offers a variety of other methods for evaluating your machine learning model.\n",
    "\n",
    "For instance, depending on the problem you're working on you might want to use a custom `scoring` parameter to help evaluate your model.\n",
    "\n",
    "You can then use the custom scoring parameter with Scikit-Learn's [`cross_val_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) or [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html).\n",
    "\n",
    "Let's compare the difference between using `score()` and `cross_val_score()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(69)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using score()\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81967213, 0.86885246, 0.78688525, 0.8       , 0.78333333])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using cross_val_score()\n",
    "cross_val_score(clf, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and break down what's happened here.\n",
    "\n",
    "You might notice that `cross_val_score()` returns an array of values instead of only a single number like `score()`.\n",
    "\n",
    "This is because `cross_val_score` uses a parameter called `cv` which determines its cross-validation splitting strategy.\n",
    "\n",
    "By default, `cv` uses a 5-fold cross-validation strategy.\n",
    "\n",
    "Now what does all this mean?\n",
    "\n",
    "This visual diagram might be able to help:\n",
    "\n",
    "![Normal Train-Test Split vs 5-fold Cross-Validation](./img/sklearn_cross-validation.png)\n",
    "\n",
    "Figure 1.0 represents the usual train-test split we're used to working with. By setting a `test_size` of `0.2` (or 20%), it means that we are training the model using 80% of the samples, while the remaining 20% are solely for validation and not used for the model to learn anything.\n",
    "\n",
    "This also means depending on what 80% is used to train on and what 20% is used to evaluate the model, it may achieve a score which doesn't reflect the entire dataset. For example, if a lot of easy examples are in the 80% training data, when it comes to test on the 20%, your model may perform poorly. The same goes for the reverse.\n",
    "\n",
    "Figure 2.0 shows 5-fold cross-validation, a method which tries to provide a solution to:\n",
    "\n",
    "1. Not training on all the data\n",
    "2. Avoiding getting lucky scores on single splits of the data\n",
    "\n",
    "Instead of training only on 1 training split and evaluating on 1 testing split, 5-fold cross-validation does it 5 times. On a different split each time, returning a score for each.\n",
    "\n",
    "Why 5-fold?\n",
    "\n",
    "The actual name of this setup K-fold cross-validation, Where K is an abitrary number. 5-fold cross-validation is simply the default used by `cross_val_score()` starting from Scikit-Learn version 0.22 onwards.\n",
    "\n",
    "Figure 2.0 is what happens when we run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80327869, 0.90163934, 0.80327869, 0.8       , 0.8       ])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, X, y, cv=5) # cv is equivalent to K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By getting 5 different scores instead of 1, we can have a wider perspective when it comes to evaluating our model.\n",
    "\n",
    "We can also simple take the mean of these 5 scores to get a singular result.\n",
    "\n",
    "Let's compare the average `cross_val_score()` with our usual `score()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8524590163934426, 0.8249180327868852)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(69)\n",
    "\n",
    "clf_single_score = clf.score(X_test, y_test)\n",
    "clf_cross_val_score = np.mean(cross_val_score(clf, X, y))\n",
    "\n",
    "clf_single_score, clf_cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the mean score returned by `cross_val_score()` is slightly lower than the score returned by `score()`, but we can be much more confident on the accuracy of the cross-validated metric.\n",
    "\n",
    "But wait, where is the `scoring` parameter we're supposed to be talking about?\n",
    "\n",
    "By default, the `scoring` parameter is set to `None`, meaning we haven't actually used it yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83606557, 0.86885246, 0.80327869, 0.85      , 0.78333333])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, X, y, scoring=None) # default scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When scoring is set to `None` (by default), it uses the same metric as `score()` for whatever model is passed to `cross_val_score()`.\n",
    "\n",
    "In our case, we're using a `RandomForestClassifier` model which uses mean accuracy as the default `score()` metric.\n",
    "\n",
    "You can change the evaluation score `cross_val_score()` uses by changing the `scoring` parameter.\n",
    "\n",
    "For different problems using different kinds of models, you might have to use different evaluation scores.\n",
    "\n",
    "The [Scikit-Learn documentation](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) outlines a vast range of evaluation metrics for different problems, but let's have a look at a few.\n",
    "\n",
    "### Classification model evaluation metrics\n",
    "\n",
    "Scikit-learn offers a variety of evaluation metrics for classification problems. Here are the most common metrics/methods you're most likely to come across:\n",
    "\n",
    "1. Accuracy\n",
    "2. Area under ROC curve\n",
    "3. Confusion matrix\n",
    "4. Classification report\n",
    "\n",
    "Using the classification code from above, let's have a look at each of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(69)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy\n",
    "\n",
    "Accuracy is the default metric for the `score()` function within each of Scikit-Learn's classifier models, and is the one we're already used to working with by now.\n",
    "\n",
    "It's probably the metric you're most likely to see being used in classification problems, but there can be quite a few situations where other metrics might make more sense to use.\n",
    "\n",
    "Scikit-Learn returns accuracy as a decimal, but you can easily convert it to a percentage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart Disease Classifier Accuracy: 85.25%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Heart Disease Classifier Accuracy: {clf.score(X_test, y_test) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Area Under Receiver Operating Characteristic (ROC) Curve\n",
    "\n",
    "The length of its name might sound intimidating, but you'll also see this referred to as Area Under Curve (AUC).\n",
    "\n",
    "In a nutshell, the Receiver Operating Characteristic (ROC) curve is a comparison of true postive rate (tpr) versus false positive rate (fpr).\n",
    "\n",
    "For clarity:\n",
    "\n",
    "- True positive = model predicts 1 when truth is 1\n",
    "- False positive = model predicts 1 when truth is 0\n",
    "- True negative = model predicts 0 when truth is 0\n",
    "- False negative = model predicts 0 when truth is 1\n",
    "\n",
    "Scikit-Learn lets you calculate the information required for a ROC curve using the [`roc_curve`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03448276, 0.03448276,\n",
       "       0.03448276, 0.06896552, 0.06896552, 0.10344828, 0.10344828,\n",
       "       0.13793103, 0.13793103, 0.17241379, 0.17241379, 0.31034483,\n",
       "       0.34482759, 0.37931034, 0.44827586, 0.55172414, 0.62068966,\n",
       "       0.65517241, 0.72413793, 0.79310345, 0.89655172, 1.        ])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Make predictions with probabilities\n",
    "y_probs = clf.predict_proba(X_test)\n",
    "\n",
    "# Keep only the probabilities for positive predictions\n",
    "y_probs_positive = y_probs[:, 1]\n",
    "\n",
    "# Use roc_curve to calculate fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs_positive)\n",
    "\n",
    "# Check the false positive rate (fpr)\n",
    "fpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at these on their own doesn't make much sense. It's much easier to see their value visually.\n",
    "\n",
    "Scikit-Learn doesn't have a built-in function to plot a ROC curve, but we can always make our own function to plot these kinds of values visually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    \"\"\"\n",
    "    Plots a ROC curve given the false positve rate (fpr) and \n",
    "    true postive rate (tpr) of a classifier.\n",
    "    \"\"\"\n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, color=\"#fdab58\", label=\"ROC\")\n",
    "    # Plot simple line with no predictive power (baseline)\n",
    "    plt.plot([0, 1], [0, 1], color=\"#588dfd\", linestyle=\"--\", label=\"Guessing\")\n",
    "    # Customize the plot\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot might seem a bit confusing looking at it for the first time, but we can infer that our model seems to be doing a far better job than guessing.\n",
    "\n",
    "If you want to quantify how good your model is performing, you can use the Area Under Curve (AUC). Scikit-Learn implements a function to caculate this called [`roc_auc_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score).\n",
    "\n",
    "The maximum ROC AUC score you can achieve is `1.0` and generally, the closer to `1.0`, the better the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9504310344827586"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, y_probs_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having an `roc_auc_score` of `1.0` means your model only predicts true positives and no false positives, thus literally making perfect predictions.\n",
    "\n",
    "Looking at this using the plotting function from earlier, the ROC curve would run along the top left corner of the plot.\n",
    "\n",
    "You can see this by creating a ROC curve using only the `y_test` labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_test)\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An `roc_auc_score` of `1.0` is the most ideal score, but it is also unlikely.\n",
    "\n",
    "In a nutshell, the main takeaways are:\n",
    "\n",
    "- ROC curves and AUC metrics are evaluation metrics for binary classification models (a model which predicts one thing or another, such as heart disease or not).\n",
    "- The ROC curve compares the true positive rate (tpr) versus the false positive rate (fpr) at different classification thresholds.\n",
    "- The AUC metric tells you how well your model is at choosing between classes (for example, how well it is at deciding whether someone has heart disease or not). A perfect model will get an AUC score of 1.\n",
    "\n",
    "Here are some great resources for learning more about ROC:\n",
    "\n",
    "- [ROC and AUC, Clearly Explained!](https://www.youtube.com/watch?v=4jRBRDbJemM) by StatQuest\n",
    "- [Scikit-Learn's ROC documentation](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html) (contains code examples)\n",
    "- [How the ROC curve and AUC are calculated](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc) by Google's Machine Learning team\n",
    "\n",
    "#### [Confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix)\n",
    "\n",
    "Another metric commonly used for evaluating classification models is using a confusion matrix.\n",
    "\n",
    "A confusion matrix is a specific table layout that allows visualization of the performance of an algorithm, each row representing the instances in an actual class while each column represents the instances in a predicted class, or vice versa. The name stems from the fact that it makes it easy to see whether the system is confusing two classes (i.e. commonly mislabeling one as another)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25,  4],\n",
       "       [ 5, 27]], dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this is probably easier visualized.\n",
    "\n",
    "One way to do it is with `pd.crosstab()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted Label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted Label   0   1\n",
       "Actual Label           \n",
       "0                25   4\n",
       "1                 5  27"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test,\n",
    "            y_preds,\n",
    "            rownames=[\"Actual Label\"],\n",
    "            colnames=[\"Predicted Label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An even more visual way is with Seaborn's [`heatmap()`](https://seaborn.pydata.org/generated/seaborn.heatmap.html) plot.\n",
    "\n",
    "If you've never heard of Seaborn, it's a library which is built on top of Matplotlib. It contains a bunch of helpful plotting functions.\n",
    "\n",
    "And if you haven't got Seaborn installed, you can install it into the current environment using:\n",
    "\n",
    "```sh\n",
    "# Install Seaborn in the current Jupyter Kernel/Conda environment\n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} seaborn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, y_preds)\n",
    "\n",
    "sns.heatmap(conf_mat);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot could use some added communication to let viewers know exactly what's going on.\n",
    "\n",
    "Let's add some customizations and make it into a reusable function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_conf_mat(conf_mat):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix using Seaborn's `heatmap()` function.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(3, 3))\n",
    "    ax = sns.heatmap(conf_mat,\n",
    "                     annot=True, # Annotate the boxes\n",
    "                     cbar=False) # Remove the color bar on the side\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\");\n",
    "\n",
    "plot_conf_mat(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with ROC curves before, an ideal model only has true positives and true negatives. This means the top right and bottom left squares in the confusion matrix would both have a value of 0.\n",
    "\n",
    "Now, why did we name our function `plot_conf_mat()` instead of `plot_confusion_matrix()`?\n",
    "\n",
    "Scikit-Learn has an implementation of plotting a confusion matrix called [`plot_confusion_matrix()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html#sklearn.metrics.plot_confusion_matrix), however, the documentation also says this function is deprecated.\n",
    "\n",
    "As such, trying to import it might return an error.\n",
    "\n",
    "You can try to use it but beware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2479027f4f0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAAEWCAYAAAAw6c+oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAtaklEQVR4nO3de1hU1d4H8O/McGcAAQ0VAYnUvIeRSpqKBl46maGob4hHUETzQl7SLLuc8mR4zWtlaacMC0zteLykkembnsxX5dSpUEEQiVsKJgy3YWb2+wcyNQ4wmxHmxvdznv2ch7XXrP0b1F9r7bXW3hJBEAQQEVGzSc0dABGRtWICJSIyEhMoEZGRmECJiIzEBEpEZCQmUCIiIzGBElGrEzS/mzuEViGxhXWgqdcSoVDdNHcYLSrugWTsyoo2dxit4kS4h7lDaBWf5GzHtMBnzR1Gi2rv64W3T69qkbZUJVMATVHTlaQdYeed0iLXMwU7cwfQEhSqmyivLTZ3GC3OFr8TABTnKs0dQqspzr1h7hAsllpdAKjzm64k01hVUrKmWInIigl3/tcUiYHzloYJlIhMQgMBAjRN1mECJSJqgErQQCM0nUClBs5bGiZQIjIJNQRoDPQwDQ3xLQ0TKBGZhEZEAoWVJVCuAyUik9AIAtQGDs09rKrMyMhA7969UVSku1QqPDwcPXr00DtKS0u1df773/8iJiYGwcHBGDp0KDZs2IDa2lqD12QPlIhMQnPnaIrEyLazs7ORkJAAlUqlU15RUYG8vDwsWbIEAwcO1Dnn7u4OAMjNzcWMGTMQHByMt99+G1evXsXGjRuhUCjwyiuvNHldJlAiMgk1BKhbeAivUqmQkpKC9evXw97eXu/85cuXIQgCRo0ahaCgoAbb2LFjB9zc3LB9+3Y4ODhg+PDhcHJywqpVq5CQkAAfH59Gr88hPBGZhEoAag0cqmaO4C9cuIB169YhLi4OS5cu1TufkZEBR0dHdO3atdE2zpw5g7CwMDg4OGjLxowZA7VajdOnTzd5fSZQIjIJNSSijuYICgpCWloa5s+fD5lMpnf+8uXLaNeuHRYvXoyQkBAEBwdj0aJFuHGjbsdYVVUVCgsLERgYqPM5Ly8vyOVy5OTkNHl9DuGJyCQ0Qt1hqA4AFBYWQq1W65xzd3fX3res1759+ybbu3TpEm7evIlu3bohJiYG2dnZ2Lx5M6ZPn44DBw6gvLwcACCXy/U+6+rqCoVC0WT7TKBEZBIaET1M6Z3z0dHRyM/X3Tc/f/58LFiwoFnXXLlyJQRBQP/+/QEAISEhCAoKwjPPPIODBw9i+PDhAACJRD8uQRAglTY9SGcCJSKTEDNEr0+gycnJDfZAm6tfv356ZQ8//DDc3Nxw6dIlPPHEEwDQYE+zsrISbm5uTbbPBEpEJqESpKgVmu7RSe6c79Sp0z1fr7KyEkePHkXv3r3x4IMPassFQUBtbS08PT3h6uoKHx8f5Obm6ny2pKQECoVC797o3TiJREQmoYZU1NFSHB0dkZSUhK1bt+qUf/3116iurtauCx0yZAi++eYbKJV/PGbx2LFjkMlkemtH78YeKBGZRN0kUtNDeEOTTM0hk8kwd+5cvPXWW1i1ahVGjhyJK1euYMuWLRg1ahQGDRoEAJg1axYOHz6M2bNn469//SuuXbuGDRs2YPLkyejcuXOT12ACJSKTEDOJpDF6L1LDYmNjIZfL8fHHH2Pv3r3w8PDA1KlTdSajgoKCsGvXLqxZswYLFy6Ep6cnYmNjRU1YMYESkUmoIYXawD3QexnCR0ZGIjIyUq88KioKUVFRTX42JCQEqampzb4mEygRmYQGUmgMJEhD5y0NEygRmUStIIVS0N8t9GdSAz1US8MESkQmoYHE4D3Olr4H2tqYQInIJDQililxCE9E1AC1IGISiUN4IiJ9nEQiIjKSRgDUJlxIbwpMoERkErWCHWqFplOOofOWxrqiJSKrxUkkIiIjqQWJwSG8ofOWhgmUiEyibh2ooR4oEygRkR6NiGVMGi5jIiLSVyvIUGtgK6eh85aGCZSITKLucXYcwhMRNZsGEsMPVGYCJSLSJ+aVHS35Sg9TYAIlIpMQBKnBSSKBk0hERPrEvNbY0HlLwwRKRCZR91rjpmfZVeyBEhHp04gYwnMdKBFRA/g8UCIiIwkiXukh8B4oEZG+uoeJGOqBMoESEenRCCIW0jOBEhHpU4nYC6+ysr3w1nXH1kb88IoL/j1Drld+86wdzkxzw9FH2mFql9n4ebUzVBVNt1V2WYbD/dvh8janVoqWxBJqL+HQtR8xbUmRuUOxSPXvRDJ0WBPritYGXN/ngLx9jnrlN7+3w9l4OTS1QM9FVXh82jDk7nXE9wluEDQNt6VRAf95yQWCyrqGPbZIKhMg3H4B9g5W9lIfE1JDon2ocqMHJ5GoIYIayHzPCVe2N9xTzFjnDOdOGjz6UTlkTsCsntPws8On+GmVC26cscN9j6n0PpP1vhMUWdY15LFVUxf8BqhKzB2GRRMEw/c4BSv774/Ze6CHDh3CE088gX79+mHs2LH44osvzB1Si1PXAP87yQ1Xtjmjy5NKOPlo9M47eArwn6SE7E/51fuRWgB1w/S7lV2RIus9J3SbU92qsZNhXR+swv8kFkMin2fuUCxa/UJ6Q4c1MWu0R48exdKlSzFkyBBs27YNAwcOxPLly/Hll1+aM6wWp6mRQFUhwYD1Cjy0uhISme5/ZmWOwKAdCnSbrZsMb1+qGyA4d9JNuBoV8MNKV7QPVcH3SWXrBk9NksoELNmYh/Rv5YDTeHOHY9HqtnI2fXArZzNs2LABY8eOxYsvvggAeOyxx3D79m1s2rQJY8aMMWdoLcpOLiDsSBmkIn/blQVSHPv+G/z8pjPcuqnR8fFanfNXdzqhIleGkM23Iait656RrZky7zf4Btbgb3FdMXiquaOxbLa4ldNs0ebl5eH69euIiIjQKR89ejSys7ORl5dnpshankQK0clT+bsEJ8I9sC5uOzRKCXq/WAnZn+acyrOkyHzHCT2XVsK5o5XdMLIxAd2r8cyiYrz/emfcLHQwdzgWT3NnJ5Khw5qYLYFmZ2cDAAIDA3XKAwICAAA5OTkmj8kiSIAB6xRY9tF8yO9X4/tZchQcswdQNxH1n5dc4TlAhYAoDt3NSSoVsGTjdfx8zhVH93ibOxyroBZgeBbeyvoEZhvCl5eXAwDkct31kK6urgAAhUIhuq24B5JbLjAT+D/7Z+Hj0gGJPf/WcIXBdf83bNJgxPddgryNKiQ99y4+e+sAKq+kYuO3b6Bjh/sAADeqS3ACyxDsMgWTOzwFNy85pFLLHgYlNrIsy5oIivcgKDIg8d6N46oudYXquvWfMa88ielJswBJO0gklv1nYUp8oHILEu6sV5BIJA2WNycJ7MqKRnltccsF18rKat1RW1mATRmPN1onsWca3r32BBwfdUbhJ05Y++9wnD/gilqlPeYPWqFXP3XdQaSuO4iRx2/DxdeyM9Sh3p7mDuGerfk8C/0frYVQMkn/ZMUHECo+wPSBPVH8q3UP7X0COuCTnO0t0ha3crYgNzc3APo9zYqKCp3zbYEiW4rvE+QIiqtB1/+p0TmnrpAAEgFSBwG9nq9CbZnuTH1NiRT/We4K3/E16DJeCcf2lp08bcWOv3WGWzu1TlnSl89CuL0UaXs9kfa5J0pvcJn1n6lgeJZdZf6Vlc1itj/h+nuf169fR48ePbTlubm5OufbAhd/DVQKCXJTHeA/sQbSO52WygIpCr9ygHeICnauQLvear3PVubX/YVz6aJBh1D9xfbUOrL+66JfaD8AAFB43QHp37adDoBYtjiEN1u0AQEB6NKli96az+PHj6Nr167o3LmzmSIzPakd0PvFKpRfscO/Z7jh2h5H7H59L05PcQMkAnq/VGnuEInumUb4Yxjf+GHuKJvHrGOMefPmYcWKFfDw8MCIESNw4sQJHD16FBs3bjRnWGbR5UklpPYCru50wi9rnJErPwzvR1TokVgFeVcOy8n6iVmmZG3LmMyaQCMjI6FUKrFr1y7s3bsXfn5+SEpKwrhx48wZVqsb9VVZg+Wdx9Si85i6RfOJPT9vcpKpnouvBn/5+VaLxkfGkdh1QUTn/uYOw2JxEqkVTJ06FVOncgsHka0TRCRQgQmUiEifSiOFSmNgFt7AeUvDBEpEJsF7oERERuIQnojISBoYniSytvUmTKBEZBKchSciMpJGI4XawCSRhpNIRET6OIlERGQkDuGJiIwkCBKDs+w2MwtfUFBgVINt6SEgRCRem+qBjhw5Uu9hx2JkZGTcU0BEZKMEET1MW3ka07x584xKoEREDVELEqg1TecUta30QBcsWGDKOIjIxnEWHsDly5dx8uRJFBQUYPr06XBxccGVK1cwfPjw1oiPiGxEm5pEasgbb7yBPXv2QBAESCQSjBkzBmVlZUhMTMSIESOwadMmODo6Gm6IiNocW9wLL3rZ/8cff4zk5GTMnj0bqamp2rdnhoaGYsaMGTh58iTef//9VguUiKybIIg7rInoBPrZZ59hzJgxWLRoEfz8/LTl7u7ueOGFFzB+/HgcOnSoVYIkIutXP4Q3dBgrIyMDvXv3RlFRkU756dOnMXHiRPTv3x8jR47Erl279D773//+FzExMQgODsbQoUOxYcMG1NbWGrym6ASal5eHwYMHN3o+JCQEhYWFYpsjojZGfWcvvKHDGNnZ2UhISIBKpftm2osXL2LOnDm4//77sWXLFjz55JNYs2YNdu7cqa2Tm5uLGTNmwNHREW+//Tbi4uLw4YcfYvXq1QavK/oeqKenp15m/7PMzEx4eHiIbY6I2hgBhofozR3Bq1QqpKSkYP369bC3t9c7v3nzZvTq1Qtr164FAAwbNgwqlQrvvvsuYmJi4ODggB07dsDNzQ3bt2+Hg4MDhg8fDicnJ6xatQoJCQnw8fFp9Pqi0314eDj27NmDrKwsbVn9OtFTp04hJSUFYWFhor84EbUtgiBmGN+8Ni9cuIB169YhLi4OS5cu1TlXU1OD8+fPIyIiQqd89OjRKCsrw8WLFwEAZ86cQVhYGBwcHLR1xowZA7VajdOnTzd5fdE90MTERJw7dw6RkZHo1q0bJBIJtm7diqSkJFy6dAm+vr5ITEwU2xwRtTVi7nHeOV9YWAi1Wq1zyt3dHe7u7jplQUFBSEtLg7e3N/bv369zLi8vD7W1tQgMDNQpDwgIAADk5OSgf//+KCws1Kvj5eUFuVyOnJycJsMVnUDd3d2RmpqKDz74AMePH4ejoyN++OEH+Pr6IjY2FgkJCRzCE1GjBBgeotefj46ORn5+vs65+fPn623wad++faNtlZeXAwDkcrlOuaurKwBAoVA0Wqe+nkKhaDLeZq0DdXZ2xoIFC7hLiYiaTdBIIBjYyll/Pjk5ucEeaLOud+d+QGNb0qVSaZN1BEGAVNr0Xc5m70TKzMzEyZMnkZ+fD5lMBn9/f4wcOVJnaRMR0d2asxOpU6dO93w9Nzc3ANDrRdb/7Obmpu15NtTTrKys1LbRGNEJVKVS4eWXX8YXX3yhzdr1kpKSMGvWLCxevFhsc0TUxohZKN+SC+n9/f0hk8lw/fp1nfL6nwMDA+Hq6gofHx/k5ubq1CkpKYFCodC7N3o30bPw27dvx4EDBzBhwgQcOHAA58+fx/nz55GamorRo0fj/fffx+7du8U2R0RtTGsvpL+bo6MjQkJCcPz4cZ1O37Fjx+Dm5oY+ffoAAIYMGYJvvvkGSqVSp45MJsPAgQObvIboHuiBAwcwduxYvcWl/fr1w8aNG1FVVYXdu3cjJiZGbJNE1KZItLPsTdZpQXPnzkVsbCwWLVqEp59+Gunp6di5cyeWLFkCZ2dnAMCsWbNw+PBhzJ49G3/9619x7do1bNiwAZMnTzb4gHjRPdDS0lI88sgjjZ4fMWIEiouLxTZHRG2MOfbCh4aGYsuWLbh69SrmzZuHf/3rX1i2bBni4+O1dYKCgrBr1y5UVlZi4cKF+PDDDxEbG4uXXnrJYPuie6D9+/fHt99+i2eeeabB8z/++CN69uwptjkiamOaMwtvjMjISERGRuqVh4eHIzw8vMnPhoSEIDU1tdnXFP1OpPj4eCxcuBBLlizBzJkzERgYCIlEgvz8fKSmpvJpTETUtOYsBLUSzXonkiAIOHz4MI4cOaJXDgCTJk3iO5GIqGHN2IlkLfhOJCIyjbbUA+VuIyJqebbVKWv2TqSysjJUVlZCo9Foy9RqNSoqKnD27FnMmDGjJeMjIlshANCIqGNFRCfQ4uJiLFu2DOfOnWuyHhMoETVIELEO1Fbugd5tzZo1OHfuHMaNGwcHBwccOHAACQkJKC0txfHjx1FTU4N//OMfrRgqEVkzU2/lNAXRC+m/++47TJgwAevXr8dLL70EiUSCxx57DG+88Qa++OILuLi44KuvvmrNWInImgkiDysiOoGWlZVhwIABAOqende5c2f89NNPAOqenBIVFYUTJ060TpREZP3qh/CGDisiegjv4eGBqqoq7c/+/v64fPmy9mc/P78m35lERG2bRKg7DNWxJqJ7oAMGDMD+/fu1T3Du3r07vv/+e9TU1ACoey1oQ091JiICAGgk4g4rIjqBzp07Fzk5ORg+fDhu3bqFyZMno7i4GJGRkYiPj0dqaipGjBjRiqESkdWzofufQDMSaK9evZCamorx48fD09MTQUFB2LZtG6qrq5Geno6xY8di2bJlrRkrEVkzG5xEatZC+h49euC1117T/jxixAj2OolInLa0lfPupzGJZegBpETURrWlhfQNPY1JDD6NiYgaJGIW3mZ6oHwaExG1qLY0hLempzGdiGiH4txac4fRohLVwKE+XuYOo1UcK0g3dwit5ljBf8wdQsuS+bZYU7a4DrTZT2MiIjJKW7oHSkTU4qysh2kIEygRmUZbugdKRNSSJJq6w1Ada8IESkSmwR4ocPnyZZw8eRIFBQWYPn06XFxccOXKFQwfPrw14iMiG9HmZ+HfeOMN7NmzB4IgQCKRYMyYMSgrK0NiYiJGjBiBTZs2wdHRsbViJSJrZoOz8KIfJvLxxx8jOTkZs2fPRmpqqvZd8KGhoZgxYwZOnjyJ999/v9UCJSIrZ4MPExGdQD/77DOMGTMGixYtgp+fn7bc3d0dL7zwAsaPH49Dhw61SpBEZP0k+GMY3+hh7iCbSXQCzcvLw+DBgxs9HxISgsLCwhYJiohsT/0svKHDmoi+B+rp6dnkKzsyMzPh4eHRIkERkQ2ywVl40T3Q8PBw7NmzB1lZWdqy+oeNnDp1CikpKQgLC2v5CInINtjgPVDRPdDExEScO3cOkZGR6NatGyQSCbZu3YqkpCRcunQJvr6+SExMbM1YiciK2eIyJtE9UHd3d6SmpiI+Ph5KpRKOjo744YcfUFVVhdjYWOzbtw9eXrb59CAiooY0ax2os7MzFixYYFWPuiMiC2GD90BFJ1Cxr/jgKz2IqCESQcReeFtNoGJf8cFXehBRg9pyD7ShV3yo1WrcvHkTp06dgqurK4f2RNS4tvROpLs1lRwVCgWmTp2K3NzcFgmKiGyQDfZARc/CN0UulyMqKgopKSkt0RwR2SCD2zjF9FAtTIs9D7S2tha3bt1qqeaIyNZo7hyG6liRe56FVyqVyMjIwK5du9CzZ88WC4yIbIstLqRvkVl4QRDg6OiIJUuWtFhgRGSDrCxBGiI6gc6fP7/BcqlUig4dOmDUqFHciUREjbPBSSTRCbRTp054+OGH0bVr11YMh4hslS0O4UXPwr/55ps4fPhwa8ZCRLasLT+NydnZme87IiKjtenXGr/22mtYuXIlampqMHToUHh5eUEmk+nV4154ImpQW74HunjxYqhUKmzZsgVbt25ttB73whNRQyQw/M4ja3snkugEGh8fL+phIkREDWpLPdAVK1Zg6tSp6N+/P4Cm98ITERlS/1ZOQ3WsSaOz8AcOHMD169dNGQsR2bK2PAtPRHQv2vQsPBHRPWlL90AB4Pz581Cr1c1qcMKECfcSDxHZqrb2QOXU1FSkpqaKakgQBEgkEiZQImpYW+uBTp48GQ899JCJQiEiW2aLe+GbTKAhISF48sknTRULEdkyAYYfmGxLCZSIqKW0uR4oEVGLaYV7oCqVCgMGDEBNTY1OuYuLC9LT0wEAp0+fxsaNG5GVlQVvb29MmzYNcXFxzbtQIxpNoE8//TT8/f1b5CJERBJBgERoOkMaOn+3nJwc1NTUICkpSedZxVJp3R6hixcvYs6cORg7diwSExNx4cIFrFmzBoIgYObMmc3+DndrNIGuXr36nhsnItJqhR7opUuXIJVKMXr0aDg7O+ud37x5M3r16oW1a9cCAIYNGwaVSoV3330XMTExcHBwaN4F79IirzUmIjKkNV5rnJGRAX9//waTZ01NDc6fP4+IiAid8tGjR6OsrAwXL168l68DgPdAichEJIKIrZx3EmhhYaHeJh53d3e4u7vrlF2+fBkODg6YOXMmLl68CDs7O4wdOxbLli1DUVERamtrERgYqPOZgIAAAHXD/8GDB9/Td2ICJSLTaMYQPjo6Gvn5+Tqn5s+fr/dUuEuXLkGhUCAqKgpz5szBTz/9hC1btiAnJweLFy8GAMjlcp3PuLq6AgAUCoXRX6UeE6iF2XzoCnoEV0JT1B3H/vT359vDHlg1O7DxD1Kr2rjUDwU5jli7L0un/PcSGT5c3Rlnj7tDWTMdD/R5AHEvFqDnw5U69YquO2DH3zrjh+/q/jEPerwMs1/NRzvv5m2VtmbNWcaUnJzcYA/0bhs3boSHhwd69OgBAHjkkUfg7e2N559/HmfOnKlrs5HnGNdPNN0LJlCLIsCvWzXOHPXA0Kkr8db0Ldozv/16bze7yXhf7vHCl3u80S9Ut8dSqZBi6dPdUFJsj8j4G3Dzi8c/N7+H5VEPYPORK+j6YDUAoKxUhmWTHkBtrQSTn/0NarUEn79zH3J+ccbmI1dg72Blix+N1YweaKdOnUQ1OXDgQL2yESNG6Px8d0+z/mc3NzdR12gKE6gF8fFTwkWuwXfH3fFY7FM4sT/Z3CG1aWo18OkmH3yyvmOD51O23odfr9b1SvsOroC04xMYFrYUMwb3Qur2+7Bsc93zdPft6IAbhfZ478Ql+HerW6/4YHAFVkx9AF/t9cS46FKTfSdzaumF9CUlJThx4gQGDx4MPz8/bXl1dd1/uLy9vSGTyfSea1z/8933Ro1hMbPwGRkZ6N27N4qKiswditl07VH3B38908nMkZCyWoJ5o3tg97pOGDXpFtp3UuqcFwQgba8XBo4qQ9/BFdpyr/tUiH8lH30G/dHrOfVPT/QLVWiTJwAMGKZAl6BqnPqnZ+t/GUuhESAxcEAjPoNKJBK88sor+OSTT3TKjxw5AplMhkcffRQhISE4fvw4hD+tLz127Bjc3NzQp0+fe/5KFtEDzc7ORkJCAlQqlblDMauA7nUJNO9OAnV0VqOmSv/Np9T6lDVSVJZL8eK71zB8/O+YPrCXzvniPAfcLHRA1NzfANQl1CpFFRwBPDmjRFuv/HcZCnMdMfSJ3/Wu8UDfKpz7Wv++ns1q4XWgXl5eiI6Oxu7duyGXyxESEoILFy7g3XffRXR0NAICAjB37lzExsZi0aJFePrpp5Geno6dO3diyZIlDS59ai6zJlCVSoWUlBSsX78e9vb25gzFIgQ8WI2Kcilmv5oPTXEwDmZVoOCaA/6R1AmnDrahnooFcHFT48MzGZA18i8kP9sRANCuvQrvv94ZR5K9UVk+HZ269sSc1/IxOKIMAFBSVPf3un3HWr02vHxqUVkuQ0WZFK7uVvYodiM0ZxmTWMuXL4ePjw/27duHHTt2wMfHBwsXLsSsWbMAAKGhodiyZQs2b96MefPmwcfHB8uWLWv9rZymcOHCBaxbtw4zZ86Ej48PVq5cac5wzC6gezVc3TSQe6gh8UjCutgkTJh1Ay++kws7ewFf7/Myd4hthlSKJm9wKcrqRgYfre0EOzsBc1/Ph8xrDfa+tRZ/iwvE3/dcxYBhClQq6hpxdNbPHI5OdWXVlW0jgbbGTiR7e3vEx8cjPj6+0Trh4eEIDw9vXsMimfUeaFBQENLS0jB//nzIZByqHk32xtYXfbFqdiAkThE4nuqN58Z3R8E1B8xaWQCptI3M1lqBWmXd0piK2zJs+GcmIqaUIjxmONbtz4Krhxofru4MABA0dfWaeiO4xGJmIlpXa+xEMjez/tG1b98e3t7e5gzBohze3R7/+qiDTpmyWoqv93nC6z4V/O/cIyXzc3Kp6zEOGfc73Nr9sV5R7qHG4PDbyPzRGVUVUjjL687VVOv/U6svc5G3gd4nUHejWMxhRSxiEulefZK9zdwhtIqv1HWvUxEqkyGU/Q070l+HxCHYzFG1UbJnAYcOkHY8CgDo0DsTwIvwDEiAtONUbTVpx0x4BnwCQfgnalzPouMABwAzcKtiAaQdn9FpsvT225C3+w9c7r9swi9iPnwrp4Wadv88FOfeMHcY98S7oxKr92Tj1MF2SH67I75SpyJcNhkAMPf1XzFhJjDF/3XcumH9k23H8tPNHULzqXsByhxoiroBAAI6SGHv2AfXLu6EpuhlAHXJU1PUDYWXAuDg5AE39UDIqoGO/j2RefYjaIpe1Wky6/8eRLe+tdo2LZLMF9IOJ1ukKVt8oHIbufti+UqKHODirsbY6BK4yP8YEnborET45FL854zcJpKnrXBy0WBwxG18n+aOa5f/WLdbdN0BZ497IDTiNupv6w8ddxvp37rheqajtt7F/5Xj16tOGPHULVOHbkZihu/WlUFtogdqK7a95IvXdl3Dxn9mQqj4CP+TWITxM25Co5Jg64tdzB0e3WXWykL8+G85lk0KwoRZN+Hg9U8cePsBODppELuiUFsval4x0j73xAtTgjAx4QaUNRLs3e6Dbv0qMXJi20mg7IFSq/ruWDu8FhuI6kophPK1mDj7BjIuuGLRU92Ql8XdSZamo58Smw5lol9oBT5/5z4k/30f7u9dhY0HM9Ep4I+dS+281Vi3Pwv396rGx2s74sD7HfDomNtYlXwVDo5WljHuhSDysCLsgVqY74574LvjHvhKnYpJvpPNHQ7d8fG5Xxos7xSgxMod1wD8cQ+0IX4P1GDVJ9mtFZ5VYA+0FUVGRuLy5cvo2LHhBzcQkZVTC+IOK8IeKBGZhC32QJlAichExCyUt64MygRKRKYhZqumdeVPJlAiMpFWeJiIuTGBEpFJSNSAxMAkkcTKXhHFBEpEJiERBEgM3AM1dN7SMIESkWlwCE9EZCzOwhMRGYXrQImIjCXmgcm8B0pEpE+iFkTMwjOBEhHp4yQSEZFxuIyJiMhonIUnIjKO5s5hqI4VYQIlIpPgEJ6IyFgaAdAY6GJqmECJiPRxCE9EZBwJRAzhOYlERNQA7kQiIjISEygRkZHEvHWTWzmJiBogYhkTe6BERA3hEJ6IyEgCDK/ztK78yQRKRCbCHigRkZGYQImIjKTW1B2G6lgRJlAiMg1BU3cYqmNFmECJyET4PFAiIuNoYHgW3ro6oEygRGQinEQiIjISEygRkZHU6rrDUB0rwgRKRCbCSSQiIuNwCE9EZCTOwhMRGUnQQOBCeiIiI3ArJxGRkQSN4dcaswdKRNQATiIRERlH0AgQDPRABUOTTBaGCZSITIM9UCIiI2kEEcuYmECJiPQIGjUEA1s1BQ23chIR6RMEEQ9UZg/U5Nr7epk7hFbhE9DB3CG0DpmvuSNoPbb23aQdW6wp786eBieJvDt7ttj1TEEiCFaW8omILITU3AEQEVkrJlAiIiMxgRIRGYkJlIjISEygRERGYgIlIjISEygRkZGYQImIjMQESkRkJCZQC3Po0CE88cQT6NevH8aOHYsvvvjC3CGRSBkZGejduzeKiorMHQqZCBOoBTl69CiWLl2KIUOGYNu2bRg4cCCWL1+OL7/80tyhkQHZ2dlISEiASqUydyhkQtwLb0HCw8PRp08fbNy4UVv23HPP4fLlyzh69KgZI6PGqFQqpKSkYP369bC3t8fvv/+OU6dOoWPHlnsIB1ku9kAtRF5eHq5fv46IiAid8tGjRyM7Oxt5eXlmioyacuHCBaxbtw5xcXFYunSpucMhE2MCtRDZ2dkAgMDAQJ3ygIAAAEBOTo7JYyLDgoKCkJaWhvnz50Mmk5k7HDIxm3geqC0oLy8HAMjlcp1yV1dXAIBCoTB5TGRY+/btzR0CmRF7oBai/la0RCJpsFwq5R8VkaXhv0oL4ebmBkC/p1lRUaFznogsBxOohai/93n9+nWd8tzcXJ3zRGQ5mEAtREBAALp06aK35vP48ePo2rUrOnfubKbIiKgxnESyIPPmzcOKFSvg4eGBESNG4MSJEzh69KjOulAishxMoBYkMjISSqUSu3btwt69e+Hn54ekpCSMGzfO3KERUQO4E4mIyEi8B0pEZCQmUCIiIzGBEhEZiQmUiMhITKBEREZiAiUiMhITqIV44YUX0KNHD52jZ8+eGDBgAKKionDgwAGTxDFy5EjExMRof46JicHIkSOb3Y5CoUBpaWmLxVX/+7nXOi35OVO1R5aLC+ktzIoVK+Dp6Qmg7klMCoUCBw8exAsvvIBbt24hLi7OpPHMmTMHVVVVzfrMTz/9hLlz52LdunUYNGhQK0VGZH5MoBbm8ccfR5cuXXTKJk2ahHHjxmHbtm2YNm0aHBwcTBbPkCFDmv2ZK1eu4LfffmuFaIgsC4fwVsDJyQkjR46EQqFAZmamucMhojuYQK1E/YOW1Wo1gLp7lStXrsSLL76Ivn37YtiwYdp7junp6YiNjUVwcDCCg4MRFxeHH3/8Ua/NI0eO4KmnnkK/fv3wl7/8BWfPntWr09A90KtXryIxMRGDBg3Cww8/jJiYGJw/fx4AsGXLFqxYsQIAMH36dJ3PFhUVYdmyZRg8eDD69u2LCRMm4ODBg3rX/OmnnxAXF4fg4GA89thj+Pjjj435lQEAvvvuO8yaNQuDBg1C79698dhjj+GVV15BWVmZXt309HRMnDgRffv2RUREBP7xj3/o1RH7Haht4BDeCmg0Gpw7dw4ODg4ICgrSlh8+fBiBgYF46aWXcPPmTXh5eeHMmTNISEjAgw8+iMTERCiVSuzfvx/R0dH48MMPERISAgDYv38/VqxYgeDgYDz//PPIzc3FnDlzoNFo4Ovr22gs165dw+TJk2FnZ4dp06bBy8sLn332GWJjY5GcnIzw8HDcuHEDKSkpmDNnDvr27QsAKC4uRlRUFARBQExMDDw8PPD111/j+eefx2+//YZZs2YBADIzMxETEwN3d3c8++yzqK2txbZt27T/4WiO06dPIz4+HgMGDMDChQshkUhw5swZpKSkoLa2FqtXr9apHxcXh8cffxyRkZFIS0vD6tWrUV5ejgULFjTrO1AbIpBFWL58udC9e3fh559/FkpKSoSSkhLht99+E9LT04XExEShe/fuwptvvqmtHxYWJjz44INCbm6utkytVgujRo0Spk6dKqhUKm15RUWFEB4eLjz11FOCIAiCSqUSQkNDhYkTJwpKpVJbb9++fUL37t2FadOmacumTZsmhIWFaX9OTEwU+vXrJ1y7dk1bVlpaKjz88MPCwoULddo5e/aszvcbOHCgUFxcrPO9Fy9eLPTp00e4efOmIAiCsGDBAuGhhx4SCgoKtHWysrKEPn36CN27dxf1O6w3c+ZMISwsTKipqdGpN3nyZCE4OFjvc0lJSdoytVotTJ8+XejTp49QWlrarO9wdxxkuziEtzBPP/00QkNDERoaiqFDh2LKlCn4+uuvERMTgyVLlujU9ff3h7+/v/bnX375BXl5eXj88cdx+/ZtlJaWorS0FNXV1QgLC0NGRgaKiorw888/o6SkBJGRkbC3t9d+/qmnnoKHh0ejsWk0Gpw6dQrDhw/Xvi0UADw9PbFnzx6sXLmy0c+lpaUhJCQEdnZ22rhKS0sREREBpVKJM2fOQKPR4Ntvv8Xw4cPRqVMn7eeDgoIwdOjQZv8u33vvPezbt09n0u3WrVuQy+WorKzUq//nHqRUKsW0adOgVCrx73//W/R3oLaFQ3gLs3btWu2bHqVSKdzd3REUFARHR0e9ut7e3jo/178OZM2aNVizZk2D7RcWFqKoqAgAdJIvAMhkMp3EeLfff/8dlZWVDdbp3r17o5+7desWysvLkZaWhrS0tEbjqm//7rgA4P7778eJEycavUZDZDIZ8vLysGnTJmRlZeH69esoLi5usG67du3g5eWlU+bn5wcAyM/PF/0dqG1hArUwAwYM0FvG1Ji730Ou0WgAAImJiXjooYca/Mz999+vTSI1NTV65+vbaEj9fcjmviG0/nOjR4/G1KlTG6xTn6yMiasxn332GV599VUEBgYiJCQEERER6N+/P3bv3o1//etfOnXvfhsqoPtG1OZ+B2obmEBtSP3kj4uLCx599FGdcz/++CNu374NJycn7T/0a9eu6dQRBAH5+fno1q1bg+17enrCyclJ+6K7P9u5cydu3ryJ5cuX653z8vKCs7MzVCqVXlwFBQX45Zdf4OzsDE9PT8jlcr24AODXX39t9Hs3pKamBm+99RYGDRqEXbt2wc7uj7/qmzZt0qt/+/ZtKBQKyOVybVl9HP7+/qK/A7UtvAdqQ/r06YMOHTpg9+7d2tchA3XbKp977jmsWLECMpkMvXr1gq+vLz799FOdXUaHDx/GrVu3Gm3fzs4OQ4YMwalTp3SGq7dv38bOnTu1txDqe6j1vUY7OzsMGzYMp06dwqVLl3TafOuttzBv3jzcunULEokE4eHh+Pbbb3HlyhVtnV9//RUnT55s1u+iuroaVVVV6Nq1q07yzMjIwLlz5wAAKpVKW67RaPD5559rf1apVPjoo4/g4uKC0NBQ0d+B2hb2QG2Ivb09Xn75ZTz33HOIjIzEpEmT4OjoiL1796KgoADr1q3TJpOXX34Z8+bNw5QpUzBx4kQUFxcjOTkZ7dq1a/IaS5YsQVRUFKKiohAdHQ25XI7U1FRUVlbiueeeAwDtvcRPP/0UN2/exJNPPomlS5fi+++/R3R0NKKjo9G5c2ecPHkS33zzDaZMmaLt9SYmJuLkyZOIiYnBjBkzIJPJsHv3bri6ukKpVIr+XXh4eKB///7Yv38/5HI5AgMDkZmZib1792oTfEVFhXbSzNnZGZs3b0ZhYSH8/f1x5MgRpKen49VXX4WbmxsAiP4O1HYwgdqY0aNHY9euXXjnnXewfft2SKVSdOvWDe+88w7CwsK09cLCwvDee+9hy5Yt2LBhA3x8fPD3v/8dycnJTbYfFBSElJQUbNiwAR988AGkUin69euHpKQkbQIJDQ3F2LFj8c033+Ds2bOIiIiAv78/UlNTsXnzZm3C9fPzw4oVK3QeXtKpUyd8+umnWLNmDT744AM4ODggKioKQN2senNs2rQJq1evxr59+6BUKuHr64vZs2cjKCgICxYswNmzZzF69GgAgLu7O5KSkvDmm28iOTkZAQEBWLt2LcaPH69tT+x3oLaDL5UjIjIS74ESERmJCZSIyEhMoERERmICJSIyEhMoEZGRmECJiIzEBEpEZCQmUCIiIzGBEhEZiQmUiMhI/w+/LcBoWCOsNgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(clf, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _Deprecated since version 1.0:_ `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the following class methods: [`from_predictions`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay.from_predictions) or [`from_estimator`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay.from_estimator).\n",
    "\n",
    "Thankfully, Scikit-Learn recently released a new version 1.0, and its documentation also links us to other built-in methods we can use instead.\n",
    "\n",
    "1. [`sklearn.metrics.ConfusionMatrixDisplay.from_estimator(estimator, X, y)`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay.from_estimator) - this takes a fitted estimator (like our `clf` model), features (`X`) and labels (`y`), it then uses the trained estimator to make predictions on X and compares the predictions to y by displaying a confusion matrix.\n",
    "2. [`sklearn.metrics.ConfusionMatrixDisplay.from_predictions(y_true, y_pred)`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay.from_predictions) - this takes truth labels and predicted labels and compares them by displaying a confusion matrix.\n",
    "\n",
    "Let's take a quick look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_preds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(clf, X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report\n",
    "\n",
    "The final major metric you should consider when evaluating a classification model is a classification report.\n",
    "\n",
    "A classification report is more so a collection of metrics rather than a single one.\n",
    "\n",
    "You can create a classification report using Scikit-Learn's [`classification_report()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) function.\n",
    "\n",
    "Let's see it in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.83      0.86      0.85        29\\n           1       0.87      0.84      0.86        32\\n\\n    accuracy                           0.85        61\\n   macro avg       0.85      0.85      0.85        61\\nweighted avg       0.85      0.85      0.85        61\\n'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "classification_report(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formatting looks a bit wonky, because we actually need to pass it to the `print()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85        29\n",
      "           1       0.87      0.84      0.86        32\n",
      "\n",
      "    accuracy                           0.85        61\n",
      "   macro avg       0.85      0.85      0.85        61\n",
      "weighted avg       0.85      0.85      0.85        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It returns four columns: _precision_, _recall_, _f1-score_ and _support_.\n",
    "\n",
    "The number of rows will depend on how many different classes there are. But there will always be three rows labelled _accuracy_, _macro avg_ and _weighted avg_.\n",
    "\n",
    "Each term measures something slightly different:\n",
    "\n",
    "- **Precision** - Indicates the proportion of positive identifications (model predicted class 1) which were actually correct. A model which produces no false positives has a precision of 1.0.\n",
    "- **Recall** - Indicates the proportion of actual positives which were correctly classified. A model which produces no false negatives has a recall of 1.0.\n",
    "- **F1 score** - A combination of precision and recall. A perfect model achieves an F1 score of 1.0.\n",
    "Support - The number of samples each metric was calculated on.\n",
    "- **Accuracy** - The accuracy of the model in decimal form. Perfect accuracy is equal to 1.0, in other words, getting the prediction right 100% of the time.\n",
    "- **Macro avg** - Short for macro average, the average precision, recall and F1 score between classes. Macro avg doesn't take class imbalance into effect. So if you do have class imbalances (more examples of one class than another), you should pay attention to this.\n",
    "- **Weighted avg** - Short for weighted average, the weighted average precision, recall and F1 score between classes. Weighted means each metric is calculated with respect to how many samples there are in each class. This metric will favour the majority class (e.g. it will give a high value when one class out performs another due to having more samples).\n",
    "\n",
    "You might be tempted to ask: Why should we bother with all these? Isn't measuring the model's accuracy enough?\n",
    "\n",
    "Accuracy is a good metric to report, except when you have very imbalanced classes. Let's take a look at a basic example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.99990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.499950</td>\n",
       "      <td>0.99980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.99990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.99995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.499975</td>\n",
       "      <td>0.99985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>9999.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0.0  1.0  accuracy     macro avg  weighted avg\n",
       "precision     0.99990  0.0    0.9999      0.499950       0.99980\n",
       "recall        1.00000  0.0    0.9999      0.500000       0.99990\n",
       "f1-score      0.99995  0.0    0.9999      0.499975       0.99985\n",
       "support    9999.00000  1.0    0.9999  10000.000000   10000.00000"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disease_true = np.zeros(10000)\n",
    "disease_true[0] = 1 # only one case\n",
    "\n",
    "disease_preds = np.zeros(10000) # every prediction is 0\n",
    "\n",
    "pd.DataFrame(classification_report(disease_true,\n",
    "                                   disease_preds,\n",
    "                                   zero_division=0,\n",
    "                                   output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example represents a heavily imbalanced situation where only one case is positive over a total of 10,000 cases.\n",
    "\n",
    "You build a model, and find that it's 99.99% accurate... But all it really does is predict that no one has the disease, in other words all 10,000 predictions are false.\n",
    "\n",
    "If what you need is for the model to successfuly predict positive cases, this model won't be the right fit even though it has a 99.99% accuracy.\n",
    "\n",
    "This is such an example where you'd want to use other metrics such as F1 score, where you can see a comparison between positive and negative predictions.\n",
    "\n",
    "Here are some rules of thumb for evaluating classification models:\n",
    "\n",
    "- Accuracy is a good measure to start with if all classes are balanced (e.g. same amount of samples which are labelled with 0 or 1)\n",
    "- Precision and recall become more important when classes are imbalanced.\n",
    "- If false positive predictions are worse than false negatives, aim for higher precision.\n",
    "- If false negative predictions are worse than false positives, aim for higher recall.\n",
    "\n",
    "### Regression model evaluation metrics\n",
    "\n",
    "So far we've only looked at evaluating classification models. Scikit-Learn provides a different set of evaluation metrics for regression models. Here are some of the commonly used ones:\n",
    "\n",
    "1. **R<sup>2</sup> (pronounced r-squared)** or **coefficient of determination** - Compares your models predictions to the mean of the targets. Values can range from negative infinity (a very poor model) to 1. For example, if all your model does is predict the mean of the targets, its R<sup>2</sup> value would be 0. And if your model perfectly predicts a range of numbers it's R<sup>2</sup> value would be 1.\n",
    "2. **Mean absolute error (MAE)** - The average of the absolute differences between predictions and actual values. It gives you an idea of how wrong your predictions were.\n",
    "3. **Mean squared error (MSE)** - The average squared differences between predictions and actual values. Squaring the errors removes negative errors. It also amplifies outliers (samples which have larger errors).\n",
    "\n",
    "Let's see them in action using the housing dataset from earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(69)\n",
    "\n",
    "X = california_df.drop(\"target\", axis=1)\n",
    "y = california_df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R<sup>2</sup> Score (Coefficient of Determination)\n",
    "\n",
    "Using the default `score()` method, we can get the R<sup>2</sup> metric for our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8081169165695959"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R<sup>2</sup> can also be calculated using Scikit-Learn's [`r2_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score) function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8081169165695959"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "r2_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An R<sup>2</sup>score of 0.0 means that the model only predicts the mean of the `y` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_mean = np.full(len(y_test), y_test.mean())\n",
    "\n",
    "r2_score(y_test, y_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A perfect model would get an R<sup>2</sup> score of 1.0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your regression models, you'll want to maximize R<sup>2</sup> while minimizing MAE and MSE.\n",
    "\n",
    "#### Mean Absolute Error (MAE)\n",
    "\n",
    "Scikit-Learn's [`mean_absolute_error()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html) function calculates the MAE for a regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3270582259932172"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_preds)\n",
    "\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model achieved an MAE of `0.3270`. This means, on average our model's predictions are `0.3270` units away from the actual value.\n",
    "\n",
    "For a more visual example, let's compare our model's predictions with the actual values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual values</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.645</td>\n",
       "      <td>1.719890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5120</th>\n",
       "      <td>1.174</td>\n",
       "      <td>1.669390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11002</th>\n",
       "      <td>2.866</td>\n",
       "      <td>3.005181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19854</th>\n",
       "      <td>0.686</td>\n",
       "      <td>0.585970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5427</th>\n",
       "      <td>4.500</td>\n",
       "      <td>2.876230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18956</th>\n",
       "      <td>0.942</td>\n",
       "      <td>1.222180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>1.188</td>\n",
       "      <td>1.236010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10090</th>\n",
       "      <td>2.020</td>\n",
       "      <td>2.568470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2527</th>\n",
       "      <td>0.710</td>\n",
       "      <td>0.764750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>1.948</td>\n",
       "      <td>1.966140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4128 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       actual values  predictions\n",
       "9995           1.645     1.719890\n",
       "5120           1.174     1.669390\n",
       "11002          2.866     3.005181\n",
       "19854          0.686     0.585970\n",
       "5427           4.500     2.876230\n",
       "...              ...          ...\n",
       "18956          0.942     1.222180\n",
       "1908           1.188     1.236010\n",
       "10090          2.020     2.568470\n",
       "2527           0.710     0.764750\n",
       "10004          1.948     1.966140\n",
       "\n",
       "[4128 rows x 2 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data={\"actual values\": y_test,\n",
    "                        \"predictions\": y_preds})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the predictions are slightly away from the actual values.\n",
    "\n",
    "Let's take it a step further and visualize them in a plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x = np.arange(0, len(df), 1)\n",
    "ax.scatter(x, df[\"actual values\"], c=\"#588dfd\", label=\"Actual Values\")\n",
    "ax.scatter(x, df[\"predictions\"], c=\"#fd5869\", label=\"Predictions\")\n",
    "ax.legend(loc=(1, 0.5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending what problem you're working on, having a difference like we do now, might be okay. On the flip side, it may also not be okay, meaning the predictions would have to be closer.\n",
    "\n",
    "#### Mean Squared Error (MSE)\n",
    "\n",
    "We can also calculate the MSE using Scikit-Learn's [`mean_squared_error()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2572168897374702"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_test, y_preds)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because MSE takes the square of the errors rather than just taking the absolute difference into account, MSE will often be higher than MAE.\n",
    "\n",
    "To summarize, here are a few rules of thumb for choosing evaluation metrics for regression models:\n",
    "\n",
    "- R<sup>2</sup> is similar to accuracy. It gives you a quick indication of how well your model might be doing. Generally, the closer your R<sup>2</sup> value is to 1.0, the better the model. But it doesn't really tell exactly how wrong your model is in terms of how far off each prediction is.\n",
    "- MAE gives a better indication of how far off each of your model's predictions are on average.\n",
    "- As for MAE or MSE, because of the way MSE is calculated, squaring the differences between predicted values and actual values, it amplifies larger differences. Let's say we're predicting the value of houses (which we are).\n",
    "    - Pay more attention to MAE: When being $10,000 off is _**twice**_ as bad as being $5,000 off.\n",
    "    - Pay more attention to MSE: When being $10,000 off is _**more than twice**_ as bad as being $5,000 off.\n",
    "\n",
    "These are only a hadful of potential metrics you can use to evaluate regression models. For a more complete list, refer to the [Scikit-Learn metrics and scoring documentation](https://scikit-learn.org/stable/modules/model_evaluation.html).\n",
    "\n",
    "You can also check out these resources for more information:\n",
    "\n",
    "- [Beyond Accuracy: Precision and Recall by Will Koehrsen](https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c)\n",
    "- [StackOverflow answer describing MSE (mean squared error) and RSME (root mean squared error)](https://stackoverflow.com/a/37861832)\n",
    "\n",
    "### Finally using the `scoring` parameter\n",
    "\n",
    "We've covered a lot in this section, but we haven't exactly worked with the `scoring` parameter yet, so now it's finally time to use it to evaluate our machine learning models.\n",
    "\n",
    "The `scoring` parameter can be used with a function like `cross_val_score()` to tell Scikit-Learn what evaluation metric to return using cross-validation.\n",
    "\n",
    "As a reference, let's go back to our classification model and the heart disease dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(69)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the default metric aka mean accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81967213, 0.8852459 , 0.81967213, 0.83333333, 0.76666667])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(69)\n",
    "cv_acc = cross_val_score(clf, X, y, cv=5)\n",
    "cv_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've seen before, taking the mean of these values gives us the cross-validated accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated accuracy is: 82.49%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The cross-validated accuracy is: {np.mean(cv_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where does the `scoring` parameter fit into all this?\n",
    "\n",
    "The above result is actually the same as if we use the `scoring` parameter and set it as `\"accuracy\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated accuracy is: 82.49%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(69)\n",
    "cv_acc = cross_val_score(clf, X, y, cv=5, scoring=\"accuracy\")\n",
    "print(f\"The cross-validated accuracy is: {np.mean(cv_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The beauty of the `scoring` parameter is that we can actually use the other metrics we've discussed earlier and get cross-validated results.\n",
    "\n",
    "Let's take a look at those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated precision is: 0.83\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(69)\n",
    "cv_precision = cross_val_score(clf, X, y, cv=5, scoring=\"precision\")\n",
    "print(f\"The cross-validated precision is: {np.mean(cv_precision):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated recall is: 0.85\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(69)\n",
    "cv_recall = cross_val_score(clf, X, y, cv=5, scoring=\"recall\")\n",
    "print(f\"The cross-validated recall is: {np.mean(cv_recall):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated F1 score is: 0.84\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(69)\n",
    "cv_f1 = cross_val_score(clf, X, y, cv=5, scoring=\"f1\")\n",
    "print(f\"The cross-validated F1 score is: {np.mean(cv_f1):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For regression models, the workflow is also the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(69)\n",
    "\n",
    "X = california_df.drop(\"target\", axis=1)\n",
    "y = california_df[\"target\"]\n",
    "\n",
    "model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default `scoring` parameter for regression models is `\"r2\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated R^2 score is: 0.65\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(69)\n",
    "cv_r2 = cross_val_score(model, X, y, cv=5)\n",
    "print(f\"The cross-validated R^2 score is: {np.mean(cv_r2):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated R^2 score is: 0.65\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(69)\n",
    "cv_r2 = cross_val_score(model, X, y, cv=5, scoring=\"r2\")\n",
    "print(f\"The cross-validated R^2 score is: {np.mean(cv_r2):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the corss-validated MAE and MSE scores using the `scoring` parameter, however, there's a slight difference as to how they are called.\n",
    "\n",
    "The Scikit-Learn documentation states:\n",
    "\n",
    "> [\"All scorer objects follow the convention that higher return values are better than lower return values.\"](https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values)\n",
    "\n",
    "Thus, we call MAE as `\"neg_mean_absolute_error\"` and MSE as `\"neg_mean_squared_error\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated MAE score is: -0.47\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(69)\n",
    "cv_mae = cross_val_score(model,\n",
    "                         X,\n",
    "                         y,\n",
    "                         cv=5,\n",
    "                         scoring=\"neg_mean_absolute_error\")\n",
    "\n",
    "print(f\"The cross-validated MAE score is: {np.mean(cv_mae):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated MSE score is: -0.43\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(69)\n",
    "cv_mse = cross_val_score(model, \n",
    "                         X, \n",
    "                         y, \n",
    "                         cv=5,\n",
    "                         scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "print(f\"The cross-validated MSE score is: {np.mean(cv_mse):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using different evaluation metrics with Scikit-Learn\n",
    "\n",
    "Remember the third way of evaluating Scikit-Learn functions?\n",
    "\n",
    "> 3. Problem-specific metric functions. Similar to how the scoring parameter can be passed different scoring functions, Scikit-Learn implements these as stand alone functions.\n",
    "\n",
    "We've actually covered these a bit in the earlier parts of this section.\n",
    "\n",
    "Essentially, all the evaluation metrics we've used so far each have their own corresponding function provided by Scikit-Learn.\n",
    "\n",
    "They all work by comparing an array of predictions, usually called `y_preds` to an array of actual labels, usually called `y_test` or `y_true`.\n",
    "\n",
    "For classification models:\n",
    "\n",
    "- **Accuracy:** use [`accuracy_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
    "- **Precision:** use [`precision_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html)\n",
    "- **Recall:** use [`recall_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html)\n",
    "- **F1:** use [`f1_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier metrics for the test set:\n",
      "Accuracy: 85.25%\n",
      "Precision: 0.87\n",
      "Recall: 0.84\n",
      "F1: 0.86\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(69)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "print(\"Classifier metrics for the test set:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_preds) * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test, y_preds):.2f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_preds):.2f}\")\n",
    "print(f\"F1: {f1_score(y_test, y_preds):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For regression models:\n",
    "\n",
    "- **R<sup>2</sup>:** use [`r2_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html)\n",
    "- **MAE (mean absolute error):** use [`mean_absolute_error()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html)\n",
    "- **MSE (mean squared error):** use [`mean_squared_error()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression model metrics on the test set:\n",
      "R^2: 0.81\n",
      "MAE: 0.33\n",
      "MSE: 0.26\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(69)\n",
    "\n",
    "X = california_df.drop(\"target\", axis=1)\n",
    "y = california_df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "print(\"Regression model metrics on the test set:\")\n",
    "print(f\"R^2: {r2_score(y_test, y_preds):.2f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_preds):.2f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_preds):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phew! We've covered a lot in this section, but it's all worth it. Evaluating a model's predictions is paramaount in any machine learning project.\n",
    "\n",
    "There's nothing worse than training a machine learning model and optimizing for the wrong evaluation metric.\n",
    "\n",
    "Keep in mind the different metrics and evaluation methods we've covered in this section when training your future models.\n",
    "\n",
    "For more information, you can always refer to the [Scikit-Learn documentation for evaluation metrics](https://scikit-learn.org/stable/modules/model_evaluation.html).\n",
    "\n",
    "## Improving the model\n",
    "\n",
    "The first predictions you make with a model are generally referred to as baseline predictions. Conversely, the first evaluation metrics you get are referred to as baseline metrics.\n",
    "\n",
    "The next step is to improve upon these baseline metrics.\n",
    "\n",
    "Two of the main methods to improve baseline metrics are from a data perspective and a model perspective.\n",
    "\n",
    "From a data perspective asks:\n",
    "\n",
    "- Could we collect more data? In machine learning, more data is generally better, as it gives a model more opportunities to learn patterns.\n",
    "- Could we improve our data? This could mean filling in misisng values or finding a better encoding (turning things into numbers) strategy.\n",
    "\n",
    "From a model perspective asks:\n",
    "\n",
    "- Is there a better model we could use? If you've started out with a simple model, could you use a more complex one? (we saw an example of this when looking at the Scikit-Learn machine learning map, ensemble methods are generally considered more complex models)\n",
    "- Could we improve the current model? If the model you're using performs well straight out of the box, can the hyperparameters be tuned to make it even better?\n",
    "\n",
    "> **Note:** Patterns in data are also often referred to as data parameters. The difference between parameters and hyperparameters is a machine learning model seeks to find parameters in data on its own, where as, hyperparameters are settings on a model which a user (you) can adjust.\n",
    "\n",
    "Since we are working with two datasets, Why not approach this step from a model perspective.\n",
    "\n",
    "More specifically, we'll look at how we could improve our `RandomForestClassifier` and `RandomForestRegressor` models through hyperparameter tuning.\n",
    "\n",
    "What are hyperparameters, you might ask?\n",
    "\n",
    "Let's instantiate a default `RandomForestClassifier` as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiating a model like we did above means we're using the default hyperparameters.\n",
    "\n",
    "You can take a look at these hyperparameters using the `get_params()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these `n_estimators`, `max_depth`, `min_samples_split` values are called _hyperparameters_. You can adjust these values as needed when you instantiate a model.\n",
    "\n",
    "You can think of hyperparameters as being similar to dials on an oven. On the default setting your oven might do an okay job cooking your favourite meal. But with a little experimentation, you find it does better when you adjust the settings.\n",
    "\n",
    "![](./img/sklearn-hyperparameter-tuning-oven.png)\n",
    "\n",
    "The same goes for imporving a machine learning model by hyperparameter tuning. The default hyperparameters on a machine learning model may find patterns in data well. But there's a chance a adjusting the hyperparameters may improve a models performance.\n",
    "\n",
    "Every machine learning model will have different hyperparameters you can tune.\n",
    "\n",
    "The sheer amount of these hyperparameters might seem daunting, but don't worry.\n",
    "\n",
    "For now we can focus on Random Forest models and see how tuning their hyperparameters can change the resulting metrics. From there, we can apply the same principles into other types of models as needed.\n",
    "\n",
    "Adjusting hyperparameters is usually an experimental process to figure out which are best. As there's no real way of knowing which hyperparameters will be best when starting out.\n",
    "\n",
    "To get familar with hyparameter tuning, we'll take our `RandomForestClassifier` and adjust its hyperparameters in 3 ways:\n",
    "\n",
    "1. By hand\n",
    "2. Randomly with [RandomSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "3. Exhaustively with [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "\n",
    "### Tuning hyperparameters by hand\n",
    "\n",
    "So far, we've been using `train_test_split` to split our datasets into two parts: The training set and the test set.\n",
    "\n",
    "The process thus far is also fairly straightforward: The model gets fitted using the training set then it gets evaluated using the test set.\n",
    "\n",
    "With hyperparameter tuning, we introduce a third set for the split, a _validation set_.\n",
    "\n",
    "The model would still get fitted on the training set and evaluated with the test set, but now we use the validation set to (try to) improve the results by adjusting the hyperparameters.\n",
    "\n",
    "If our starting dataset contained 100 different patient records labels indicating who had heart disease and who didn't and we wanted to build a machine learning model to predict who had heart disease and who didn't, it might look like this:\n",
    "\n",
    "![Diagram illustrating the allocation for training/test/validation sets](./img/sklearn-train-valid-test-annotated.png)\n",
    "\n",
    "For starters, [the Scikit-Learn User Guide on Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#random-forest-parameters) suggests changing the `n_estimators` hyperparameter. As the name suggests, the `n_estimators` hyperparameter is the number of estimators that the model uses (or the number of \"trees\" in the forest).\n",
    "\n",
    "While we're at it, let's also try tuning these hyperparameters as well:\n",
    "\n",
    "- `min_samples_split`: The minimum number of samples required to split an internal node\n",
    "- `max_features`: The number of features to consider when looking for the best split\n",
    "- `max_depth`: The maximum depth of the tree\n",
    "- `min_samples_leaf`: The minimum number of samples required to be at a leaf node\n",
    "\n",
    "If this still sounds like a lot, the good news is, the process we're taking with the Random Forest and tuning its hyperparameters, can be used for other machine learning models in Scikit-Learn. The only difference is, with a different model, the hyperparameters you tune will be different.\n",
    "\n",
    "Let's remind ourselves again of the default hyperparameters we've been using so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's split our data into the train/test/validation sets as illustrated above, with the training set containing 70% of the data and the validation and test sets each containing 15%.\n",
    "\n",
    "Since we're going to be evaluating a few models, let's also make this into an evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    Performs evaluation comparison on y_true labels vs. y_pred labels.\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_preds)\n",
    "    precision = precision_score(y_true, y_preds)\n",
    "    recall = recall_score(y_true, y_preds)\n",
    "    f1 = f1_score(y_true, y_preds)\n",
    "\n",
    "    metric_dict = {\"accuracy\": round(accuracy, 2),\n",
    "                   \"precision\": round(precision, 2), \n",
    "                   \"recall\": round(recall, 2),\n",
    "                   \"f1\": round(f1, 2)}\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 score: {f1:.2f}\")\n",
    "\n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.22%\n",
      "Precision: 0.85\n",
      "Recall: 0.85\n",
      "F1 score: 0.85\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.82, 'precision': 0.85, 'recall': 0.85, 'f1': 0.85}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(69)\n",
    "\n",
    "# Shuffle the data\n",
    "heart_disease = heart_disease.sample(frac=1)\n",
    "\n",
    "# Split into X & y\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split the data into train, validation & test sets\n",
    "train_split = round(0.7 * len(heart_disease)) # 70% of data\n",
    "valid_split = round(train_split + 0.15 * len(heart_disease)) # 15% of data\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_valid, y_valid = X[train_split:valid_split], y[train_split:valid_split]\n",
    "X_test, y_test = X[valid_split:], y[valid_split:]\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_preds = clf.predict(X_valid)\n",
    "\n",
    "# Evaluate the classifier\n",
    "baseline_metrics = evaluate_preds(y_valid, y_preds)\n",
    "baseline_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful, now let's try and improve the results.\n",
    "\n",
    "We'll change 1 of the hyperparameters, `n_estimators`, to 200 and see if it improves on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.00%\n",
      "Precision: 0.85\n",
      "Recall: 0.81\n",
      "F1 score: 0.83\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(69)\n",
    "\n",
    "clf_2 = RandomForestClassifier(n_estimators=200)\n",
    "clf_2.fit(X_train, y_train)\n",
    "\n",
    "y_preds_2 = clf_2.predict(X_valid)\n",
    "\n",
    "clf_2_metrics = evaluate_preds(y_valid, y_preds_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metric scores seem to actually have gotten worse. Let's maybe try tuning some other hyperparameters.\n",
    "\n",
    "However, this could take a while if all we're doing is building new models with new hyperparameters each time.\n",
    "\n",
    "Fortunately, Scikit-Learn also provides helpful functions to help us with hyperparameter tuning.\n",
    "\n",
    "### Hyperparameter tuning with `RandomizedSearchCV`\n",
    "\n",
    "Scikit-Learn's [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) allows us to randomly search across different hyperparameters to see which work best. It also stores details about the ones which work best!\n",
    "\n",
    "Let's see it in action.\n",
    "\n",
    "First, we create a grid (dictionary) of hyperparameters we'd like to search over:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\"n_estimators\": [10, 100, 200, 500, 1000, 1200],\n",
    "        \"max_depth\": [None, 5, 10, 20, 30],\n",
    "        \"max_features\": [\"auto\", \"sqrt\"],\n",
    "        \"min_samples_split\": [2, 4, 6],\n",
    "        \"min_samples_leaf\": [1, 2, 4]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might wonder where all these values came from.\n",
    "\n",
    "They're actually made up.\n",
    "\n",
    "Not completely pulled out of the air but after reading the [Scikit-Learn documentation on Random Forests](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) you'll see some of these values have certain values which usually perform well and certain hyperparameters take strings rather than integers.\n",
    "\n",
    "Now we've got the grid setup, Scikit-Learn's RandomizedSearchCV will look at it, pick a random value from each, instantiate a model with those values and test each model.\n",
    "\n",
    "`RandomizedSearchCV` will then test as many models as there are combinations to be tested:\n",
    "\n",
    "- `max_depth` has 4 combinations\n",
    "- `max_features` has 2 combinations\n",
    "- `min_samples_leaf` has 3 combinations\n",
    "- `min_samples_split` has 3 combinations\n",
    "- `n_estimators` has 5 combinations\n",
    "\n",
    "That's 4x2x3x3x5 = 360 models!\n",
    "\n",
    "We can also set the `n_iter` parameter to limit the number of models `RandomizedSearchCV` tests.\n",
    "\n",
    "We will also get cross-validated results (hence the \"CV\" in `RandomizedSearchCV`) so we can use `train_test_split()`.\n",
    "\n",
    "And since we're going over so many different models, we'll set n_jobs to -1 of RandomForestClassifier so Scikit-Learn takes advantage of all the cores (processors) on our computers.\n",
    "\n",
    "> **Note:** Depending on n_iter (how many models you test), the different values in the hyperparameter grid, and the power of your computer, running the cell below may take a while.\n",
    "> \n",
    "> **Note 2:** Setting n_jobs=-1 seems to be breaking on some machines (for [the original notebook](https://github.com/mrdbourke/zero-to-mastery-ml/blob/master/section-2-data-science-and-ml-tools/introduction-to-scikit-learn.ipynb) at least, as of 8 December 2019). There seems to be an issue about it, being tracked on GitHub. For the tim ebeing, n_jobs=1 seems to be working.\n",
    "\n",
    "Let's see it in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   4.5s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.9s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.6s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.7s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=1200; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=1200; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=1200; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=1200; total time=   0.6s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1000; total time=   0.6s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1000; total time=   0.7s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1000; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.6s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.6s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.6s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.6s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.6s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.7s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1000; total time=   0.6s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=1200; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=1200; total time=   1.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=1200; total time=   1.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=1200; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.3s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "\n",
    "np.random.seed(69)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "rs_clf = RandomizedSearchCV(estimator=clf,\n",
    "                            param_distributions=grid,\n",
    "                            n_iter=20, # try 20 models total\n",
    "                            cv=5, # 5-fold cross-validation\n",
    "                            verbose=2) # print out results\n",
    "\n",
    "rs_clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After RandomizedSearchCV goes through `n_iter` combinations of of hyperparameter search space, it stores the best ones in the attribute `best_params_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 5}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when we call `predict()` on `rs_clf` (our `RandomizedSearchCV` version of our classifier), it'll use the best hyperparameters it found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.97%\n",
      "Precision: 0.73\n",
      "Recall: 0.96\n",
      "F1 score: 0.83\n"
     ]
    }
   ],
   "source": [
    "rs_y_preds = rs_clf.predict(X_test)\n",
    "\n",
    "rs_clf_metrics = evaluate_preds(y_test, rs_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! Thanks to `RandomizedSearchCV` testing out a bunch of different hyperparameters, we get a substantial boost to the recall score while keeping a similarly good score for the other evaluation metrics for our classification model.\n",
    "\n",
    "### Hyperparameter tuning with `GridSearchCV`\n",
    "\n",
    "Scikit-Learn's [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) also searches across different hyperparameters to see which work best, but the main difference between `GridSearchCV` and `RandomizedSearchCV` is `GridSearchCV` searches across a grid of hyperparamters exhaustively, whereas `RandomizedSearchCV` searches across a grid of hyperparameters randomly (stopping after `n_iter` combinations).\n",
    "\n",
    "Going back to the grid of hyperparameters we've been using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [10, 100, 200, 500, 1000, 1200],\n",
       " 'max_depth': [None, 5, 10, 20, 30],\n",
       " 'max_features': ['auto', 'sqrt'],\n",
       " 'min_samples_split': [2, 4, 6],\n",
       " 'min_samples_leaf': [1, 2, 4]}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've calculated that there's a total of 360 different combinations of hyperparameters within this grid.\n",
    "\n",
    "This could take a long time depending on the power of the computer you're using, the amount of data you have and the complexity of the hyperparamters (usually higher values means a more complex model).\n",
    "\n",
    "In our case, the data we're using is relatively small (only ~300 samples).\n",
    "\n",
    "Since we've already tried to find some ideal hyperparameters using `RandomizedSearchCV`, we'll create another hyperparameter grid based on the `best_params_` of `rs_clf`* with less options and then try to use `GridSearchCV` to find a more ideal set.\n",
    "\n",
    "> **Note:** Based on the `best_params_` of `rs_clf` implies the next set of hyperparameters we'll try are roughly in the same range of the best set found by RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_2 = {\"n_estimators\": [10, 100, 200],\n",
    "          \"max_depth\": [None, 5, 10],\n",
    "          \"max_features\": [\"auto\", \"sqrt\"],\n",
    "          \"min_samples_split\": [2, 4],\n",
    "          \"min_samples_leaf\": [2, 4]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new grid contains less total combinations of hyperparameters to search over, letting us use `GridSearchCV` to exhaustively search through all possible combintions much more freely.\n",
    "\n",
    "This time, we're using 3x3x2x2x2 = 72 models in total. Or about 5 times less (360/72) combinations of hyperparameters less than our original grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   2.2s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "np.random.seed(69)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "gs_clf = GridSearchCV(estimator=clf,\n",
    "                      param_grid=grid_2,\n",
    "                      cv=5, # 5-fold cross-validation\n",
    "                      verbose=2) # print out progress\n",
    "\n",
    "gs_clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as before, the best hyperparameter combination found by `GridSearchCV` can be found using the `best_params_` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `gs_clf()`'s `predict()` method by default would also use these best hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.97%\n",
      "Precision: 0.73\n",
      "Recall: 0.96\n",
      "F1 score: 0.83\n"
     ]
    }
   ],
   "source": [
    "gs_y_preds = gs_clf.predict(X_test)\n",
    "\n",
    "gs_clf_metrics = evaluate_preds(y_test, gs_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize what we've learned in this section, let's create a DataFrame to compare the different metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_metrics = pd.DataFrame({\"baseline\": baseline_metrics,\n",
    "                                \"clf_2\": clf_2_metrics,\n",
    "                                \"random search\": rs_clf_metrics,\n",
    "                                \"grid search\": gs_clf_metrics})\n",
    "compare_metrics.plot.bar(figsize=(10, 8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It seems, even after trying 72 different combinations of hyperparamters, we don't get much improvement in results.\n",
    "\n",
    "These things might happen. But it's important to remember, it's not over. There may be more we can do.\n",
    "\n",
    "In a hyperparameter tuning sense, there may be a better set we could find through more extensive searching with `RandomizedSearchCV` and `GridSearchCV` but it's likely these improvements will be marginal.\n",
    "\n",
    "A few next ideas you could try:\n",
    "\n",
    "- **Collecting more data** - Based on the results our models are getting now, it seems like they're finding some patterns. Collecting more data may improve a models ability to find patterns. However, your ability to do this will largely depend on the project you're working on.\n",
    "- **Try a more advanced model** - Although our tuned Random Forest model is doing pretty well, a more advanced ensemble method such as XGBoost or CatBoost might perform better.\n",
    "\n",
    "Since machine learning is part engineering, part science, these kind of experiments are common place in any machine learning project.\n",
    "\n",
    "## Saving and loading a trained model\n",
    "\n",
    "Since our `GridSearchCV` model has the best results so far, we'll export it and save it to file.\n",
    "\n",
    "### Saving and loading a model with `pickle`\n",
    "\n",
    "One way to save a model is using Python's [`pickle` module](https://docs.python.org/3/library/pickle.html).\n",
    "\n",
    "Using `pickle`'s `dump()` method, we'll pass our `gs_clf` model along with the `open()` function  containing a string for the filename we want to save our model as, along with the `\"wb\"` string which stands for \"write binary\", which is the file type `open()` will write our model as."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(gs_clf, open(\"gs_random_forest_model_1.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once it's saved, we can import it using pickle's `load()` method, passing it `open()` containing the filename as a string and `\"rb\"` standing for \"read binary\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_pickle_model = pickle.load(open(\"gs_random_forest_model_1.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've reimported your trained model using `pickle`, you can use it to make predictions as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.97%\n",
      "Precision: 0.73\n",
      "Recall: 0.96\n",
      "F1 score: 0.83\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.82, 'precision': 0.73, 'recall': 0.96, 'f1': 0.83}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_y_preds = loaded_pickle_model.predict(X_test)\n",
    "evaluate_preds(y_test, pickle_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading a model with `joblib`\n",
    "\n",
    "Alternatively, we can also save and load our models using [`joblib`](https://joblib.readthedocs.io/en/latest/persistence.html).\n",
    "\n",
    "To save a model, we can use `joblib`'s `dump()` function, passing it the model (`gs_clf`) and the desired filename:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "dump(gs_clf, filename=\"gs_random_forest_model_1.joblib\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've saved a model using `dump()`, you can import it using `load()` and passing it the filename of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_joblib_model = load(filename=\"gs_random_forest_model_1.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, once imported, we can make predictions with our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.97%\n",
      "Precision: 0.73\n",
      "Recall: 0.96\n",
      "F1 score: 0.83\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.82, 'precision': 0.73, 'recall': 0.96, 'f1': 0.83}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib_y_preds = loaded_joblib_model.predict(X_test)\n",
    "evaluate_preds(y_test, joblib_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice the evaluation metrics are the same as before.\n",
    "\n",
    "Which one should you use, `pickle` or `joblib`?\n",
    "\n",
    "According to [Scikit-Learn's documentation](https://scikit-learn.org/stable/modules/model_persistence.html), they suggest it may be more efficient to use `joblib` as it's more efficient with large numpy arrays (which is what may be contained in trained/fitted Scikit-Learn models).\n",
    "\n",
    "Either way, they both function fairly similar so deciding on which one to use, shouldn't cause too much of an issue."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a17b241f4543d8602b7482e0e0acc758b16495de27bccf17cd651e6db5d1cb08"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
