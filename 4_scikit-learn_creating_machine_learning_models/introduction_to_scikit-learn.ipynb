{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Scikit-Learn (sklearn)\n",
    "\n",
    "This notebook demonstrates some of the most useful functions of the beautiful Scikit-Learn library.\n",
    "\n",
    "## What is Scikit-Learn?\n",
    "\n",
    "[Scikit-Learn](https://scikit-learn.org/stable/index.html), also referred to as `sklearn`, is an open-source, commercially usable Python machine learning library. Built on NumPy, SciPy, and Matplotlib, It provides simple, efficient tools that are accessible to everybody, and reusable in various contexts.\n",
    "\n",
    "![Scikit-Learn is used for modeling in machine learning projects.](./img/sklearn_6-step_ml_framework_tools_scikit-learn_highlight.png)\n",
    "\n",
    "## What we're going to cover\n",
    "\n",
    "This notebook shall be focusing on the main use cases of the Scikit-Learn library. More specifically, we shall go through the typical workflow of a Scikit-Learn project in a step-by-step process and improving upon our knowledge of Scikit-Learn as we go through the steps.\n",
    "\n",
    "0. An end-to-end Scikit-Learn workflow\n",
    "1. Getting the data ready\n",
    "2. Choosing the right estimator/algorithm for our problems\n",
    "3. Fitting the model/algorithm and using it to make predictions on our data\n",
    "4. Evaluating the model\n",
    "5. Improving the model\n",
    "6. Saving and loading a trained model\n",
    "7. Putting it all together\n",
    "\n",
    "**Note:** All of the steps in this notebook shall focus on **supervised learning** (having data and labels).\n",
    "\n",
    "## 0. An end-to-end Scikit-Learn workflow\n",
    "\n",
    "Scikit-Learn is a vast library containing a large variety of tools that can be used in various different contexts. As such, it might be better to start off with a typical end-to-end Scikit-Learn workflow and take a look at the most common use-cases of the library. \n",
    "\n",
    "[This notebook](./scikit-learn_workflow.ipynb) demonstrates one such typical Scikit-Learn workflow.\n",
    "\n",
    "From there, we shall take a much closer look at each step in the process and improve upon the knoledge we gained using Scikit-Learn.\n",
    "\n",
    "![Diagram of the Scikit-Learn workflow](img/sklearn_workflow.png)\n",
    "\n",
    "## 1. Getting the data ready\n",
    "\n",
    "### Standard imports\n",
    "\n",
    "The very first step when working with a machine learning project is to import the necessary libraries and packages you'll be working with.\n",
    "\n",
    "For this project, we shall keep using the usual Numpy, Pandas, and Matplotlib packages, so let's go ahead and import those right away:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've imported the usual packages, let's get some data to work with.\n",
    "\n",
    "Let's take a look at some heart disease data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease = pd.read_csv(\"../data/heart-disease.csv\")\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three main things we have to do are:\n",
    "\n",
    "- Split the data into features (usually called `X`) and labels (usually called `y`)\n",
    "- Converting non-numeric values into numeric values (also called *feature encoding*)\n",
    "- Filling (aka *imputing*) or disregarding missing values in the data\n",
    "\n",
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  \n",
       "0   0     1  \n",
       "1   0     2  \n",
       "2   0     2  \n",
       "3   0     2  \n",
       "4   0     2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = heart_disease[\"target\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've split the data into features and labels, we also have to split them further into *training* and *test sets* that we can use to train and validate the machine learning models we're going to be making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((242, 13), (61, 13), (242,), (61,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! we now have training and test sets for our heart disease data.\n",
    "\n",
    "When we take a look at the shapes of the training and test shapes, notice we seem to get tuples corresponding to the dimensions of the data. The second number in the tuples simply means that `X` has `13` columns of data, while `y` has only one column. But what about the `242` and `61`?\n",
    "\n",
    "Let's take a look at the shape of our original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((303, 13), (303,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(heart_disease)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the original heart disease data has `303` rows.\n",
    "\n",
    "When we did the `train_test_split()` call, notice we had a `test_size` parameter set to `0.2`.\n",
    "\n",
    "This means 20% of the data rows shoud be allocated for the test set. Let's verify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(303 * 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "303 - 61"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it checks out. 242 rows were allocated for the training set while 61 rows were allocated for the test set.\n",
    "\n",
    "### Converting data into numeric values\n",
    "\n",
    "Luckily, the heart disease data provided to us is already in numeric form on all columns.\n",
    "\n",
    "However, most other datasets might not have all their data in numerical form.\n",
    "\n",
    "It is important to convert the non-numeric data into numerical form first, because most machine learning models only work on numeric inputs.\n",
    "\n",
    "Let's take a look at another example dataset and see how we can convert these kinds of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431</td>\n",
       "      <td>4</td>\n",
       "      <td>15323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714</td>\n",
       "      <td>5</td>\n",
       "      <td>19943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714</td>\n",
       "      <td>4</td>\n",
       "      <td>28343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365</td>\n",
       "      <td>4</td>\n",
       "      <td>13434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577</td>\n",
       "      <td>3</td>\n",
       "      <td>14043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Make Colour  Odometer (KM)  Doors  Price\n",
       "0   Honda  White          35431      4  15323\n",
       "1     BMW   Blue         192714      5  19943\n",
       "2   Honda  White          84714      4  28343\n",
       "3  Toyota  White         154365      4  13434\n",
       "4  Nissan   Blue         181577      3  14043"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales = pd.read_csv(\"../data/car-sales-extended.csv\")\n",
    "car_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(car_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             object\n",
       "Colour           object\n",
       "Odometer (KM)     int64\n",
       "Doors             int64\n",
       "Price             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the `Make` and `Colour` columns have non-numeric data.\n",
    "\n",
    "Let's see what happens if we try and build a model on the dataset without first converting those columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = car_sales.drop(\"Price\", axis=1)\n",
    "y = car_sales[\"Price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Nissan'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ecb56ad8f06d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    327\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         )\n",
      "\u001b[1;32mD:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    570\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 956\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m    957\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    736\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 738\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    739\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m                 raise ValueError(\n",
      "\u001b[1;32mD:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1898\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1899\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1900\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1901\u001b[0m     def __array_wrap__(\n",
      "\u001b[1;32mD:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Nissan'"
     ]
    }
   ],
   "source": [
    "# Try to predict with random forest on price column (doesn't work)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh dear, looks like Scikit-Learn throws an error when we try and build a model this time.\n",
    "\n",
    "The error message gives us a hint as to what went wrong:\n",
    "> ValueError: could not convert string to float: 'Nissan'\n",
    "\n",
    "This means the `RandomForestRegressor()` model only accepts numeric inputs. Otherwise, it throws an error when it tries to deal with non-numeric data.\n",
    "\n",
    "Now, let's see how to get around that error by converting the non-numeric data into a numeric format that the model can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `categorical_features` list contains the columns that have non-numeric or *categorical* data\n",
    "\n",
    "Now, we're trying to convert the `Make` and `Colour` columns into a numeric format, but why is `Doors` also included in the list?\n",
    "\n",
    "Let's take a look at the `Doors` column first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    856\n",
       "5     79\n",
       "3     65\n",
       "Name: Doors, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales[\"Doors\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Doors` column indeed contains numerical data, but at the same time it also has very few distinct values with little variance.\n",
    "\n",
    "Thus, it can also make sense to treat those discrete values as different *categories* that the data can fall into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 3.54310e+04],\n",
       "       [1.00000e+00, 0.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        1.00000e+00, 1.92714e+05],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 8.47140e+04],\n",
       "       ...,\n",
       "       [0.00000e+00, 0.00000e+00, 1.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 6.66040e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 2.15883e+05],\n",
       "       [0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 2.48360e+05]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                  one_hot,\n",
    "                                  categorical_features)],\n",
    "                                  remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that's quite a lot to take in. Let's try and convert it into a Pandas `DataFrame` so we can have an easier time reading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>192714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181577.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66604.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215883.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248360.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9    10   11        12\n",
       "0    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   35431.0\n",
       "1    1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  192714.0\n",
       "2    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   84714.0\n",
       "3    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  154365.0\n",
       "4    0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  181577.0\n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...\n",
       "995  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   35820.0\n",
       "996  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  155144.0\n",
       "997  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0   66604.0\n",
       "998  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  215883.0\n",
       "999  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  248360.0\n",
       "\n",
       "[1000 rows x 13 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(transformed_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you might say: \"Hold on, this doesn't look the same as the original data!\", but let's take a step back and look at what's actually happened here.\n",
    "\n",
    "For reference, here's the dataset we're working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>35820</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>White</td>\n",
       "      <td>155144</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>66604</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215883</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>248360</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Make Colour  Odometer (KM)  Doors\n",
       "0     Honda  White          35431      4\n",
       "1       BMW   Blue         192714      5\n",
       "2     Honda  White          84714      4\n",
       "3    Toyota  White         154365      4\n",
       "4    Nissan   Blue         181577      3\n",
       "..      ...    ...            ...    ...\n",
       "995  Toyota  Black          35820      4\n",
       "996  Nissan  White         155144      3\n",
       "997  Nissan   Blue          66604      4\n",
       "998   Honda  White         215883      4\n",
       "999  Toyota   Blue         248360      4\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm... It looks like we do have the same values on the `Odometer (KM)` column in the `teansformed_X` dataset.\n",
    "\n",
    "Still, what's the deal with all the other columns?\n",
    "\n",
    "The new columns are a result of the `OneHotEncoder` transforming the catergorical data into multiple categories.\n",
    "\n",
    "It does this by generating additional columns to represent each distinct category for the data.\n",
    "\n",
    "For example, `OneHotEncoder` generated four columns to represent each of the car makes (`BMW`, `Honda`, `Nissan`, and `Toyota`). Each of those columns will then have a value of `0.0` if the car doesn't have the corresponding car make, or `1.0` if the car does have the corresponding car make. Note that only one column out of those four will have a `1.0` value, and the rest should have a value of `0.0`.\n",
    "\n",
    "`OneHotEncoder` also does the same thing for the other `categorical_features` in the dataset.\n",
    "\n",
    "#### Another way to encode categorical data\n",
    "\n",
    "We can also use the `get_dummies()` function from the Pandas library to convert categorical data into numeric form.\n",
    "\n",
    "Let's take a look at the original `car_sales` dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431</td>\n",
       "      <td>4</td>\n",
       "      <td>15323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714</td>\n",
       "      <td>5</td>\n",
       "      <td>19943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714</td>\n",
       "      <td>4</td>\n",
       "      <td>28343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365</td>\n",
       "      <td>4</td>\n",
       "      <td>13434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577</td>\n",
       "      <td>3</td>\n",
       "      <td>14043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Make Colour  Odometer (KM)  Doors  Price\n",
       "0   Honda  White          35431      4  15323\n",
       "1     BMW   Blue         192714      5  19943\n",
       "2   Honda  White          84714      4  28343\n",
       "3  Toyota  White         154365      4  13434\n",
       "4  Nissan   Blue         181577      3  14043"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doors</th>\n",
       "      <th>Make_BMW</th>\n",
       "      <th>Make_Honda</th>\n",
       "      <th>Make_Nissan</th>\n",
       "      <th>Make_Toyota</th>\n",
       "      <th>Colour_Black</th>\n",
       "      <th>Colour_Blue</th>\n",
       "      <th>Colour_Green</th>\n",
       "      <th>Colour_Red</th>\n",
       "      <th>Colour_White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Doors  Make_BMW  Make_Honda  Make_Nissan  Make_Toyota  Colour_Black  \\\n",
       "0        4         0           1            0            0             0   \n",
       "1        5         1           0            0            0             0   \n",
       "2        4         0           1            0            0             0   \n",
       "3        4         0           0            0            1             0   \n",
       "4        3         0           0            1            0             0   \n",
       "..     ...       ...         ...          ...          ...           ...   \n",
       "995      4         0           0            0            1             1   \n",
       "996      3         0           0            1            0             0   \n",
       "997      4         0           0            1            0             0   \n",
       "998      4         0           1            0            0             0   \n",
       "999      4         0           0            0            1             0   \n",
       "\n",
       "     Colour_Blue  Colour_Green  Colour_Red  Colour_White  \n",
       "0              0             0           0             1  \n",
       "1              1             0           0             0  \n",
       "2              0             0           0             1  \n",
       "3              0             0           0             1  \n",
       "4              1             0           0             0  \n",
       "..           ...           ...         ...           ...  \n",
       "995            0             0           0             0  \n",
       "996            0             0           0             1  \n",
       "997            1             0           0             0  \n",
       "998            0             0           0             1  \n",
       "999            1             0           0             0  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = pd.get_dummies(car_sales[[\"Make\", \"Colour\", \"Doors\"]])\n",
    "dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the `Make` and `Colour` columns were split into different categories, but the `Doors` column was still left intact.\n",
    "\n",
    "Again, since the `Doors` column is already numeric, we can leave it as-is, but if we want to treat it as a categorical data, we can convert it into an `object` type for the `get_dummies()` function to split it into categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make_BMW</th>\n",
       "      <th>Make_Honda</th>\n",
       "      <th>Make_Nissan</th>\n",
       "      <th>Make_Toyota</th>\n",
       "      <th>Colour_Black</th>\n",
       "      <th>Colour_Blue</th>\n",
       "      <th>Colour_Green</th>\n",
       "      <th>Colour_Red</th>\n",
       "      <th>Colour_White</th>\n",
       "      <th>Doors_3</th>\n",
       "      <th>Doors_4</th>\n",
       "      <th>Doors_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Make_BMW  Make_Honda  Make_Nissan  Make_Toyota  Colour_Black  \\\n",
       "0           0           1            0            0             0   \n",
       "1           1           0            0            0             0   \n",
       "2           0           1            0            0             0   \n",
       "3           0           0            0            1             0   \n",
       "4           0           0            1            0             0   \n",
       "..        ...         ...          ...          ...           ...   \n",
       "995         0           0            0            1             1   \n",
       "996         0           0            1            0             0   \n",
       "997         0           0            1            0             0   \n",
       "998         0           1            0            0             0   \n",
       "999         0           0            0            1             0   \n",
       "\n",
       "     Colour_Blue  Colour_Green  Colour_Red  Colour_White  Doors_3  Doors_4  \\\n",
       "0              0             0           0             1        0        1   \n",
       "1              1             0           0             0        0        0   \n",
       "2              0             0           0             1        0        1   \n",
       "3              0             0           0             1        0        1   \n",
       "4              1             0           0             0        1        0   \n",
       "..           ...           ...         ...           ...      ...      ...   \n",
       "995            0             0           0             0        0        1   \n",
       "996            0             0           0             1        1        0   \n",
       "997            1             0           0             0        0        1   \n",
       "998            0             0           0             1        0        1   \n",
       "999            1             0           0             0        0        1   \n",
       "\n",
       "     Doors_5  \n",
       "0          0  \n",
       "1          1  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "..       ...  \n",
       "995        0  \n",
       "996        0  \n",
       "997        0  \n",
       "998        0  \n",
       "999        0  \n",
       "\n",
       "[1000 rows x 12 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales[\"Doors\"] = car_sales[\"Doors\"].astype(object)\n",
    "dummies = pd.get_dummies(car_sales[[\"Make\", \"Colour\", \"Doors\"]])\n",
    "dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now that we've successfully transformed the data into numeric form, we can try and fit a model on our transformed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31695249778476753"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(69)\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X, y, test_size=0.2)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic! Looks like we've successfully fitted a model to the data without getting an error this time, all thanks to transforming our data into numeric form.\n",
    "\n",
    "### Dealing with missing values\n",
    "\n",
    "There are two ways to deal with missing data.\n",
    "\n",
    "- Fill in the missing parts with a predetermined value. This approach is also known as **_imputation_**.\n",
    "- Remove the rows cotaining missing data altogether. Note that this results in having less data to work with.\n",
    "\n",
    "**Note:** Dealing with missing values is a problem to problem issue. And there's often no best way to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>35820.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>155144.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>66604.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215883.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>248360.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12732.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Make Colour  Odometer (KM)  Doors    Price\n",
       "0     Honda  White        35431.0    4.0  15323.0\n",
       "1       BMW   Blue       192714.0    5.0  19943.0\n",
       "2     Honda  White        84714.0    4.0  28343.0\n",
       "3    Toyota  White       154365.0    4.0  13434.0\n",
       "4    Nissan   Blue       181577.0    3.0  14043.0\n",
       "..      ...    ...            ...    ...      ...\n",
       "995  Toyota  Black        35820.0    4.0  32042.0\n",
       "996     NaN  White       155144.0    3.0   5716.0\n",
       "997  Nissan   Blue        66604.0    4.0  31570.0\n",
       "998   Honda  White       215883.0    4.0   4001.0\n",
       "999  Toyota   Blue       248360.0    4.0  12732.0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing = pd.read_csv(\"../data/car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see some odd bits on `NaN` values in this dataset.\n",
    "\n",
    "One way to quickly check exactly how much missing data is in your dataset is to use the `isna()` method from Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have quite a lot of missing fields in our dataset.\n",
    "\n",
    "What happens if we try and fit a model on a dataset with missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = car_sales_missing.drop(\"Price\", axis=1)\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-189d5475a87d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m69\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformed_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    327\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         )\n",
      "\u001b[1;32mD:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    570\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 956\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m    957\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    710\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m         \u001b[0m_ensure_no_complex_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 712\u001b[1;33m         array = _ensure_sparse_format(\n\u001b[0m\u001b[0;32m    713\u001b[0m             \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[1;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse)\u001b[0m\n\u001b[0;32m    469\u001b[0m             )\n\u001b[0;32m    470\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"allow-nan\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    112\u001b[0m         ):\n\u001b[0;32m    113\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"infinity\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"NaN, infinity\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    115\u001b[0m                 msg_err.format(\n\u001b[0;32m    116\u001b[0m                     \u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "# Transform categorical data into numeric form\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                   one_hot,\n",
    "                                   categorical_features)],\n",
    "                                   remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X\n",
    "\n",
    "# Try and fit a model\n",
    "np.random.seed(69)\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X, y, test_size=0.2)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get another error this time:\n",
    "> ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
    "\n",
    "This means Scikit-Learn also needs the data to contain no missing values.\n",
    "\n",
    "Let's see how we can deal with these missing data before we try and fit a model on this dataset.\n",
    "\n",
    "#### Option 1: Use Pandas to deal with missing data\n",
    "\n",
    "We can use Pandas to fill in the missing values of the dataset.\n",
    "\n",
    "For numerical values we can simply use the mean of the existing data in the column, and for categorical data we can use some other predetermined value instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>35820.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Missing</td>\n",
       "      <td>White</td>\n",
       "      <td>155144.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>66604.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215883.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>248360.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12732.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Make Colour  Odometer (KM)  Doors    Price\n",
       "0      Honda  White        35431.0    4.0  15323.0\n",
       "1        BMW   Blue       192714.0    5.0  19943.0\n",
       "2      Honda  White        84714.0    4.0  28343.0\n",
       "3     Toyota  White       154365.0    4.0  13434.0\n",
       "4     Nissan   Blue       181577.0    3.0  14043.0\n",
       "..       ...    ...            ...    ...      ...\n",
       "995   Toyota  Black        35820.0    4.0  32042.0\n",
       "996  Missing  White       155144.0    3.0   5716.0\n",
       "997   Nissan   Blue        66604.0    4.0  31570.0\n",
       "998    Honda  White       215883.0    4.0   4001.0\n",
       "999   Toyota   Blue       248360.0    4.0  12732.0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing[\"Make\"].fillna(\"Missing\", inplace=True)\n",
    "car_sales_missing[\"Colour\"].fillna(\"Missing\", inplace=True)\n",
    "car_sales_missing[\"Odometer (KM)\"].fillna(car_sales_missing[\"Odometer (KM)\"].mean(), inplace=True)\n",
    "car_sales_missing[\"Doors\"].fillna(4, inplace=True)\n",
    "car_sales_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make              0\n",
       "Colour            0\n",
       "Odometer (KM)     0\n",
       "Doors             0\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `Price` column still has missing values.\n",
    "\n",
    "Since `Price` is the value we're trying to predict, it might be better to just remove the rows with no `Price` value for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             0\n",
       "Colour           0\n",
       "Odometer (KM)    0\n",
       "Doors            0\n",
       "Price            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have no missing values in our data, but it came at a cost of having to remove a number of rows that had no `Price` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "950"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(car_sales_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try fitting a model into this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = car_sales_missing.drop(\"Price\", axis=1)\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25296341556528734"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform categorical data into numeric form\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                   one_hot,\n",
    "                                   categorical_features)],\n",
    "                                   remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X\n",
    "\n",
    "# Try and fit a model\n",
    "np.random.seed(69)\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X, y, test_size=0.2)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: Use Scikit-Learn to deal with missing data\n",
    "\n",
    "We can also use Scikit-Learn to deal with missing data.\n",
    "\n",
    "Let's use the `car_sales_missing` dataset once again, this time using Scikit-Learn to fill in or remove rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing = pd.read_csv(\"../data/car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we can drop the rows with the missing `Price` values for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             47\n",
       "Colour           46\n",
       "Odometer (KM)    48\n",
       "Doors            47\n",
       "Price             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing.dropna(subset=[\"Price\"], inplace=True)\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also split the remaining data into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X and y\n",
    "X = car_sales_missing.drop(\"Price\", axis=1)\n",
    "y = car_sales_missing[\"Price\"]\n",
    "\n",
    "# Split data into train and test\n",
    "np.random.seed(69)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's fill in the missing data using Scikit-Learn.\n",
    "\n",
    "Note that it is best practice to use the following Scikit-Learn functions to fill and transform missing data separately on the training and test sets.\n",
    "\n",
    "Why is that? It is because performing imputation on the whole un-split dataset is causing \"information leakage\", which is when information contained in the test set is \"leaked\" into the training data set. The result is a biased estimator with an optimistic test error. The test set should be set aside at the beginning of any machine learning project and only be touched when validating the model.\n",
    "\n",
    "Here are some guidelines to keep in mind when handling missing data:\n",
    "- Split your data first (into train/test), always keep your training & test data separate\n",
    "- Fill/transform the training set and test sets separately (this goes for filling data with pandas as well)\n",
    "- Don't use data from the future (test set) to fill data from the past (training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Use SimpleImputer to fill in missing values\n",
    "cat_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"Missing\")\n",
    "door_imputer = SimpleImputer(strategy=\"constant\", fill_value=4)\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "# Define columns\n",
    "cat_features = [\"Make\", \"Colour\"]\n",
    "door_feature = [\"Doors\"]\n",
    "num_features = [\"Odometer (KM)\"]\n",
    "\n",
    "# Create an imputer\n",
    "imputer = ColumnTransformer([\n",
    "    (\"cat_imputer\", cat_imputer, cat_features),\n",
    "    (\"door_imputer\", door_imputer, door_feature),\n",
    "    (\"num_imputer\", num_imputer, num_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an imputer set up, it's time to use it to actually fill in the missing values in the dataset.\n",
    "\n",
    "> **Note:** We use `fit_transform()` on the training data and `transform()` on the testing data. In essence, we learn the patterns in the training set and transform it via imputation (fit, then transform). Then we take those same patterns and fill the test set (transform only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['BMW', 'White', 5.0, 152410.0],\n",
       "       ['Nissan', 'Green', 4.0, 87701.0],\n",
       "       ['Nissan', 'White', 4.0, 51004.0],\n",
       "       ...,\n",
       "       ['Honda', 'White', 4.0, 40134.0],\n",
       "       ['Nissan', 'Black', 4.0, 125251.0],\n",
       "       ['Missing', 'White', 4.0, 109384.0]], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_X_train = imputer.fit_transform(X_train)\n",
    "filled_X_test = imputer.transform(X_test)\n",
    "\n",
    "filled_X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the result as a Pandas `DataFrame` to get a better look at what just happened:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BMW</td>\n",
       "      <td>White</td>\n",
       "      <td>5.0</td>\n",
       "      <td>152410.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Green</td>\n",
       "      <td>4.0</td>\n",
       "      <td>87701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>White</td>\n",
       "      <td>4.0</td>\n",
       "      <td>51004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Blue</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>4.0</td>\n",
       "      <td>132327.821823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>4.0</td>\n",
       "      <td>193179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Blue</td>\n",
       "      <td>4.0</td>\n",
       "      <td>196507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Black</td>\n",
       "      <td>4.0</td>\n",
       "      <td>125251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>Missing</td>\n",
       "      <td>White</td>\n",
       "      <td>4.0</td>\n",
       "      <td>109384.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Make Colour Doors  Odometer (KM)\n",
       "0        BMW  White   5.0       152410.0\n",
       "1     Nissan  Green   4.0        87701.0\n",
       "2     Nissan  White   4.0        51004.0\n",
       "3      Honda   Blue   4.0        30120.0\n",
       "4     Toyota   Blue   4.0  132327.821823\n",
       "..       ...    ...   ...            ...\n",
       "755    Honda  White   4.0       193179.0\n",
       "756    Honda   Blue   4.0       196507.0\n",
       "757    Honda  White   4.0        40134.0\n",
       "758   Nissan  Black   4.0       125251.0\n",
       "759  Missing  White   4.0       109384.0\n",
       "\n",
       "[760 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_filled_train = pd.DataFrame(filled_X_train,\n",
    "                                      columns=[\"Make\", \"Colour\", \"Doors\", \"Odometer (KM)\"])\n",
    "\n",
    "car_sales_filled_test = pd.DataFrame(filled_X_test,\n",
    "                                      columns=[\"Make\", \"Colour\", \"Doors\", \"Odometer (KM)\"])\n",
    "\n",
    "car_sales_filled_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             0\n",
       "Colour           0\n",
       "Doors            0\n",
       "Odometer (KM)    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_filled_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonderful! We've just used Scikit-Learn to fill in the missing values.\n",
    "\n",
    "Now, there's just one more step before we can fit a model to this dataset.\n",
    "\n",
    "Let's revisit a previous topic and convert the categorical features into a numeric form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<760x15 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3040 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode the features with the same code as before \n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\", \n",
    "                                 one_hot, \n",
    "                                 categorical_features)],\n",
    "                                 remainder=\"passthrough\")\n",
    "\n",
    "# Fill train and test values separately\n",
    "transformed_X_train = transformer.fit_transform(car_sales_filled_train)\n",
    "transformed_X_test = transformer.transform(car_sales_filled_test)\n",
    "\n",
    "# Check transformed and filled X_train\n",
    "transformed_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>152410.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87701.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51004.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132327.821823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>193179.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>196507.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40134.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125251.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109384.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9    10   11   12   13  \\\n",
       "0    1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0   \n",
       "1    0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "2    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   \n",
       "3    0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "4    0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "755  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   \n",
       "756  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "757  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   \n",
       "758  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "759  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   \n",
       "\n",
       "                14  \n",
       "0    152410.000000  \n",
       "1     87701.000000  \n",
       "2     51004.000000  \n",
       "3     30120.000000  \n",
       "4    132327.821823  \n",
       "..             ...  \n",
       "755  193179.000000  \n",
       "756  196507.000000  \n",
       "757   40134.000000  \n",
       "758  125251.000000  \n",
       "759  109384.000000  \n",
       "\n",
       "[760 rows x 15 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(transformed_X_train.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've done all the necessary steps to get our data ready, let's see if we can fit a machine learning model this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2603174739059788"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(69)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(transformed_X_train, y_train)\n",
    "model.score(transformed_X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work! We've successfully prepared our dataset by splitting into training and test sets, handling missing data, and converting categorical features into a numerical form. That means we are now able to use these steps to transform any other dataset in order to better fit machine learning models.\n",
    "\n",
    "If this looks confusing, don't worry, we've covered a lot of ground very quickly. And we'll revisit these strategies in a future section in way which makes a lot more sense.\n",
    "\n",
    "For now, the key takeaways to remember are:\n",
    "\n",
    "- Most datasets you come across won't be in a form ready to immediately start using them with machine learning models. And some may take more preparation than others to get ready to use.\n",
    "- For most machine learning models, your data has to be numerical. This will involve converting whatever you're working with into numbers. This process is often referred to as **feature engineering** or **feature encoding**.\n",
    "- Some machine learning models aren't compatible with missing data. The process of filling missing data is referred to as **data imputation**.\n",
    "\n",
    "## 2. Choosing the right estimator/algorithm for our problems\n",
    "\n",
    "In order to get the right predictions for our data, it is important that we choose the right machine learning model that can best fit our data.\n",
    "\n",
    "So far we've been using the `RandomForestRegressor` model provided by Scikit-Learn. But how did we know that it's the right model to use for our dataset? When does it make sense to use that particular model, and when does it make more sense to choose another model to fit?\n",
    "\n",
    "First, we must ask ourselves what kind of machine learning problem are we trying to solve.\n",
    "\n",
    "Here are some common types of machine learning problems:\n",
    "- **Classification** - predicting whether a sample is one thing or another (i.e. whether a patient has heart disease)\n",
    "   > Sometimes you'll see `clf` (short for classifier) used as a classification estimator instance's variable name.\n",
    "- **Regression** - predicting a number (i.e. selling price of a car)\n",
    "- **Clustering** - discovering groups in data (i.e. identifying different cutomer segments)\n",
    "- **Dimensionality Reduction** - reducing the number of features in a given dataset (select only the important ones)\n",
    "\n",
    "Scikit-Learn also provides [a handy cheat-sheet](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) to help us identify the machine learning problem, as well as some options for machine learning models to use on our given datasets:\n",
    "\n",
    "![Scikit-Learn algorithm cheat-sheet](./img/sklearn_ml_map.png)\n",
    "\n",
    "> **Note:** Scikit-Learn uses *estimator* as another term for machine learning *model* or *algorithm*.\n",
    "\n",
    "### Picking a machine learning model for a regression problem\n",
    "\n",
    "Let's start with a regression problem. We'll use the [California housing dataset](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset) built into Scikit-Learn's `datasets` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "california = fetch_california_housing() # returns a HUGE dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `california` dataset is loaded as a Python dictionary, so let's turn it into a Pandas `DataFrame` to make it easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  target  \n",
       "0        -122.23   4.526  \n",
       "1        -122.22   3.585  \n",
       "2        -122.24   3.521  \n",
       "3        -122.25   3.413  \n",
       "4        -122.25   3.422  \n",
       "...          ...     ...  \n",
       "20635    -121.09   0.781  \n",
       "20636    -121.21   0.771  \n",
       "20637    -121.22   0.923  \n",
       "20638    -121.32   0.847  \n",
       "20639    -121.24   0.894  \n",
       "\n",
       "[20640 rows x 9 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "california_df = pd.DataFrame(california[\"data\"], columns=california[\"feature_names\"])\n",
    "california_df[\"target\"] = pd.Series(california[\"target\"])\n",
    "california_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's quite a lot of data. Let's see exactly how many samples are we working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20640"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(california_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now let's try using that cheat-sheet and pick a machine learning model for the dataset.\n",
    "\n",
    "![Using the Scikit-Learn cheatsheet to choose a model for the Boston housing dataset](./img/sklearn-ml-map-cheatsheet-boston-housing-ridge.png)\n",
    "\n",
    "Following the flowchart we see that Scikit-Learn suggests using a [`Ridge`](https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression) regression model. Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6060537241737072"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "np.random.seed(69)\n",
    "\n",
    "X = california_df.drop(\"target\", axis=1)\n",
    "y = california_df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = Ridge()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad. But let's see if we can still get an even better result.\n",
    "\n",
    "What happens if the `Ridge` regressor did not work, or did not produce as good of a score as we wanted?\n",
    "\n",
    "Let's check back on the cheat-sheet to see if we can prceed with an alternative step:\n",
    "\n",
    "![Trying out the Ensemble regressors in case the Ridge regressor did not achieve the result we wanted](./img/sklearn-ml-map-cheatsheet-boston-housing-ensemble.png)\n",
    "\n",
    "Following the diagram, we see that the next step would be to try out [`EnsembleRegressors`](https://scikit-learn.org/stable/modules/ensemble.html).\n",
    "\n",
    "One of the most common and useful ensemble methods is the [Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#forest), known for its fast training and prediction times and adaptability to different problems.\n",
    "\n",
    "We've actually used the `RandomForestRegressor` model earlier in this notebook, and here we see why we chose this particular model in those earlier datasets.\n",
    "\n",
    "The basic premise of the Random Forest is to combine a number of different decision trees, each one random from the other and make a prediction on a sample by averaging the result of each decision tree.\n",
    "\n",
    "An in-depth discussion of the Random Forest algorithm is beyond the scope of this notebook but if you're interested in learning more, [An Implementation and Explanation of the Random Forest](https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76) in Python by Will Koehrsen is a great read.\n",
    "\n",
    "Let's try using the [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) on the Boston dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8081169165695959"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(69)\n",
    "\n",
    "X = california_df.drop(\"target\", axis=1)\n",
    "y = california_df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonderful! We see that we get a much better score using the `RandomForestRegressor`.\n",
    "\n",
    "### Picking a machine learning model for a classification problem\n",
    "\n",
    "Now let's try another type of machine learning problem. This time let's work through the steps of picking a model for a classification problem.\n",
    "\n",
    "The heart disease dataset from earlier contains data for exactly that kind of problem, so let's take another look at that here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease = pd.read_csv(\"../data/heart-disease.csv\")\n",
    "heart_disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's check how many samples we're dealing with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(heart_disease)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's work through the cheat-sheet yet again to try and find the right model for our heart disease dataset.\n",
    "\n",
    "![Using the Scikit-Learn cheat-sheet to find the right model for the heart disease dataset](./img/sklearn-ml-map-cheatsheet-heart-disease-linear-svc.png)\n",
    "\n",
    "Following the diagram, we see that we are recommended to use the [`LinearSVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC) model. `LinearSVC` stands for Linear Support Vector Classifier.\n",
    "\n",
    "Let's try it on our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8360655737704918"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "np.random.seed(69)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = LinearSVC(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, but we see that we get some warning that tells us that .\n",
    "\n",
    "We can try and tweak some settings to try and fix those issues, but let's get to that another time.\n",
    "\n",
    "For now, let's proceed along the cheat-sheet and choose another classifier model.\n",
    "\n",
    "![Picking another classifier model from the cheat-sheet](./img/sklearn-ml-map-cheatsheet-heart-disease-ensemble.png)\n",
    "\n",
    "We see that we get to the `EnsembleMethods` again. Except this time, we're going to be using ensemble *classifiers* instead of *regressors*.\n",
    "\n",
    "The Random Forest model has another variant that is used for classification problems. Let's try using it on the heart disease data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(69)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good job! We see that we got no warnings this time using the `RandomForestClassifier`, and we also got a better score to boot.\n",
    "\n",
    "Again, we can tweak some settings or *hyperparameters* in the models above to try and improve their results, and we'll take a look at that more closely in later sections.\n",
    "\n",
    "To wrap things up for this section, here's some quick guideleined for choosing machine learning models:\n",
    "- If you have structured data (tables or dataframes), use ensemble methods, such as, a Random Forest.\n",
    "- If you have unstructured data (text, images, audio, things not in tables), use deep learning or transfer learning.\n",
    "\n",
    "For this notebook, we're focused on structured data, which is why the Random Forest has been our model of choice.\n",
    "\n",
    "If you'd like to learn more about the Random Forest and why it's the war horse of machine learning, check out these resources:\n",
    "\n",
    "- [Random Forest Wikipedia](https://en.wikipedia.org/wiki/Random_forest)\n",
    "- [Random Forests in Python](http://blog.yhat.com/posts/random-forests-in-python.html) by yhat\n",
    "- [An Implementation and Explanation of the Random Forest in Python](https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76) by Will Koehrsen\n",
    "\n",
    "The beautiful part about using Scikit-Learn is that its API allows us to use different models with pretty much the exact same workflows. Indeed, we see that our code has stayed pretty much the same across the different machine learning models used in this section. A big part of being a machine learning engineer or data scientist is experimenting - you might want to try out some of the other models on the cheat-sheet and see how you go. The more you can reduce the time between experiments, the better.\n",
    "\n",
    "## 3. Fitting the model/algorithm and using it to make predictions on our data\n",
    "\n",
    "Now that we have chosen a model for our data, it's time to have the model learn about our data so it can be used to make predictions.\n",
    "\n",
    "We've actually encountered some examples of this in the earlier sections, when we were fitting the model to the sample datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(69)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what is the `fit()` method actually doing when we call it on our data?\n",
    "\n",
    "When we call the `fit()` method, the machine learning algorithm attempt to find patterns between `X` and/or `y`.\n",
    "\n",
    "Let's take a look at our `X` and `y` data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>193</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>293</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "77    59    1   1       140   221    0        1      164      1      0.0   \n",
       "117   56    1   3       120   193    0        0      162      0      1.9   \n",
       "124   39    0   2        94   199    0        1      179      0      0.0   \n",
       "237   60    1   0       140   293    0        0      170      0      1.2   \n",
       "122   41    0   2       112   268    0        0      172      1      0.0   \n",
       "\n",
       "     slope  ca  thal  \n",
       "77       2   0     2  \n",
       "117      1   0     3  \n",
       "124      2   0     2  \n",
       "237      1   2     3  \n",
       "122      2   0     2  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77     1\n",
       "117    1\n",
       "124    1\n",
       "237    0\n",
       "122    1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we call `fit(X, y)`, the model takes a look at all the examples in `X` (features) and sees what the corresponding `y` (label) is.\n",
    "\n",
    "Each different model looks at the data differently, but for now you can imagine it being similar to how people notice patterns in data over time.\n",
    "\n",
    "You'd look at the feature variables, X, the age, sex, chol (cholesterol) and see what different values led to the labels, y, 1 for heart disease, 0 for not heart disease.\n",
    "\n",
    "This concept, regardless of the problem, is similar throughout all of machine learning.\n",
    "\n",
    "**During training (finding patterns in data):**\n",
    "\n",
    "A machine learning algorithm looks at a dataset, finds patterns, tries to use those patterns to predict something and corrects itself as best it can with the available data and labels. It stores these patterns for later use.\n",
    "\n",
    "**During testing or in production (using learned patterns):**\n",
    "\n",
    "A machine learning algorithm uses the patterns its previously learned in a dataset to make a prediction on some unseen data.\n",
    "\n",
    "### Making predictions using a machine learning model\n",
    "\n",
    "After fitting the model to the data (aka training the machine learning model), we'll want to use it to make predictions.\n",
    "\n",
    "Scikit-Learn offers several ways to make predictions, the most common of which being `predict()` and `predict_proba()`.\n",
    "\n",
    "Let's see how they work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given data in the form of `X`, the `predict()` function returns labels in the form of `y`.\n",
    "\n",
    "It's standard practice to save these predictions to a variable named something like `y_preds` for later comparison to `y_test` or `y_true` (usually same as `y_test` just another name):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = clf.predict(X_test)\n",
    "np.mean(y_preds == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, where have we seen that kind of result before?\n",
    "\n",
    "That's right, the `accuracy_score()` and `clf.score()` functions make these comparisons in the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've been dealing with the `predict()` function. The `predict()` function returns values in the same format as the labels in `y`.\n",
    "\n",
    "If you would instead like to get the *probabilities* of getting a label based on the given data, you can instead use `predict_proba()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9 , 0.1 ],\n",
       "       [0.99, 0.01],\n",
       "       [0.73, 0.27],\n",
       "       [0.93, 0.07],\n",
       "       [0.01, 0.99]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast, here's what `predict()` would've returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `predict_proba()` returns an array of values for each row of the input rather than just one single number per row like `predict()` does.\n",
    "\n",
    "The array of values returned by `predict_proba()` are actualy the *probabilities* of getting a certain label (in our case either `0` or `1`) given an input sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9, 0.1]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This particular output means that for the sample `X_test[:1]`, the model predicts that the sample will have a label `0` with a probability score of `0.9`.\n",
    "\n",
    "Conversely, this also means the sample would have a label `1` with probability score of `0.1`.\n",
    "\n",
    "Given these two probabilities, which one do you think would we get if we used `predict()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a predicted label `0`.\n",
    "\n",
    "Because our problem is a classification task, we could simply just get the one with the highest probability if we want a singular output label.\n",
    "\n",
    "With our dataset only having two labels to choose from, predicting a label with 0.5 probability every time would be the same as a coin toss (guessing). Therefore, once the prediction probability of a sample passes 0.5 for a certain label, it's assigned that label.\n",
    "\n",
    "### Predicting values for regression problems\n",
    "\n",
    "`predict()` can also be used for regression problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(69)\n",
    "\n",
    "X = california_df.drop(\"target\", axis=1)\n",
    "y = california_df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For regression problems, we can validate our predictions using `mean_absolute_error()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3270582259932172"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluating the model\n",
    "\n",
    "We've seen how to train a model to find patterns in data with `fit()`. We've also seen how to make predictions with the trined model using `predict()` and `predict_proba()`.\n",
    "\n",
    "Now it's time to evaluate how trustworthy our model's predictions are.\n",
    "\n",
    "Once you've trained a model, you'll want a way to measure how trustworthy its predictions are.\n",
    "\n",
    "Scikit-Learn implements 3 different methods of evaluating models.\n",
    "\n",
    "1. The `score()` method. Calling `score()` on a model instance will return a metric assosciated with the type of model you're using. The metric depends on which model you're using.\n",
    "2. The `scoring` parameter. This parameter can be passed to methods such as `cross_val_score()` or `GridSearchCV()` to tell Scikit-Learn to use a specific type of scoring metric.\n",
    "3. Problem-specific metric functions. Similar to how the `scoring` parameter can be passed different scoring functions, Scikit-Learn implements these as stand alone functions.\n",
    "\n",
    "The scoring function you use will also depend on the problem you're working on.\n",
    "\n",
    "Classification problems have different evaluation metrics and scoring functions to regression problems.\n",
    "\n",
    "Let's look at some examples.\n",
    "\n",
    "### General model evaluation with `score()`\n",
    "\n",
    "We've already seen a quick and easy way to evaluate a machine learning model.\n",
    "\n",
    "Each model instance provided by Scikit-Learn comes with a `score()` method that we can use to generate a metric for how accurate the models predictions are compared to the actual test data labels.\n",
    "\n",
    "Let's review the heart disease dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(69)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a trained model, we can simply use the `score()` method and pass along the test data (meaning the data the model has never seen before) to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `score()` method may differ for different type of machine learning models.\n",
    "\n",
    "For instance, a `RandomForestClassifier`'s `score()` method uses mean accuracy between the prediction vs the test label as its score method.\n",
    "\n",
    "A model which predicts everything 100% correct would receive a score of 1.0 (or 100%).\n",
    "\n",
    "Using the `score()` method, we can see that our model currently has a score of 0.8524, or 85.24%.\n",
    "\n",
    "Let's try and `score()` a regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8081169165695959"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(69)\n",
    "\n",
    "X = california_df.drop(\"target\", axis=1)\n",
    "y = california_df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we can call the `score()` method in pretty much the same way, but there's actually a subtle difference to how the `score()` method works behind the scenes.\n",
    "\n",
    "A `RandomForestRegressor` model uses a different metric to score the model's accuracy. Specifically, the metric used for regression models is the coefficient of determination or [R^2 (pronounced R-squared)](https://en.wikipedia.org/wiki/Coefficient_of_determination).\n",
    "\n",
    "### Evaluating a model using the `scoring` parameter\n",
    "\n",
    "The `score()` method is one way to quickly asses the performance of a machine learning models, providing some default evaluation metric that can work across most types of machine learning models.\n",
    "\n",
    "If you want to take a step up from using `score()`, Scikit-Learn also offers a variety of other methods for evaluating your machine learning model.\n",
    "\n",
    "For instance, depending on the problem you're working on you might want to use a custom `scoring` parameter to help evaluate your model.\n",
    "\n",
    "You can then use the custom scoring parameter with Scikit-Learn's [`cross_val_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) or [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html).\n",
    "\n",
    "Let's compare the difference between using `score()` and `cross_val_score()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(69)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using score()\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81967213, 0.86885246, 0.78688525, 0.8       , 0.78333333])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using cross_val_score()\n",
    "cross_val_score(clf, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and break down what's happened here.\n",
    "\n",
    "You might notice that `cross_val_score()` returns an array of values instead of only a single number like `score()`.\n",
    "\n",
    "This is because `cross_val_score` uses a parameter called `cv` which determines its cross-validation splitting strategy.\n",
    "\n",
    "By default, `cv` uses a 5-fold cross-validation strategy.\n",
    "\n",
    "Now what does all this mean?\n",
    "\n",
    "This visual diagram might be able to help:\n",
    "\n",
    "![Normal Train-Test Split vs 5-fold Cross-Validation](./img/sklearn_cross-validation.png)\n",
    "\n",
    "Figure 1.0 represents the usual train-test split we're used to working with. By setting a `test_size` of `0.2` (or 20%), it means that we are training the model using 80% of the samples, while the remaining 20% are solely for validation and not used for the model to learn anything.\n",
    "\n",
    "This also means depending on what 80% is used to train on and what 20% is used to evaluate the model, it may achieve a score which doesn't reflect the entire dataset. For example, if a lot of easy examples are in the 80% training data, when it comes to test on the 20%, your model may perform poorly. The same goes for the reverse.\n",
    "\n",
    "Figure 2.0 shows 5-fold cross-validation, a method which tries to provide a solution to:\n",
    "\n",
    "1. Not training on all the data\n",
    "2. Avoiding getting lucky scores on single splits of the data\n",
    "\n",
    "Instead of training only on 1 training split and evaluating on 1 testing split, 5-fold cross-validation does it 5 times. On a different split each time, returning a score for each.\n",
    "\n",
    "Why 5-fold?\n",
    "\n",
    "The actual name of this setup K-fold cross-validation, Where K is an abitrary number. 5-fold cross-validation is simply the default used by `cross_val_score()` starting from Scikit-Learn version 0.22 onwards.\n",
    "\n",
    "Figure 2.0 is what happens when we run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80327869, 0.90163934, 0.80327869, 0.8       , 0.8       ])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, X, y, cv=5) # cv is equivalent to K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By getting 5 different scores instead of 1, we can have a wider perspective when it comes to evaluating our model.\n",
    "\n",
    "We can also simple take the mean of these 5 scores to get a singular result.\n",
    "\n",
    "Let's compare the average `cross_val_score()` with our usual `score()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8524590163934426, 0.8249180327868852)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(69)\n",
    "\n",
    "clf_single_score = clf.score(X_test, y_test)\n",
    "clf_cross_val_score = np.mean(cross_val_score(clf, X, y))\n",
    "\n",
    "clf_single_score, clf_cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the mean score returned by `cross_val_score()` is slightly lower than the score returned by `score()`, but we can be much more confident on the accuracy of the cross-validated metric.\n",
    "\n",
    "But wait, where is the `scoring` parameter we're supposed to be talking about?\n",
    "\n",
    "By default, the `scoring` parameter is set to `None`, meaning we haven't actually used it yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83606557, 0.86885246, 0.80327869, 0.85      , 0.78333333])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, X, y, scoring=None) # default scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When scoring is set to `None` (by default), it uses the same metric as `score()` for whatever model is passed to `cross_val_score()`.\n",
    "\n",
    "In our case, we're using a `RandomForestClassifier` model which uses mean accuracy as the default `score()` metric.\n",
    "\n",
    "You can change the evaluation score `cross_val_score()` uses by changing the `scoring` parameter.\n",
    "\n",
    "For different problems using different kinds of models, you might have to use different evaluation scores.\n",
    "\n",
    "The [Scikit-Learn documentation](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) outlines a vast range of evaluation metrics for different problems, but let's have a look at a few.\n",
    "\n",
    "### Classification model evaluation metrics\n",
    "\n",
    "Scikit-learn offers a variety of evaluation metrics for classification problems. Here are the most common metrics/methods you're most likely to come across:\n",
    "\n",
    "1. Accuracy\n",
    "2. Area under ROC curve\n",
    "3. Confusion matrix\n",
    "4. Classification report\n",
    "\n",
    "Using the classification code from above, let's have a look at each of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(69)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy\n",
    "\n",
    "Accuracy is the default metric for the `score()` function within each of Scikit-Learn's classifier models, and is the one we're already used to working with by now.\n",
    "\n",
    "It's probably the metric you're most likely to see being used in classification problems, but there can be quite a few situations where other metrics might make more sense to use.\n",
    "\n",
    "Scikit-Learn returns accuracy as a decimal, but you can easily convert it to a percentage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart Disease Classifier Accuracy: 85.25%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Heart Disease Classifier Accuracy: {clf.score(X_test, y_test) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Area Under Receiver Operating Characteristic (ROC) Curve\n",
    "\n",
    "The length of its name might sound intimidating, but you'll also see this referred to as Area Under Curve (AUC).\n",
    "\n",
    "In a nutshell, the Receiver Operating Characteristic (ROC) curve is a comparison of true postive rate (tpr) versus false positive rate (fpr).\n",
    "\n",
    "For clarity:\n",
    "\n",
    "- True positive = model predicts 1 when truth is 1\n",
    "- False positive = model predicts 1 when truth is 0\n",
    "- True negative = model predicts 0 when truth is 0\n",
    "- False negative = model predicts 0 when truth is 1\n",
    "\n",
    "Scikit-Learn lets you calculate the information required for a ROC curve using the [`roc_curve`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03448276, 0.03448276,\n",
       "       0.03448276, 0.06896552, 0.06896552, 0.10344828, 0.10344828,\n",
       "       0.13793103, 0.13793103, 0.17241379, 0.17241379, 0.31034483,\n",
       "       0.34482759, 0.37931034, 0.44827586, 0.55172414, 0.62068966,\n",
       "       0.65517241, 0.72413793, 0.79310345, 0.89655172, 1.        ])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Make predictions with probabilities\n",
    "y_probs = clf.predict_proba(X_test)\n",
    "\n",
    "# Keep only the probabilities for positive predictions\n",
    "y_probs_positive = y_probs[:, 1]\n",
    "\n",
    "# Use roc_curve to calculate fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs_positive)\n",
    "\n",
    "# Check the false positive rate (fpr)\n",
    "fpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at these on their own doesn't make much sense. It's much easier to see their value visually.\n",
    "\n",
    "Scikit-Learn doesn't have a built-in function to plot a ROC curve, but we can always make our own function to plot these kinds of values visually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    \"\"\"\n",
    "    Plots a ROC curve given the false positve rate (fpr) and \n",
    "    true postive rate (tpr) of a classifier.\n",
    "    \"\"\"\n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, color=\"#fdab58\", label=\"ROC\")\n",
    "    # Plot simple line with no predictive power (baseline)\n",
    "    plt.plot([0, 1], [0, 1], color=\"#588dfd\", linestyle=\"--\", label=\"Guessing\")\n",
    "    # Customize the plot\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot might seem a bit confusing looking at it for the first time, but we can infer that our model seems to be doing a far better job than guessing.\n",
    "\n",
    "If you want to quantify how good your model is performing, you can use the Area Under Curve (AUC). Scikit-Learn implements a function to caculate this called [`roc_auc_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score).\n",
    "\n",
    "The maximum ROC AUC score you can achieve is `1.0` and generally, the closer to `1.0`, the better the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9504310344827586"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, y_probs_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having an `roc_auc_score` of `1.0` means your model only predicts true positives and no false positives, thus literally making perfect predictions.\n",
    "\n",
    "Looking at this using the plotting function from earlier, the ROC curve would run along the top left corner of the plot.\n",
    "\n",
    "You can see this by creating a ROC curve using only the `y_test` labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_test)\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An `roc_auc_score` of `1.0` is the most ideal score, but it is also unlikely.\n",
    "\n",
    "In a nutshell, the main takeaways are:\n",
    "\n",
    "- ROC curves and AUC metrics are evaluation metrics for binary classification models (a model which predicts one thing or another, such as heart disease or not).\n",
    "- The ROC curve compares the true positive rate (tpr) versus the false positive rate (fpr) at different classification thresholds.\n",
    "- The AUC metric tells you how well your model is at choosing between classes (for example, how well it is at deciding whether someone has heart disease or not). A perfect model will get an AUC score of 1.\n",
    "\n",
    "Here are some great resources for learning more about ROC:\n",
    "\n",
    "- [ROC and AUC, Clearly Explained!](https://www.youtube.com/watch?v=4jRBRDbJemM) by StatQuest\n",
    "- [Scikit-Learn's ROC documentation](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html) (contains code examples)\n",
    "- [How the ROC curve and AUC are calculated](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc) by Google's Machine Learning team\n",
    "\n",
    "#### [Confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix)\n",
    "\n",
    "Another metric commonly used for evaluating classification models is using a confusion matrix.\n",
    "\n",
    "A confusion matrix is a specific table layout that allows visualization of the performance of an algorithm, each row representing the instances in an actual class while each column represents the instances in a predicted class, or vice versa. The name stems from the fact that it makes it easy to see whether the system is confusing two classes (i.e. commonly mislabeling one as another)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25,  4],\n",
       "       [ 5, 27]], dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this is probably easier visualized.\n",
    "\n",
    "One way to do it is with `pd.crosstab()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted Label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted Label   0   1\n",
       "Actual Label           \n",
       "0                25   4\n",
       "1                 5  27"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test,\n",
    "            y_preds,\n",
    "            rownames=[\"Actual Label\"],\n",
    "            colnames=[\"Predicted Label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An even more visual way is with Seaborn's [`heatmap()`](https://seaborn.pydata.org/generated/seaborn.heatmap.html) plot.\n",
    "\n",
    "If you've never heard of Seaborn, it's a library which is built on top of Matplotlib. It contains a bunch of helpful plotting functions.\n",
    "\n",
    "And if you haven't got Seaborn installed, you can install it into the current environment using:\n",
    "\n",
    "```sh\n",
    "# Install Seaborn in the current Jupyter Kernel/Conda environment\n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} seaborn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, y_preds)\n",
    "\n",
    "sns.heatmap(conf_mat);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot could use some added communication to let viewers know exactly what's going on.\n",
    "\n",
    "Let's add some customizations and make it into a reusable function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOQAAADfCAYAAADm6n/jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAeGElEQVR4nO3de1xM+f8H8Nc0EV0ViaikbSoqbLkkohRq3Rmisu6iEnIp67p27bLuu24/YrEuRXLJdVF9sdLateuLFLrSDV2nJNX5/eHRfHdMtVPNdE71fj4e+3jsnPOZM69Grz5zzpw5w2MYhgEhhBOU2A5ACPkfKiQhHEKFJIRDqJCEcAgVkhAOUWY7gKKU/B7GdoQmQ91+AdsRmpSy0lfVrqMZkhAOoUISwiFUSEI4hApJCIdQIQnhECokIRxChSSEQ6iQhHAIFZIQDqFCEsIhVEhCOIQKSQiHUCEJ4RAqJCEcQoUkhEOokIRwCBWSEA6hQhLCIVRIQjiECkkIh1AhCeEQKiQhHEKFJIRDqJCEcAgVkhAOoUISwiFUSEI4hApJCIdQIQnhECokIRxChSSEQ6iQhHBIk/3CVq648zAB+89GIi45HTweD9afGcBX6ALrzwzFY6as3o3HiS+l7uvcuzu2+Hs0ZNxGz8rKAvfuXsL3G3/E1+u3sh2n1qiQCnQ/LhE+PxyGSaf28BW6oLy8AiE37mHGN/txaNUcWJkYgGEYJKVnw9GmG5x7d5e4v367NuwEb6T4fD6CD2xDy5Yt2Y5SZ1RIBdr0y0V00NHCL+vmobXKx1+SkQN7Ycyy7fjp1K/YFzgDr17norikFI42FhgxoBfLiRu3wOV+6N5NwHaMeqF9SAUpKHqHhNRMDO1rJS4jALTV0oCNuTH+epYCAHjxKhsAYKzfnpWcTYWlpTlWBC3Atxt2sB2lXqiQCqLWWgXnflgET1d7qXV5hUVQVvr41L94mQUA6KqvCwAoLiltuJBNBJ/Px4H9W3Hjxm0cOx7Gdpx6oZesCsJXUoJRh3ZSyxNSM/DXs1T0tzIFADx/mQW1VirYfOwSrt57iOKSUnRurwNfoQtc7Xo0dOxGadlSH5h+ZozxE2ZCWZnPdpx6Yb2Qr169QlJSEkQiEZSUlKChoQFjY2N06NCB7WhyV1zyHiv3ngYAzBjpAAB48TIbRSXvUVj8Dt/MFaKwuATHr/6GwF0hKCuvwEjar6xRt24CrPxqIRb4r8SrVxkwMurMdqR6Ya2Q165dw44dO5CYmAiGYSTW8Xg8GBkZYeHChRg+fDhLCeXr3ftSLNh6FPGpGZg5chBsLboCAMY79UZFRQXcXezEY4fbWWN84A5sO3EZbv17gK9EexZVUVJSQvD+rbhz53cEHzzOdhy5qLaQv//+e5022Lt3738dc/bsWQQGBsLV1RV+fn4wMjKCmpoaGIZBUVERUlJScPXqVSxatAgfPnzAyJEj65SFKwqK3sFvyxH8lZCCMYNs4DdxqHjdxCF9pca3atkCI+x7Ym/4TSS+yoapQdN7tSAPSwLmwdq6GwYNHou2bbUBANraWgAAVdXWaNtWGzk5eVJ/8LmMx1ST1tzcHDweT+YNMQwDHo+HuLi4fx3r5uaGvn37Ys2aNTWOW7t2Le7fv4+IiAiZc1Qq+Z0bO/dv80WYt+kQ4lMyMN6xN1bNGCPT8xryaww2HD6PI2u80cPU8F/HK5K6/QJWH786N349hUGD+tc4xsS0L1JSpE+6YFNZ6atq11U7Q3733XcKCQN83G90dnb+13FDhgxBeHi4wnIoWtG79+Iyeg63x1LPLyTWZ+Xkw3vjIQzrZwXvsUMk1iVlvAYAdNLVbrC8jc3SZV9DW7uNxLL2eu1w9PBPOPrLafzyy2lkZr5mJ1wdVVvIsWPHKuxBDQwMcPv2bdjbS78l8E9RUVGN+uDOhsPnEZ+SAY9h/aXKCAB6OloQFZfgTOR9eA6zh7pqKwBA5ts8nP/Pn+jdrSvatdFo6NiNxp8P/iu1rPKgTlJSCm7cvNXQkeqt1gd1bt68iaioKKSnp2Px4sVQVVXFb7/9hvHjx0NFRUWmbXh7e2Pp0qXIzs7G0KFDYWxsDHV1dfB4PIhEIvE+ZEREBNatW1frH4oLEl9lI+L2A2iotoKZUUdE3H4gNWbEgF4I+nIUFm3/BVO/3ovxg3ujqOQ9Tv4aAz5fCSu+HMVCcsImmQv54cMHLFiwAJGRkeDz+aioqMDMmTORnJyMr7/+GmfOnEFwcDC0tLT+dVsjRowAn8/Htm3bcPHiRal9KoZh0LlzZ2zYsEGhM7Ui3X+aBAAoLC7B6v+ren92xIBecLLthu2LPHHgfBS2h1yFSgtl2Fp0hf+koXT2TjNU7UGdT+3cuRN79+7FunXrMHDgQAwePBiHDh1C7969ceLECWzcuBFTpkzBihUrahUgLS0NiYmJEIlEYBhG/D6koWH9DmRw5aBOU8DVgzqNVZ0O6nzq/PnzGD9+PIRCIXJzc/+3AWVleHl5ISkpCTdu3Kh1IQ0MDGBgYFCr+xDSVMn8jnNmZiYsLS2rXW9mZobXrxvXES1CuEbmQurp6SExMbHa9Q8fPoSurq5cQhHSXMlcyBEjRiAkJAS//fabeFnlwZhjx44hPDy8yZzmRghbZD6oU1paijlz5uDevXvQ0dFBTk4OjIyMkJeXh7y8PFhZWeHw4cNQVVVVdGaZ0EEd+aGDOvIll4M6LVu2xMGDB3H27Flcu3YNaWlpKC8vR/fu3eHk5AShUNioL51ACBfIPEM2NjRDyg/NkPIllxmyUlRUFKKiovDq1Svw+XwYGhrC2dkZffr0qVdIQkgtZkiRSAQfHx/ExsaCYRhoaWmhoqIChYWF4PF4cHNzw6ZNm8Dnc+MT2zRDyg/NkPIllxly+/btiI2NhY+PD6ZOnQpNTU0AQE5ODoKDgxEcHIwuXbrAz8+v/okJaaZkftvj8uXLEAqF8PX1FZcRAHR0dLB06VKMHj0aYWE0KxFSHzIXsqioCGZmZtWut7GxQV5enjwyEdJsyVxIe3t7XL58GRUVFVWuj46Ohq2trdyCEdIcyXxNHVdXV6xatQpeXl6YNm0ajI2NwePx8PLlS5w+fRp//vkntm5tfN+lQAiX1OqaOpVDa1ouyzV1GgIdZZUfOsoqX5y7pg4hpGqsXFOHEFK1Wp+pExcXh6KiIolrXZaVlaGoqAgxMTFYuXKlXAMS0pzIXMjnz5/Dx8cHqamp1Y5RUlKiQhJSDzIXcvPmzUhPT8fs2bPB4/Gwb98+rF69GgUFBQgPD0dWVhbOnj2rwKiENH0yvw/54MEDTJo0CYsXL8a8efPA5/NhZGQEb29vnD59Gjo6Ojh48KAisxLS5NXqTB1zc3MAQKtWrdC5c2c8fvwYAKChoYEJEyYgJiZGMSkJaSZkLmTbtm0lTo0zNDREQkKC+Lauri6ys7PlGo6Q5kbmQvbr1w8hISFITk4GAHTr1g13794Vl/TOnTvQ1qbvoSCkPmQupI+PDwoKCuDq6oqcnBxMmTIFxcXFGD58OL744gtcvXoVbm5uisxKSJMncyENDQ1x6dIlLF68GDo6OtDT08PRo0chEAigrKyMWbNmwd/fX5FZCWny6Jo65F/RuazyVdO5rHL7ruy9e/fS6XaE1JPcCpmRkYGnT5/Ka3OENEtyKyQhpP6okIRwCBWSEA6hQhLCIdV+2uOnn36q1YYePXpU7zDypO8UyHaEJuNd+i22IzQbciskIH2tHUJI7VRbyCNHjjRkDkIIaigkfXkOIQ2PDuoQwiFUSEI4hApJCIdQIQnhECokIRxS6wslx8fHIyoqCunp6Zg6dSpUVVWRkJCAQYMGKSIfIc1KrQq5fv16HD9+HAzDgMfjYfjw4SgoKIC/vz8GDx6MHTt2QEVFRVFZCWnyZH7JeuTIERw7dgxz5sxBaGio+KsE7OzsMG3aNERFRWH//v0KC0pIcyBzIU+ePInhw4dj0aJFMDAwEC/X1NREYGAgRo0ahYiICIWEJKS5kLmQaWlp6NevX7XrbW1tkZGRIZdQhDRXMhdSW1sbmZmZ1a5/9uwZtLS05BKKkOZK5kK6uLjg+PHjeP78uXhZ5ac7oqOjERISAkdHR/knJKQZkfkykAUFBfDw8EBKSgpMTU3x5MkT2NjYoKioCE+fPkWnTp0QGhoKHR0dRWeWiY6GKdsRmoyspKtsR2hSWrTrWu06mWdITU1NhIaGYvbs2SgtLYWKigr+/vtvvHv3DtOnT0dYWBhnykhIY9VkL5RMM6T80AwpXzXNkDKfGJCeni7TOH19fVk3SQj5hMyFdHJykukSHXFxcfUKREhzJnMhfXx8pApZXl6ON2/eIDo6GmpqavDz85N7QEKaE5kLWVPZRCIR3N3dkZKSIpdQhDRXcvn4lbq6OoRCIUJCQuSxOUKaLbl9HvLDhw/Izc2V1+YIaZbqfZS1tLQUcXFxOHjwICwsLOQWjJDmSC5HWRmGgYqKCgICAuQWjJDmSOZC+vr6VrlcSUkJurq6GDJkCJ2pQ0g9yVzIjh07wsbGBl26dFFgHEKaN5kP6mzYsAEXL15UZBZCmj2ZC9m6dWu6Xg4hCibzS9a1a9di5cqVeP/+PQYMGAAdHR3w+XypcXQuKyF1J/OnPaytrVFWVoaKiooaz2nlyrms9GkP+aFPe8iXXD7tMXv2bPr+R0IUrNoZMigoCO7u7ujRo0dDZ5ILLs+Qv0aeho2t9PN6/uwVTPPi3gn6XJoh79z7A/t+PoEn8c/BU+KhR3dz+M2eih6WFniVkYVhE6bVeP+DP25En8+tGyZsNeo0Q4aHh6N///6NtpBcJjAzQcSFa7hwTvIXPS1Nts+cNle/P3gI74BV+MzYCAvmfImy8nKEhEdgmu8yHNm9GSbGRvhu9VKp+71//x4btu2BjnYbmH1mzEJy2dX6qwRI/RgadYaGhjouX7yBUyHn2Y7TqGzcsQ8d2uvi+P5taN2qFQBglOsQjJoyBzv2HcaBHRswcpiT1P2+374XZWXl2Lh6GbQ0NRo6dq3Ql+00MHOLjy+lE+JfsJykcckvKET88yQMcxooLiMAtNPRhm0vK/z96EmV90t4kYTjYRcw2s0ZNj0tGypundU4Q96/fx/l5eW12uCYMWPqk6fJ+7SQqqqtUVz8js1IjYK6mioiTuyXKGOlvLyCKt+CA4Cd+w5DRaUlFsz+UtER5aLGQoaGhiI0NFSmDVV+AQ8VsmYWFqYoLBDhm++CMGacGzQ01JGUmIpvv96KM2F0JlR1+Hw+jAw6SS2Pf56EB/99Avu+NlWui7pzD19OHgfddo3jPOsaCzlx4kT07NmzgaI0D+YWptDQVIeWlibmz10GLS1NzJ33JQ78vB3KLZQRevIc2xEbjeLid1ixfjMAYKanUGp9SHgE+HwleEwY1dDR6qzGQtra2mLkyJENlaVZOHwoBHy+EoL3HxMvO3M6AnfuXcK6b5bjdOgFVFRUsJiwcXhXUgLf5esQ/zwRs7wmoXcvybcySt6/R8TVSAy27wf9Dnospaw91o6yZmVl1Wq8nl7jeVJr8vPBE1LLSkreI/TkWSxfsQBm5p8h7kkCC8kaj4JCEXyWrcGDh08wdsRQ+M+V3j+M/eNvFL97h2FOA1lIWHesFXLIkCG1OmDElVPyFOX167cAAHV1VZaTcNvb3DzMXfQVnj5LhHC0K1Yv9avyDLJbd++jRQtlOPTvzULKuqu2kGPHjoWhoaHCHvjUqVOYO3cuSktLERAQAGXlpv+WaMeOegg7dwjhYZfww8afJNaZCkwAACnJL9mI1igUFRWLyzh10lgsWzCn2rEP/vsYlhYCqKupNWDC+qu2Bd99951CH9jCwgI///wzhEIhXr9+jfnz5yv08bggIyMLmpoamDptIvbu/hmFhSIAQKdOHTDFYxz+E30X2dlvWE7JXd9s3Y2nzxLhKRxdYxk/lJXhRXIqhKNcGzCdfLA6LXXt2hWLFy/Gli1b4O7u3iwuAbJsyTr8cmIPrlwPwZGfQ6GuroZZcz1RVlaGZQHr2I7HWS+SU3Hhyg1oqKvB3NQEF67elBpTeZZORmY2PnwoQwe99g0ds95Yf53o7u4OU1Punggub5cirsPD3RuLA+ZhzddLUfKuBLdv38P6tVvwLCGR7Xicdf/BfwEAhaIirNywtcoxlYXMLygE8PFkgsaGvv2K/CsufdqjKZDL90MSQhSPCkkIh1AhCeEQKiQhHEKFJIRDqJCEcAgVkhAOoUISwiFUSEI4hApJCIdQIQnhECokIRxChSSEQ6iQhHAIFZIQDqFCEsIhVEhCOIQKSQiHUCEJ4RAqJCEcQoUkhEOokIRwCBWSEA6hQhLCIVRIQjiECkkIh1AhCeEQKiQhHEKFJIRDqJCEcAgVkhAOoUISwiFUSEI4pMl+gzIhjRHNkIRwCBWSEA6hQhLCIVRIQjiECkkIh1AhCeEQKiQhHEKFJIRDqJCEcAgVkhAOoUKyJCIiAl988QWsra3h6uqKs2fPsh2p0YuLi0P37t2RmZnJdpQ6o0Ky4PLly1iyZAns7e2xa9cu9OnTB8uXL8eVK1fYjtZoJSYmYu7cuSgrK2M7Sr3QyeUscHFxgaWlJbZt2yZetnDhQsTHx+Py5cssJmt8ysrKEBISgi1btqBFixbIy8tDdHQ0OnTowHa0OqEZsoGlpaUhNTUVQ4cOlVg+bNgwJCYmIi0tjaVkjdMff/yBzZs3Y8aMGViyZAnbceqNCtnAEhMTAQDGxsYSy42MjAAASUlJDZ6pMTMxMcH169fh6+sLPp/Pdpx6U2Y7QHNTWFgIAFBXV5dYrqamBgAQiUQNnqkxa9euHdsR5IpmyAZWucvO4/GqXK6kRP8kzRn96zcwDQ0NANIzYVFRkcR60jxRIRtY5b5jamqqxPKUlBSJ9aR5okI2MCMjI3Tu3FnqPcdr166hS5cu0NfXZykZ4QI6qMMCHx8fBAUFQUtLC4MHD8bNmzdx+fJlifclSfNEhWTBuHHjUFpaioMHD+LUqVMwMDDAxo0b4ebmxnY0wjI6U4cQDqF9SEI4hApJCIdQIQnhECokIRxChSSEQ6iQhHAIFbKWAgMDYWZmJvGfhYUFPv/8cwiFQoSHhzdIDicnJ3h5eYlve3l5wcnJqdbbEYlEyMnJkVuuyuenJmfOnIGZmRnOnDkjl8f88ccfYWZmhpcvX3Jye7VBJwbUUVBQELS1tQF8/KSGSCTC+fPnERgYiNzcXMyYMaNB83h7e+Pdu3e1us+jR48wb948bN68GX379lVQMlIbVMg6cnZ2RufOnSWWTZgwAW5ubti1axc8PT3RsmXLBstjb29f6/skJCQgOztbAWlIXdFLVjlq1aoVnJycIBKJ8OzZM7bjkEaICilnlR88Li8vB/BxX2/lypVYsWIFrKys4ODgIN5ne/DgAaZPn45evXqhV69emDFjBh4+fCi1zUuXLmH06NGwtrbGiBEjEBMTIzWmqn3IFy9ewN/fH3379oWNjQ28vLxw//59AB/3k4KCggAAU6dOlbhvZmYmli1bhn79+sHKygpjxozB+fPnpR7z0aNHmDFjBnr16oWBAwfiyJEjdXnKavT48WP4+fmhf//+6N69O+zs7BAQEFDlpR4TExMxdepUWFtbY/DgwdixYwc+fPggMSY/Px/r16/HwIEDYWlpCVdXVxw+fBhcOYOUXrLKUUVFBWJjY9GyZUuYmJiIl1+8eBHGxsb46quv8ObNG+jo6ODOnTuYO3cuzM3N4e/vj9LSUpw5cwYeHh44dOgQbG1tAXw8ABIUFIRevXph6dKlSElJgbe3NyoqKtCpU6dqsyQnJ2PixIlQVlaGp6cndHR0cPLkSUyfPh3Hjh2Di4sLXr9+jZCQEHh7e8PKygoAkJWVBaFQCIZh4OXlBS0tLdy4cQNLly5FdnY2Zs2aBQB49uwZvLy8oKmpifnz5+PDhw/YtWuX+A+RPMTHx2PKlCkwMjLCnDlz0Lp1a/z55584d+4csrOzcfToUYnxlX98li9fjtjYWOzevRsZGRn4/vvvAQDFxcXw9PRERkYGpkyZgg4dOiAmJgYbNmxAcnIy1qxZI7fsdcaQWlm+fDkjEAiYx48fM2/fvmXevn3LZGdnMw8ePGD8/f0ZgUDAbNiwQTze0dGRMTc3Z1JSUsTLysvLmSFDhjDu7u5MWVmZeHlRURHj4uLCjB49mmEYhikrK2Ps7OyY8ePHM6WlpeJxYWFhjEAgYDw9PcXLPD09GUdHR/Ftf39/xtramklOThYvy8nJYWxsbJgFCxZIbCcmJkbi5+vTpw+TlZUl8XMvXryYsbS0ZN68ecMwDMP4+fkxPXv2ZNLT08Vjnj9/zlhaWjICgaDG57DyccPCwmoct3r1aqZHjx5Mbm6uxPJFixYxAoFAvHznzp2MQCBg/P39JcYFBgYyAoGAefr0qXhc9+7dxbcrbdmyhREIBExcXJzE9tLS0mrMpwj0krWOxo4dCzs7O9jZ2WHAgAGYNGkSbty4AS8vLwQEBEiMNTQ0hKGhofj2kydPkJaWBmdnZ+Tn5yMnJwc5OTkoKSmBo6Mj4uLikJmZicePH+Pt27cYN24cWrRoIb7/6NGjoaWlVW22iooKREdHY9CgQeKr2QGAtrY2jh8/jpUrV1Z7v+vXr8PW1hbKysriXDk5ORg6dChKS0tx584dVFRU4NatWxg0aBA6duwovr+JiQkGDBhQ6+eyOmvXrsXNmzfRpk0b8TKRSAQVFRUAH2e8f5o5c6bE7cq3haKjowF8/BC4QCCArq6uxM/m7OwMAIiMjJRb9rqil6x19MMPP4iveKakpARNTU2YmJiIf1n+qW3bthK3Ky/fsWnTJmzatKnK7WdkZIj3k/5ZZgDg8/kSRftUXl4eiouLqxwjEAiqvV9ubi4KCwtx/fp1XL9+vdpcldv/NBcAdO3aFTdv3qz2MWqDx+MhNzcX+/btQ3x8PFJTU5Geni7e36uoqJB67H+qzFf5fmJqaipKSkpgZ2dX5eNlZGTIJXd9UCHr6PPPP5d626M6n14vtPIXyd/fHz179qzyPl27dkVWVhYA4P3791LrP/1l/KfK/bjaXsGu8n7Dhg2Du7t7lWMMDAzE/1/bXLUVFRWF+fPno3379ujXrx8cHBxgaWmJ27dvY9++fVLjq7uSX+XzX15eDhsbG/j6+lb5eO3bt5db9rqiQrKg8mCMqqoq+vfvL7Hu4cOHyM/PR6tWrcS//MnJyRJjGIbBq1evYGpqWuX2tbW10apVK/GFs/4pODgYb968wfLly6XW6ejooHXr1igrK5PKlZ6ejidPnqB169bQ1taGurq6VC4Acj27Zf369TAyMkJYWBhUVVXFyy9cuFDl+E+fk8qLTlfOlJ06dUJRUZHUz5afn4+7d+/W+KqjodA+JAssLS2hq6uLo0ePii//CHzcP1q4cCGCgoLA5/PRrVs3dOrUCSdOnJA4C+fixYvIzc2tdvvKysqwt7dHdHS0xMuw/Px8BAcHi18yV86glbOasrIyHBwcEB0djadPn0ps8/vvv4ePjw9yc3PB4/Hg4uKCW7duISEhQTzm5cuXiIqKqvsT84m8vDzo6+tLlDEjIwPXrl0DAKkjuqGhoRK3Dx06BB6PJ35Lx8nJCU+fPpXKuGfPHvj7+3PivWOaIVnQokULrFq1CgsXLsS4ceMwYcIEqKio4NSpU0hPT8fmzZuhrPzxn2bVqlXw8fHBpEmTMH78eGRlZeHYsWMSBzqqEhAQAKFQCKFQCA8PD6irqyM0NBTFxcVYuHAhgI8zIgCcOHECb968wciRI7FkyRLcu3cPHh4e8PDwgL6+PqKiohAZGYlJkyaJZyB/f39ERUXBy8sL06ZNA5/Px9GjR6GmpobS0lKZnofw8HD89ddfUsstLCwwefJkODg44NKlS1i9ejWsrKzw8uVLhIaGiv84/fOPGfBx5hSJRLC2tkZ0dDQiIyMxa9Ys8cw3d+5cXLt2Db6+vnB3d4epqSn++OMPnDt3Dg4ODnBwcJAptyJRIVkybNgwHDx4EHv27MHu3buhpKQEU1NT7NmzB46OjuJxjo6O2LdvH3788Uds3boVenp6+Pbbb3Hs2LEat29iYoKQkBBs3boVBw4cgJKSEqytrbFx40Zxqezs7ODq6orIyEjExMRg6NChMDQ0RGhoKHbu3CkusIGBAYKCgiROZu/YsSNOnDiBTZs24cCBA2jZsiWEQiEAVLl/V5XY2FjExsZKLR8yZAgmT56MtWvXQlVVFTdv3sS5c+fQoUMHjBkzBi4uLpg8eTJiYmLQrVs38f3279+Pb775BhEREdDT00NQUBCmTZsmXt+mTRuEhIRg586duHLlCkJCQqCvr4/58+djzpw5nLhqPF3kihAOYf9PAiFEjApJCIdQIQnhECokIRxChSSEQ6iQhHAIFZIQDqFCEsIhVEhCOOT/Adc1rYEew7oeAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_conf_mat(conf_mat):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix using Seaborn's `heatmap()` function.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(3, 3))\n",
    "    ax = sns.heatmap(conf_mat,\n",
    "                     annot=True, # Annotate the boxes\n",
    "                     cbar=False) # Remove the color bar on the side\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\");\n",
    "\n",
    "plot_conf_mat(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with ROC curves before, an ideal model only has true positives and true negatives. This means the top right and bottom left squares in the confusion matrix would both have a value of 0.\n",
    "\n",
    "Now, why did we name our function `plot_conf_mat()` instead of `plot_confusion_matrix()`?\n",
    "\n",
    "Scikit-Learn has an implementation of plotting a confusion matrix called [`plot_confusion_matrix()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html#sklearn.metrics.plot_confusion_matrix), however, the documentation also says this function is deprecated.\n",
    "\n",
    "As such, trying to import it might return an error.\n",
    "\n",
    "You can try to use it but beware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\git-gud\\ztm-machine-learning\\env\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1e98a6b8a90>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(clf, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _Deprecated since version 1.0:_ `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the following class methods: [`from_predictions`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay.from_predictions) or [`from_estimator`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay.from_estimator).\n",
    "\n",
    "Thankfully, Scikit-Learn recently released a new version 1.0, and its documentation also links us to other built-in methods we can use instead.\n",
    "\n",
    "Let's take a quick look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_preds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report\n",
    "\n",
    "The final major metric you should consider when evaluating a classification model is a classification report.\n",
    "\n",
    "A classification report is more so a collection of metrics rather than a single one.\n",
    "\n",
    "You can create a classification report using Scikit-Learn's [`classification_report()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) function.\n",
    "\n",
    "Let's see it in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.83      0.86      0.85        29\\n           1       0.87      0.84      0.86        32\\n\\n    accuracy                           0.85        61\\n   macro avg       0.85      0.85      0.85        61\\nweighted avg       0.85      0.85      0.85        61\\n'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "classification_report(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formatting looks a bit wonky, because we actually need to pass it to the `print()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85        29\n",
      "           1       0.87      0.84      0.86        32\n",
      "\n",
      "    accuracy                           0.85        61\n",
      "   macro avg       0.85      0.85      0.85        61\n",
      "weighted avg       0.85      0.85      0.85        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It returns four columns: _precision_, _recall_, _f1-score_ and _support_.\n",
    "\n",
    "The number of rows will depend on how many different classes there are. But there will always be three rows labelled _accuracy_, _macro avg_ and _weighted avg_.\n",
    "\n",
    "Each term measures something slightly different:\n",
    "\n",
    "- **Precision** - Indicates the proportion of positive identifications (model predicted class 1) which were actually correct. A model which produces no false positives has a precision of 1.0.\n",
    "- **Recall** - Indicates the proportion of actual positives which were correctly classified. A model which produces no false negatives has a recall of 1.0.\n",
    "- **F1 score** - A combination of precision and recall. A perfect model achieves an F1 score of 1.0.\n",
    "Support - The number of samples each metric was calculated on.\n",
    "- **Accuracy** - The accuracy of the model in decimal form. Perfect accuracy is equal to 1.0, in other words, getting the prediction right 100% of the time.\n",
    "- **Macro avg** - Short for macro average, the average precision, recall and F1 score between classes. Macro avg doesn't take class imbalance into effect. So if you do have class imbalances (more examples of one class than another), you should pay attention to this.\n",
    "- **Weighted avg** - Short for weighted average, the weighted average precision, recall and F1 score between classes. Weighted means each metric is calculated with respect to how many samples there are in each class. This metric will favour the majority class (e.g. it will give a high value when one class out performs another due to having more samples).\n",
    "\n",
    "You might be tempted to ask: Why should we bother with all these? Isn't measuring the model's accuracy enough?\n",
    "\n",
    "Accuracy is a good metric to report, except when you have very imbalanced classes. Let's take a look at a basic example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.99990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.499950</td>\n",
       "      <td>0.99980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.99990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.99995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.499975</td>\n",
       "      <td>0.99985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>9999.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0.0  1.0  accuracy     macro avg  weighted avg\n",
       "precision     0.99990  0.0    0.9999      0.499950       0.99980\n",
       "recall        1.00000  0.0    0.9999      0.500000       0.99990\n",
       "f1-score      0.99995  0.0    0.9999      0.499975       0.99985\n",
       "support    9999.00000  1.0    0.9999  10000.000000   10000.00000"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disease_true = np.zeros(10000)\n",
    "disease_true[0] = 1 # only one case\n",
    "\n",
    "disease_preds = np.zeros(10000) # every prediction is 0\n",
    "\n",
    "pd.DataFrame(classification_report(disease_true,\n",
    "                                   disease_preds,\n",
    "                                   zero_division=0,\n",
    "                                   output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example represents a heavily imbalanced situation where only one case is positive over a total of 10,000 cases.\n",
    "\n",
    "You build a model, and find that it's 99.99% accurate... But all it really does is predict that no one has the disease, in other words all 10,000 predictions are false.\n",
    "\n",
    "If what you need is for the model to successfuly predict positive cases, this model won't be the right fit even though it has a 99.99% accuracy.\n",
    "\n",
    "This is such an example where you'd want to use other metrics such as F1 score, where you can see a comparison between positive and negative predictions.\n",
    "\n",
    "Here are some rules of thumb for evaluating classification models:\n",
    "\n",
    "- Accuracy is a good measure to start with if all classes are balanced (e.g. same amount of samples which are labelled with 0 or 1)\n",
    "- Precision and recall become more important when classes are imbalanced.\n",
    "- If false positive predictions are worse than false negatives, aim for higher precision.\n",
    "- If false negative predictions are worse than false positives, aim for higher recall."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a17b241f4543d8602b7482e0e0acc758b16495de27bccf17cd651e6db5d1cb08"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
